{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as web\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import plotly.colors\n",
    "from datetime import datetime\n",
    "import time\n",
    "import datetime as dt\n",
    "import copy\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(asset_name='SPY', directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019', force_yahoo=0, verbosity=0):\n",
    "        \n",
    "    # If the 'directory' doesn't exist, create it\n",
    "    if os.path.isdir(directory) == False:\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    pathname = directory + '/' + asset_name + '_' + start_date + '.csv'\n",
    "    if os.path.isfile(pathname) == True and not force_yahoo:\n",
    "        if verbosity >= 1:\n",
    "            print('Loading from file: ', pathname)        \n",
    "        df = pd.read_csv(pathname, index_col='Date')\n",
    "    else:\n",
    "        if verbosity >= 1:\n",
    "            print('Downloading from Yahoo! - ', asset_name)\n",
    "        df = web.DataReader(asset_name, data_source='yahoo', start=start_date, end=stop_date)\n",
    "        df.to_csv(pathname)    \n",
    "\n",
    "    # Copy the (date) index to a Date field and make a new index which enumerates\n",
    "    # all the entries.\n",
    "    df.insert(0, 'Date', df.index)\n",
    "    df.index = np.arange(df.shape[0])\n",
    "    df['Date']=pd.to_datetime(df['Date'], format='%Y/%m/%d')\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic stock generator\n",
    "\n",
    "# We'll generate the Adj Close price as the primary (since this is the sequnce of labels we are training on)\n",
    "# The relationship of the other features to the Adj Close will be as follows:\n",
    "# Close = close_scale * Adj Close\n",
    "# Open = previous day's Close\n",
    "# Low = Open\n",
    "# High = Close\n",
    "# Volume = 0\n",
    "\n",
    "# source_asset_name - name of asset to model from\n",
    "# trend_list - list of tuples - (magnitude, days for a full cycle of this trend)\n",
    "\n",
    "def make_synthetic_stock(source_asset_name='SPY', new_name='SYN', directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019', trend_list=[], adj_close_start=0, price_slope=0, close_scale=1.4):\n",
    "    \n",
    "    syn_df = get_data(asset_name=source_asset_name, directory=directory, start_date=start_date, stop_date=stop_date, force_yahoo=1)\n",
    "        \n",
    "    syn_length = len(syn_df)\n",
    "    \n",
    "    for i in range(syn_length):\n",
    "        mag = adj_close_start + (i * price_slope)\n",
    "        for trend in trend_list:\n",
    "            mag += (trend[0] * np.sin(6.28 * i / trend[1]))\n",
    "\n",
    "        syn_df['Adj Close'].loc[i] = mag\n",
    "        syn_df['Close'].loc[i] = mag * close_scale\n",
    "    \n",
    "        # Today's open is yesterday's close\n",
    "        if i > 0:\n",
    "            syn_df['Open'].loc[i] = syn_df['Close'].loc[i-1]\n",
    "        else:\n",
    "            syn_df['Open'].loc[i] = syn_df['Close'].loc[i]\n",
    "        \n",
    "        syn_df['Low'].loc[i] = syn_df['Open'].loc[i]\n",
    "        syn_df['High'].loc[i] = syn_df['Close'].loc[i]\n",
    "    \n",
    "    pathname = directory + '/' + new_name + '_' + start_date + '.csv'    \n",
    "    \n",
    "    syn_df.to_csv(pathname, index=False)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a Plotly interactive candelstick chart\n",
    "\n",
    "# path is directory to save image in\n",
    "# display_plot - 1=display plot in Notebook\n",
    "\n",
    "def plotly_candlestick(asset_df, asset_name, basefn = '', display_plot = 0, save_plot=1):\n",
    "\n",
    "    df = asset_df\n",
    "    \n",
    "    trace1 = {\n",
    "        'x': df.Date,\n",
    "        'open': df.Open,\n",
    "        'close': df.Close,\n",
    "        'high': df.High,\n",
    "        'low': df.Low,\n",
    "        'type': 'candlestick',\n",
    "        'name': asset_name,\n",
    "        'showlegend': True\n",
    "    }\n",
    "\n",
    "    data = [trace1]\n",
    "        \n",
    "    layout = go.Layout({\n",
    "        'title': {\n",
    "            'text': 'Asset: ' + asset_name,\n",
    "            'font': {\n",
    "                'size': 20\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    fig = go.Figure(trace1, layout)\n",
    "    \n",
    "    if display_plot:        \n",
    "        fig.show()\n",
    "    \n",
    "    if save_plot:\n",
    "        fig.write_html(basefn + 'asset_candelstick.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_to_df(df):\n",
    "    # Add a feature called Prev Adj CLose\n",
    "    prev_adj_close = df['Adj Close'].shift(1).copy()\n",
    "    df['Prev Adj Close'] = prev_adj_close\n",
    "\n",
    "    # Take care of special case of very first previous Adj close - just make is the same as the Adj Close\n",
    "    df['Prev Adj Close'][0] = df['Prev Adj Close'][1]\n",
    "    \n",
    "    # Volume isn't used\n",
    "    df = df.drop(columns=['Volume'])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Cuda available:\",torch.cuda.is_available())\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will normalise each column of a dataframe to +/- 0.5\n",
    "\n",
    "def normalise_df(df):\n",
    "           \n",
    "    r = df.copy()\n",
    "    \n",
    "    # Get the min and max of all values in dataframe except 'Date' field\n",
    "    min_value = df.drop('Date',1).min().min()    \n",
    "    max_value = df.drop('Date',1).max().max()\n",
    "\n",
    "#    print(min_value)\n",
    "#    print(max_value)\n",
    "    \n",
    "#    r['Open'] = (r['Open'] - min_value) / (max_value - min_value) - 0.5\n",
    "#    r['Low'] = (r['Low'] - min_value) / (max_value - min_value) - 0.5\n",
    "#    r['High'] = (r['High'] - min_value) / (max_value - min_value) - 0.5\n",
    "#    r['Close'] = (r['Close'] - min_value) / (max_value - min_value) - 0.5\n",
    "#    r['Adj Close'] = (r['Adj Close'] - min_value) / (max_value - min_value) - 0.5\n",
    "#    r['Prev Adj Close'] = (r['Prev Adj Close'] - min_value) / (max_value - min_value) - 0.5    \n",
    "\n",
    "\n",
    "    r.loc[:, r.columns != 'Date'] = (((r.loc[:, r.columns != 'Date'] - min_value) / (max_value - min_value)) - 0.5)\n",
    "#    print(r.describe())\n",
    "    \n",
    "#    display(r)\n",
    "    scale = max_value - min_value\n",
    "    offset = min_value\n",
    "#    To un-normalise:\n",
    "    \n",
    "#    original_value = ((norm_price + 0.5) * scale) + offset\n",
    "#    scale = max_value - min_value\n",
    "#    offset = min_value\n",
    "\n",
    "#    print(\"values from df normalisation:\")\n",
    "#    print(\"Scale:\", scale)\n",
    "#    print(\"Offset:\", offset)\n",
    "\n",
    "\n",
    "#    display(r.head())\n",
    "#    display(df.head())\n",
    "    return r, scale, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalise_value(norm_value, scale, offset):\n",
    "    return (((norm_value + 0.5) * scale) + offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalise_df(df, scale, offset):\n",
    "    \n",
    "    result = df.copy()\n",
    "    \n",
    "    df = ((df + 0.5) * scale) + offset\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version is for sequence to value learning - the label is a single value - tomorrow's Adj Close\n",
    "\n",
    "# Given one of the asset train, valid or test dataframes, this will make a new three dimensional list which has\n",
    "# dimensions (num_samples, window_size - tw, 6) which represents the effect of sliding a window of width window_size (tw)\n",
    "# down the dataframe from start to end and collecting the input features into a length 6 vector.  This will be our\n",
    "# input dataset to the LSTM.\n",
    "\n",
    "# In addition, also generate a list of (training) labels which is \"tomorrow's\" adjusted closing price - the thing \n",
    "# we are trying to predict. There is a single training label for each tw x 6 set of inputs.\n",
    "\n",
    "\n",
    "def create_input_sequences_out_val_from_df(input_data_df, tw):\n",
    "    in_seq = []\n",
    "    out_seq= []\n",
    "    L = len(input_data_df)\n",
    "\n",
    "    for i in range(L-tw):\n",
    "        seq = []\n",
    "        for j in range(tw):\n",
    "            features = [input_data_df['Open'].loc[i+j], input_data_df['Low'].loc[i+j], input_data_df['High'].loc[i+j], \n",
    "                        input_data_df['Close'].loc[i+j], \n",
    "                         input_data_df['Prev Adj Close'].loc[i+j], input_data_df['Adj Close'].loc[i+j]]\n",
    "            seq.append(features)\n",
    "\n",
    "        train_label = input_data_df['Adj Close'].loc[i+tw]\n",
    "        out_seq.append(train_label)\n",
    "        in_seq.append(seq)\n",
    "    return in_seq, out_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version is for sequence to sequence learning - the label is a sequence up to and including tomorrows Adj Close\n",
    "\n",
    "def create_input_sequences_from_df(input_data_df, tw):\n",
    "    in_seq = []\n",
    "    out_seq= []\n",
    "    L = len(input_data_df)\n",
    "\n",
    "    for i in range(L-tw):\n",
    "        window_input_seq = []\n",
    "        window_output_seq = []\n",
    "        for j in range(tw):\n",
    "            features = [input_data_df['Open'].loc[i+j], input_data_df['Low'].loc[i+j], input_data_df['High'].loc[i+j], \n",
    "                        input_data_df['Close'].loc[i+j], \n",
    "                         input_data_df['Prev Adj Close'].loc[i+j], input_data_df['Adj Close'].loc[i+j]]\n",
    "            window_input_seq.append(features)\n",
    "            \n",
    "            window_output_seq.append(input_data_df['Adj Close'].loc[i+j+1])\n",
    "\n",
    "        out_seq.append(window_output_seq)\n",
    "        in_seq.append(window_input_seq)\n",
    "        \n",
    "#        print(\"seq:\", i)\n",
    "#        print(\"input:\\n\",window_input_seq)\n",
    "#        print(\"output:\\n\", window_output_seq)\n",
    "    return in_seq, out_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_color(colorscale, intermed):\n",
    "    \"\"\"\n",
    "    Plotly continuous colorscales assign colors to the range [0, 1]. This function computes the intermediate\n",
    "    color for any value in that range.\n",
    "\n",
    "    Plotly doesn't make the colorscales directly accessible in a common format.\n",
    "    Some are ready to use:\n",
    "    \n",
    "        colorscale = plotly.colors.PLOTLY_SCALES[\"Greens\"]\n",
    "\n",
    "    Others are just swatches that need to be constructed into a colorscale:\n",
    "\n",
    "        viridis_colors, scale = plotly.colors.convert_colors_to_same_type(plotly.colors.sequential.Viridis)\n",
    "        colorscale = plotly.colors.make_colorscale(viridis_colors, scale=scale)\n",
    "\n",
    "    :param colorscale: A plotly continuous colorscale defined with RGB string colors.\n",
    "    :param intermed: value in the range [0, 1]\n",
    "    :return: color in rgb string format\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if len(colorscale) < 1:\n",
    "        raise ValueError(\"colorscale must have at least one color\")\n",
    "\n",
    "    if intermed <= 0 or len(colorscale) == 1:\n",
    "        return colorscale[0][1]\n",
    "    if intermed >= 1:\n",
    "        return colorscale[-1][1]\n",
    "\n",
    "    for cutoff, color in colorscale:\n",
    "        if intermed >= cutoff:\n",
    "            low_cutoff, low_color = cutoff, color\n",
    "        else:\n",
    "            high_cutoff, high_color = cutoff, color\n",
    "            break\n",
    "\n",
    "    # noinspection PyUnboundLocalVariable\n",
    "    return plotly.colors.find_intermediate_color(\n",
    "        lowcolor=low_color, highcolor=high_color,\n",
    "        intermed=((intermed - low_cutoff) / (high_cutoff - low_cutoff)),\n",
    "        colortype=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_gradients(model, min_grads, max_grads, ave_grads, basefn='', display_plot=0, save_plot=1):\n",
    "    \n",
    "    scale = plotly.colors.PLOTLY_SCALES[\"Bluered\"]\n",
    "\n",
    "    print(\"Number of gradients randomly sampled:\", len(ave_grads))  \n",
    "    \n",
    "    \n",
    "    # Assemble the names of the layers\n",
    "    layers = []\n",
    "    for n,p in model.named_parameters():\n",
    "        if (p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "    \n",
    "    # Dong this the dumb way just now\n",
    "    max_array = np.zeros(len(layers))\n",
    "    min_array = np.ones(len(layers))\n",
    "    mean_array = np.zeros(len(layers))\n",
    "    \n",
    "    for i in range(len(min_grads)):\n",
    "        for j in range(len(layers)):\n",
    "            if max_grads[i][j].item() > max_array[j]:\n",
    "                max_array[j] = max_grads[i][j].item()\n",
    "            \n",
    "            mean_array[j] += ave_grads[i][j].item()\n",
    "            \n",
    "            if min_grads[i][j].item() < min_array[j]:\n",
    "                min_array[j] = min_grads[i][j].item()\n",
    "                   \n",
    "    mean_array /= len(min_grads)\n",
    "    \n",
    "    print(len(layers))\n",
    "    print(len(min_grads))\n",
    "    print(len(max_grads))\n",
    "    print(len(ave_grads))    \n",
    "\n",
    "    print(min_array)\n",
    "    print(mean_array)\n",
    "    print(max_array)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    df = pd.DataFrame(\n",
    "#        {'mean': [0.1,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "#        'max': [0.3,0.5,0.6,0.9,1.1,1.3,1.6],\n",
    "#        'min': [0.0,0.2,0.4,0.3,0.5,0.2,0.3],\n",
    "        {'mean': mean_array,\n",
    "        'max': max_array,\n",
    "        'min': min_array,         \n",
    "        'labels': layers})\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df['labels'], y=df['min'],\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        line_color=get_continuous_color(scale, 0),\n",
    "        name=\"Min\",\n",
    "        line={'width': 4},\n",
    "        legendgroup=\"group1\"\n",
    "        ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['labels'],\n",
    "        y=df['mean'],\n",
    "        legendgroup=\"group2\",\n",
    "        fill='tonexty',\n",
    "        fillcolor=get_continuous_color(scale, 0.25).replace('rgb','rgba').replace(')',',0.5)'),\n",
    "        line_color=get_continuous_color(scale, 0.25),\n",
    "        mode='lines', name=\"Bottom Half\"))\n",
    "    fig.add_trace(go.Scatter(x=df['labels'], y=df['mean'],\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        legendgroup=\"group1\",\n",
    "        line={'width': 4},\n",
    "        line_color=get_continuous_color(scale, 0.5),\n",
    "        name=\"Mean\"))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['labels'],\n",
    "        y=df['max'],\n",
    "        legendgroup=\"group2\",\n",
    "        fill='tonexty',\n",
    "        fillcolor=get_continuous_color(scale, 0.75).replace('rgb','rgba').replace(')',',0.5)'),\n",
    "        line_color=get_continuous_color(scale, 0.75),\n",
    "        mode='lines',\n",
    "        name=\"Top Half\"))\n",
    "    fig.add_trace(go.Scatter(x=df['labels'], y=df['max'],\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        legendgroup=\"group1\",\n",
    "        line={'width': 4},\n",
    "        line_color=get_continuous_color(scale, 1),\n",
    "        name=\"Max\"\n",
    "        ))\n",
    "\n",
    "    if display_plot:\n",
    "        fig.show()\n",
    "        \n",
    "    if save_plot:\n",
    "        fig.write_html(basefn + 'gradients.html')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss and val_loss are lists containing the loss per step\n",
    "\n",
    "\n",
    "def plot_losses(train_loss, val_loss, title='Train / Validation Loss', basefn='', display_plot=0, save_plot=1):\n",
    "\n",
    "    iter = len(train_loss)\n",
    "    \n",
    "    # Plot the training / validation loss vs step\n",
    "    trace1 = {\n",
    "        'x': np.arange(0,len(train_loss)),\n",
    "        'y': np.array(train_loss),\n",
    "                  \n",
    "        'type': 'scatter',\n",
    "        'name': 'Training',\n",
    "        'showlegend': True\n",
    "    }\n",
    "\n",
    "    trace2 = {\n",
    "        'x': np.arange(0,len(val_loss)),\n",
    "        'y': np.array(val_loss),\n",
    "                  \n",
    "        'type': 'scatter',\n",
    "        'name': 'Validation',\n",
    "        'showlegend': True\n",
    "    }\n",
    "\n",
    "    data = [trace1, trace2]\n",
    "        \n",
    "    layout = go.Layout({\n",
    "        'title': {\n",
    "            'text': title,\n",
    "            'font': {\n",
    "                'size': 20\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    fig = go.Figure(data, layout)\n",
    "    \n",
    "    if display_plot:\n",
    "        fig.show()\n",
    "        \n",
    "    if save_plot:\n",
    "        fig.write_html(basefn + 'Train_losses.html')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_returns_hist(predicted_returns, actual_returns, title='Histogram: Predicted vs Actual Returns', basefn='', display_plot=0, save_plot=1):\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=predicted_returns, name='Predicted'))\n",
    "    fig.add_trace(go.Histogram(x=actual_returns, name='Actual'))\n",
    "    fig.update_layout(\n",
    "        title_text = title,\n",
    "        xaxis_title_text = 'Return',\n",
    "        yaxis_title_text = 'Count'\n",
    "    )\n",
    "    \n",
    "    if display_plot:\n",
    "        fig.show()\n",
    "    \n",
    "    if save_plot:\n",
    "        fig.write_html(basefn + 'Returns_hist.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hidden(h, basefn='', display_plot=0, save_plot=1):\n",
    "    \n",
    "    # h is a tuple containing 2 tensors (one for h, one for c). \n",
    "    # Each tensor is of dimension [num layers, batch size, hidden size]\n",
    "    # e.g. [3, 1, 128]\n",
    "        \n",
    "    titles = ['Hidden State', 'Cell State']\n",
    "    \n",
    "    x = np.arange(0, h[0].size()[2])\n",
    "        \n",
    "    # Loop through hidden and cell states\n",
    "    for state in range(2):\n",
    "        data = []\n",
    "        # Loop through each layer, add a trace for each\n",
    "        for layer in range(h[state].size()[0]):\n",
    "            h_tensor = h[state][layer][0].cpu()\n",
    "            trace = {\n",
    "                'x': x,                \n",
    "                'y': np.array(h_tensor.detach().numpy()),\n",
    "                  \n",
    "                'type': 'scatter',\n",
    "                'name': 'Layer '+str(layer),\n",
    "                'showlegend': True\n",
    "                }\n",
    "            data.append(trace)\n",
    "        \n",
    "        layout = go.Layout({\n",
    "            'title': {\n",
    "                'text': titles[state],\n",
    "                'font': {\n",
    "                    'size': 20\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "        fig = go.Figure(data, layout)\n",
    "        \n",
    "        if display_plot:\n",
    "            fig.show()\n",
    "        \n",
    "        if save_plot:\n",
    "            fig.write_html(basefn + 'Train_hidden_layer_snapshot.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lstm_output(lstm_output, basefn='', display_plot=0, save_plot=1):\n",
    "    \n",
    "    # lstm_output is a tuple containing [sequence length] number of tensors.\n",
    "    # Each tensor is the lstm output with dimensions [batch size, hidden size]\n",
    "    # e.g. [1, 128]\n",
    "    \n",
    "    x = np.arange(0, lstm_output.size()[1])\n",
    "        \n",
    "    data = []\n",
    "    \n",
    "    # Loop through each layer, add a trace for each\n",
    "    for i in range(len(lstm_output)):\n",
    "        lstm_tensor = lstm_output[i].cpu()\n",
    "        trace = {\n",
    "            'x': x,\n",
    "            'y': np.array(lstm_tensor.detach().numpy()),\n",
    "                  \n",
    "            'type': 'scatter',\n",
    "            'name': 'Cell '+str(i),\n",
    "            'showlegend': True\n",
    "            }\n",
    "        data.append(trace)\n",
    "        \n",
    "    layout = go.Layout({\n",
    "        'title': {\n",
    "            'text': 'LSTM Output',\n",
    "            'font': {\n",
    "                'size': 20\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    fig = go.Figure(data, layout)\n",
    "    \n",
    "    if display_plot:\n",
    "        fig.show()   \n",
    "        \n",
    "    if save_plot:\n",
    "        fig.write_html(basefn + 'Train_LSTM_output_snapshot.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(model, basefn='', display_plot=0, save_plot=1):\n",
    "    \n",
    "    # Plot the linear weights - just a simple line chart\n",
    "    linear_tensor = model.linear.weight[0].cpu()\n",
    "    x = np.arange(0, len(model.linear.weight[0]))\n",
    "    y = np.array(linear_tensor.detach().numpy())\n",
    "  \n",
    "    # Plot the training / validation loss vs step\n",
    "    trace1 = {\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "                  \n",
    "        'type': 'scatter',\n",
    "        'name': 'Linear Weights',\n",
    "        'showlegend': True\n",
    "    }\n",
    "\n",
    "    data = [trace1]\n",
    "        \n",
    "    layout = go.Layout({\n",
    "        'title': {\n",
    "            'text': 'Linear Weights',\n",
    "            'font': {\n",
    "                'size': 20\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    fig = go.Figure(data, layout)\n",
    "    \n",
    "    if display_plot:\n",
    "        fig.show()\n",
    "        \n",
    "    if save_plot:\n",
    "        fig.write_html(basefn + 'Train_linear_weights.html')\n",
    "    \n",
    "    ave_weights = []\n",
    "    max_weights = []\n",
    "    layers = []\n",
    "    for n,p in model.named_parameters():\n",
    "        if (p.requires_grad) and (\"bias\" not in n) and (\"linear\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_weights.append(p.abs().mean().item())\n",
    "            max_weights.append(p.abs().max().item())\n",
    "\n",
    "    trace1 = {\n",
    "        'x' : layers,\n",
    "        'y' : ave_weights,\n",
    "        'type' : 'bar'\n",
    "    }    \n",
    "\n",
    "    data = [trace1]\n",
    "    layout = go.Layout({\n",
    "        'title': {\n",
    "            'text': 'Average of LSTM Weights',\n",
    "            'font': {\n",
    "                'size': 20\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    fig = go.Figure(data, layout)\n",
    "\n",
    "    if display_plot:\n",
    "        fig.show()\n",
    "        \n",
    "    if save_plot:\n",
    "        fig.write_html(basefn + 'Train_ave_lstm_weights.html')\n",
    "    \n",
    "    \n",
    "    trace1 = {\n",
    "        'x' : layers,\n",
    "        'y' : max_weights,\n",
    "        'type' : 'bar'\n",
    "    }    \n",
    "\n",
    "    data = [trace1]\n",
    "    layout = go.Layout({\n",
    "        'title': {\n",
    "            'text': 'MAX of LSTM Weights',\n",
    "            'font': {\n",
    "                'size': 20\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    fig = go.Figure(data, layout)\n",
    "    \n",
    "    if display_plot:\n",
    "        fig.show()\n",
    "        \n",
    "    if save_plot:\n",
    "        fig.write_html(basefn + 'Train_max_lstm_weights.html')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_plot(layer_names, grads, color, title, basefn='', display_plot=0, save_plot=1):\n",
    "       \n",
    "    for i in range(len(grads)):\n",
    "        plt.plot(grads[i], alpha=0.3, color=color)\n",
    "    \n",
    "    plt.hlines(0, 0, len(grads)+1, linewidth=1, color=\"k\")\n",
    "    plt.xticks(range(0,len(grads[0]),1), layer_names, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(grads[0]))\n",
    "    \n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"Gradient\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "           \n",
    "    # This has to go before the plt.show() otherwise it's blank\n",
    "    if save_plot:\n",
    "        plt.savefig(basefn + title + '.png', bbox_inches='tight')\n",
    "\n",
    "    if display_plot:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradients(model, ave_grads, max_grads, basefn='', display_plot=0, save_plot=1):\n",
    "\n",
    "    print(\"Number of gradients randomly sampled:\", len(ave_grads))    \n",
    "    \n",
    "    # Assemble the names of the layers\n",
    "    layers = []\n",
    "    for n,p in model.named_parameters():\n",
    "        if (p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "\n",
    "    gradient_plot(layers, ave_grads, 'b', 'Gradient Flow - All Layers - Average', basefn=basefn, display_plot=display_plot, save_plot=save_plot)\n",
    "    gradient_plot(layers, max_grads, 'r', 'Gradient Flow - All Layers - Max', basefn=basefn, display_plot=display_plot, save_plot=save_plot)\n",
    "        \n",
    "    ave_grads_lstm = [sublist[:len(layers)-1] for sublist in ave_grads]\n",
    "    max_grads_lstm = [sublist[:len(layers)-1] for sublist in max_grads]\n",
    "    layers_lstm = layers[0:len(layers)-1]\n",
    "    \n",
    "    gradient_plot(layers_lstm, ave_grads_lstm, 'b', 'Gradient Flow - LSTM Layers - Average', basefn=basefn, display_plot=display_plot, save_plot=save_plot)\n",
    "    gradient_plot(layers_lstm, max_grads_lstm, 'r', 'Gradient Flow - LSTM Layers - Max', basefn=basefn, display_plot=display_plot, save_plot=save_plot)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeilLSTM(nn.Module):\n",
    "    def __init__(self, input_size = 6, window_size = 11, arch = 'LH', hidden_size = 64, output_size = 1, num_layers = 3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store some stuff we need to know in the forward pass\n",
    "        self.n_layers = num_layers        \n",
    "        self.hidden_layer_size = hidden_size\n",
    "        self.arch = arch\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=False, bias=True, dropout=dropout, bidirectional=False)\n",
    "                \n",
    "        # Define the linear layer\n",
    "        # Perhaps should perform forward on the lstm to explicitly get the size of the \n",
    "        # tensor for sequence to one vs sequence to sequence versions.\n",
    "        \n",
    "        # The size of the linear layer for LH or AH model\n",
    "        if arch == 'LH':\n",
    "            self.linear = nn.Linear(hidden_size, output_size, bias = True)\n",
    "        elif arch == 'AH':\n",
    "            self.linear = nn.Linear(hidden_size * window_size, output_size, bias = True)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "        \n",
    "        # NEED TO FIX THIS STUPID HARD CODED INIT\n",
    "        if num_layers >= 1:\n",
    "            torch.nn.init.xavier_uniform_(self.lstm.weight_hh_l0)\n",
    "            torch.nn.init.xavier_uniform_(self.lstm.weight_ih_l0)\n",
    "            \n",
    "        if num_layers >= 2:\n",
    "            torch.nn.init.xavier_uniform_(self.lstm.weight_hh_l1)        \n",
    "            torch.nn.init.xavier_uniform_(self.lstm.weight_ih_l1)                    \n",
    "        \n",
    "        if num_layers >= 3:\n",
    "            torch.nn.init.xavier_uniform_(self.lstm.weight_hh_l2)                        \n",
    "            torch.nn.init.xavier_uniform_(self.lstm.weight_ih_l2)                        \n",
    "        \n",
    "        \n",
    "    # Forward pass\n",
    "    # input_seq shape is: (sequence length, num input features) - there's no batch dimension\n",
    "    def forward(self, input_seq, hidden, verbose=0):\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\\nlstm input:\\n\", input_seq)\n",
    "            print(\"\\n\\nlstm input view:\\n\", input_seq.view( len(input_seq) , 1 , -1))\n",
    "            print(\"\\n\\nlstm hidden input:\\n\", hidden)\n",
    "            \n",
    "        lstm_out, hidden = self.lstm( input_seq.view( len(input_seq) , 1 , -1), hidden)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n\\nlstm_output:\\n\", lstm_out)\n",
    "            print(\"\\n\\nhidden output:\\n\", hidden)\n",
    "                    \n",
    "        # Feed forward the outputs of the lstm into the linear layer       \n",
    "        # lstm_out dims are (seq_len, batch, hidden dim)\n",
    "        # This is converted to (seq_len, hidden_dim) before input to the linear layer        \n",
    "        # When T=22 and hidden_layer_size=64, the shape of the lstm_out tensor is [22,1,64]    \n",
    "        # This view reshapes it to [22, 64]\n",
    "        lstm_out_view = lstm_out.view(len(input_seq), -1)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n\\nlstm_out_view:\\n\", lstm_out_view)\n",
    "                                       \n",
    "        if verbose:\n",
    "            print(\"\\n\\nLinear weights:\\n\", self.linear.weight)\n",
    "            print(\"\\n\\ninput to fc:\\n\", lstm_out_view[-1])\n",
    "        \n",
    "        # LH - Just present the last hidden state to the linear network            \n",
    "        if self.arch == 'LH':\n",
    "            predictions = self.linear(lstm_out_view[-1])\n",
    "        # AH - flatten and present all to linear network\n",
    "        elif self.arch == 'AH':\n",
    "            predictions = self.linear(torch.flatten(lstm_out_view))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n\\npredictions:\\n\",predictions)\n",
    "        \n",
    "        # predictions has dimension: (1, seq_len)        \n",
    "        return predictions, hidden, lstm_out_view\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size = 1):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_layer_size).zero_().to(device),\n",
    "                 weight.new(self.n_layers, batch_size, self.hidden_layer_size).zero_().to(device))\n",
    "        return(hidden)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the given LSTM model. Also collects validation data (predicting the next day) and collects stats\n",
    "# for both.  These are used to observe training vs validation but also to construct the first allocation policy.\n",
    "\n",
    "# Q version has removed inner loop instrumentation and made other spped changes\n",
    "# This version runs about 20% faster than the non-Q version\n",
    "\n",
    "def train_modelQ(model, train_seq, train_labels, scale=1, offset=1, train_start=0, train_length=1, epochs = 20, iter_per_seq=1, max_iter=1600, lr = 0.001, dr=0.999, wd=0.0, verbosity=0, basefn='',percentiles=[0,10,20,30,40,50,60], trading_validation_period=100, valid_seq=[], valid_labels=[], plot=0):\n",
    "    input_size = 6\n",
    "    \n",
    "    \n",
    "    # if plot level is 4, plot graphs on screen for every inner loop training run\n",
    "    if plot == 4:\n",
    "        dump_log_interval = 1\n",
    "    else:\n",
    "        dump_log_interval = 10 # otherwise do it every 10\n",
    "        \n",
    "    loss_function = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = wd)\n",
    "    my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer = optimizer, gamma = dr)\n",
    "    \n",
    "    batch_size = 1  # batch mode isn't used actually but including for future possible use\n",
    "    \n",
    "    with open(basefn + 'train.csv', 'a', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Epc','AvTrLoss','AvTrMSE','AvValMSE','MdnTrMSE','MdnValMSE','ValMDA','ValMAPE','ValMAE','PXcorr','RXcorr',\n",
    "                     'EpcSecs','TtlMins'])\n",
    "        \n",
    "    with open(basefn + 'trade_validation.csv', 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Epoch','MDA','MSE','MAE','MAPE','X-Correl','Num-trades','AveRt%','MdnRT%','MinRt%','MaxRt%',\n",
    "                    'RangeRt%','StdDevRt%'])\n",
    "            \n",
    "    # Outputs a summary line for each Epoch\n",
    "    if verbosity == 1:\n",
    "        print('Epc  AvTrLoss  AvTrMSE   AvValMSE  MdnTrMSE  MdnValMSE  ValMDA    ValMAPE  ValMAE    PXcorr  RXcorr Secs    TTlMins')\n",
    "\n",
    "    # Outputs a summary line for each sequence in each epoch\n",
    "    if verbosity == 2:\n",
    "        print('EPc  Seq#   TrLoss    TrMSE     PredR   ActRt   ValLoss   VAdjC    VPred   VAct      VPredRt   VActRt   RunMDA')            \n",
    "                            \n",
    "    \n",
    "#    train_losses = []\n",
    "#    val_adj_close_price = []\n",
    "    ave_grads = []\n",
    "    max_grads = []\n",
    "    min_grads = []\n",
    "    \n",
    "    # If the number of epochs is high, just sample the gradients stochastically to avoid retaining too much\n",
    "    # data.\n",
    "    if (epochs * train_length) > 1000:\n",
    "        sample_grads = 1000.0 / (epochs * train_length)\n",
    "    else:\n",
    "        sample_grads = 1.0\n",
    "\n",
    "    start_time = time.time()       \n",
    "    \n",
    "    train_seq_cuda = train_seq.to(device)\n",
    "    train_labels_cuda = train_labels.to(device)\n",
    "\n",
    "    # How many times through the entire training set\n",
    "    for i in range(epochs):\n",
    "        train_losses = []\n",
    "        val_adj_close_price = []        \n",
    "        train_mses = []\n",
    "        val_mses = []\n",
    "        val_pred_rt = []\n",
    "        val_act_rt = []\n",
    "        val_pred_price = []\n",
    "        val_act_price = []        \n",
    "        running_mda = 0\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # Each sample in the training set\n",
    "        for j in range(train_start, train_start + train_length):      \n",
    "                        \n",
    "            inputs = train_seq_cuda[j]\n",
    "            labels = train_labels_cuda[j]\n",
    "            \n",
    "            # How many times we train on each sample as we go\n",
    "            for iter in range(iter_per_seq):\n",
    "                # Initialise hidden states before every training event\n",
    "                h = model.init_hidden(batch_size)  \n",
    "                                    \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                y_pred, h, lstm_out = model(inputs, h)\n",
    "            \n",
    "                # y_pred and labels are both size T - sequence to sequence loss function\n",
    "                train_loss = loss_function(y_pred, labels)\n",
    "            \n",
    "                # Compute gradients and update the model\n",
    "                train_loss.backward()\n",
    "                                \n",
    "                optimizer.step()\n",
    "                \n",
    "            # For speed, we only do outer loop validation at the same time we do trading validation (the stats are\n",
    "            # needed to compute the initial allocation policy)\n",
    "            \n",
    "            if i % trading_validation_period == 0:\n",
    "                # Sample stochastically the last set of gradients after the inner loop for plotting later\n",
    "                if plot and (random.random() < sample_grads):\n",
    "                    ave_grad=[]\n",
    "                    max_grad=[]\n",
    "                    min_grad=[]\n",
    "                    for n,p in model.named_parameters():\n",
    "                        if (p.requires_grad) and (\"bias\" not in n):\n",
    "                            ave_grad.append(p.grad.abs().mean())\n",
    "                            max_grad.append(p.grad.abs().max())\n",
    "                            min_grad.append(p.grad.abs().min())\n",
    "                    ave_grads.append(ave_grad)\n",
    "                    max_grads.append(max_grad)\n",
    "                    min_grads.append(min_grad)            \n",
    "            \n",
    "                # Capture the (snapshot) metrics from the last inner loop cycle\n",
    "                training_loss = train_loss.item()  # This is the sequence to sequence training loss                        \n",
    "                train_adj_close = inputs[-1][-1].item()   # Adj close at t=0\n",
    "                train_pred = y_pred[-1].item()  # Next day predicted Adj close\n",
    "                train_truth = labels[-1].item()  # Next day actual Adj close\n",
    "                train_mse = (train_pred - train_truth)**2   # MSE of just the predicted value vs truth\n",
    "                train_predicted_return = (denormalise_value(train_pred, scale, offset) / denormalise_value(train_adj_close, scale, offset)) - 1            \n",
    "                train_actual_return = (denormalise_value(train_truth, scale, offset) / denormalise_value(train_adj_close, scale, offset)) - 1\n",
    "\n",
    "                # Outer loop validation every trading_validation_period epochs\n",
    "                model.eval()\n",
    "            \n",
    "                inputs = train_seq[j+1].to(device)\n",
    "                labels = train_labels[j+1].to(device)\n",
    "            \n",
    "                with torch.no_grad():\n",
    "                    h = model.init_hidden(batch_size)\n",
    "        \n",
    "                    y_pred, h, lstm_out = model(inputs, h)\n",
    "                    \n",
    "                    valid_adj_close = inputs[-1][-1].item()                \n",
    "                    valid_pred = y_pred[-1].item()\n",
    "                    valid_truth = labels[-1].item()\n",
    "                    valid_loss = (valid_pred - valid_truth)**2  # Just the mse of the valid predicted value vs truth\n",
    "            \n",
    "                    valid_predicted_return = (denormalise_value(valid_pred, scale, offset) / denormalise_value(valid_adj_close, scale, offset)) - 1\n",
    "                    valid_actual_return = (denormalise_value(valid_truth, scale, offset) / denormalise_value(valid_adj_close, scale, offset)) - 1\n",
    "\n",
    "                    if (valid_predicted_return * valid_actual_return >= 0):\n",
    "                        running_mda += 1                \n",
    "                \n",
    "                    # If enabled, print results line at the end of inner loop training on each sequence\n",
    "                    if (verbosity==2):\n",
    "                        print('{:4}'.format(i),\n",
    "                            '{:4}'.format(j), \n",
    "                          '  {:1.1e}'.format(training_loss),\n",
    "                          '  {:1.1e}'.format(train_mse),\n",
    "                          ' {: 2.3f}'.format(100.0*train_predicted_return), \n",
    "                          ' {: 2.3f}'.format(100.0*train_actual_return),\n",
    "                          '  {:1.1e}'.format(valid_loss), \n",
    "                          ' {: 1.4f}'.format(valid_adj_close), \n",
    "                          ' {: 1.4f}'.format(valid_pred), \n",
    "                          ' {: 1.4f}'.format(valid_truth),\n",
    "                          ' {: 2.4f}'.format(100.0*valid_predicted_return), \n",
    "                          ' {: 2.4f}'.format(100.0*valid_actual_return),\n",
    "                          '  {:2.2f}'.format(100.0*running_mda/(j+1)))\n",
    "                    \n",
    "                    # Keep lists of the results of train / validation for each sequence for passing back up the stack\n",
    "                    train_losses.append(training_loss)\n",
    "                    train_mses.append(train_mse)\n",
    "                    val_mses.append(valid_loss)\n",
    "                    val_pred_rt.append(valid_predicted_return)\n",
    "                    val_act_rt.append(valid_actual_return)\n",
    "                    val_pred_price.append(valid_pred)\n",
    "                    val_act_price.append(valid_truth)\n",
    "                    val_adj_close_price.append(valid_adj_close)\n",
    "                    \n",
    "                model.train()\n",
    "                \n",
    "            # End of outer loop\n",
    "            \n",
    "        my_lr_scheduler.step()            \n",
    "           \n",
    "        elapsed_secs = time.time()-start_time\n",
    "        print(i, time.time()-epoch_start_time, elapsed_secs, optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        if i % trading_validation_period == 0:\n",
    "            # We report stats on the last portion of the training\n",
    "            stats_len = int(0.5 * len(train_losses))\n",
    "            \n",
    "            metrics_dict = compute_metrics(np.array(val_pred_rt[-stats_len:]),\n",
    "                                   np.array(val_act_rt[-stats_len:]),\n",
    "                                   np.array(val_pred_price[-stats_len:]),\n",
    "                                   np.array(val_act_price[-stats_len:]))\n",
    "\n",
    "            # This is the results we'll pass back up the stack for the entire training\n",
    "            result_dict = {'trStats_N':stats_len, 'AvTrLoss':np.mean(train_losses[-stats_len:]),\n",
    "                   'trAvTrMSE':np.mean(train_mses[-stats_len:]),\n",
    "                   'trAvValMSE':np.mean(val_mses[-stats_len:]),\n",
    "                   'trMdnTrMSE':np.median(train_mses[-stats_len:]),\n",
    "                   'trMdnValMSE':np.median(val_mses[-stats_len:]),\n",
    "                   'train_mses':train_mses, 'valid_mses':val_mses, 'val_pred_rt':val_pred_rt, 'val_act_rt':val_act_rt, \n",
    "                   'val_pred_price':val_pred_price, 'val_act_price':val_act_price, \n",
    "                   'val_adj_close_price': val_adj_close_price,\n",
    "                    'trMDA': metrics_dict['MDA'],\n",
    "                    'trMAPE': metrics_dict['MAPE'],\n",
    "                    'trMAE': metrics_dict['MAE'],\n",
    "                    'trPXCORR': metrics_dict['PXCORR'],\n",
    "                    'trRXCORR': metrics_dict['RXCORR'],\n",
    "                    'epoch_train_time':time.time()-epoch_start_time,\n",
    "                   'train_time':elapsed_secs}\n",
    "        \n",
    "            # Output summary stats at end of outer loop training  \n",
    "            if (verbosity == 1):\n",
    "                print('{:4}'.format(i),'{:4.2e}'.format(result_dict['AvTrLoss']),\n",
    "                          ' {:1.2e}'.format(result_dict['trAvTrMSE']),\n",
    "                          ' {:4.2e}'.format(result_dict['trAvValMSE']), \n",
    "                          ' {:1.2e}'.format(result_dict['trMdnTrMSE']),\n",
    "                          ' {:4.2e}'.format(result_dict['trMdnValMSE']),                  \n",
    "                          '  {:2.2f}'.format(result_dict['trMDA']), \n",
    "                          '    {:2.2f}'.format(result_dict['trMAPE']), \n",
    "                          '    {:2.2e}'.format(result_dict['trMAE']),\n",
    "                          '{: 1.2f}'.format(result_dict['trPXCORR']), \n",
    "                          '  {: 1.2f}'.format(result_dict['trRXCORR']),      \n",
    "                          '  {:2.2f}'.format(result_dict['epoch_train_time']),                  \n",
    "                          '  {:3.1f}'.format(result_dict['train_time']/60.0))\n",
    "            \n",
    "            with open(basefn + 'train.csv', 'a', newline='') as myfile:\n",
    "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow([i, result_dict['AvTrLoss'],\n",
    "                        result_dict['trAvTrMSE'],\n",
    "                        result_dict['trAvValMSE'],\n",
    "                        result_dict['trMdnTrMSE'],\n",
    "                        result_dict['trMdnValMSE'],\n",
    "                        result_dict['trMDA'],\n",
    "                        result_dict['trMAPE'],\n",
    "                        result_dict['trMAE'],\n",
    "                        result_dict['trPXCORR'],\n",
    "                        result_dict['trRXCORR'],\n",
    "                        result_dict['epoch_train_time'],\n",
    "                        result_dict['train_time']/60.0,\n",
    "                        ])\n",
    "        \n",
    "        # Periodically perform a trading validation \n",
    "        if i % trading_validation_period == 0:\n",
    "            \n",
    "            # Make a results directory. If the 'directory' doesn't exist, create it\n",
    "            if os.path.isdir(basefn + '/saved_models') == False:\n",
    "                os.mkdir(basefn + '/saved_models')\n",
    "            \n",
    "            D,Q,E,A,C = generate_initial_allocation_policy(result_dict, percentiles=percentiles, scale=scale, offset=offset, basefn=basefn + 'saved_models/'+str(i), verbosity=0)\n",
    "            \n",
    "            # Save both the model and the initial allocation policy so we can recreate for validation / test after training\n",
    "            # (pick the best model out of a complete training run after analysing the data)\n",
    "                        \n",
    "            torch.save(model,basefn + '/saved_models/epoch' + str(i) + '.mdl')\n",
    "            \n",
    "            with open(basefn + '/saved_models/DQEAC_dict' + str(i) + '.pkl','wb') as fp:\n",
    "                pickle.dump({'D':D, 'Q':Q, 'E':E, 'A':A, 'C':C}, fp, protocol=pickle.HIGHEST_PROTOCOL)            \n",
    "\n",
    "            # Note - prior to version 15, I wasn't deep copying the D,Q,E,A which means they would have been being updated\n",
    "            # by trading validation.\n",
    "            trial_results = []\n",
    "            for trial in range(5):\n",
    "                # For each trial make a deep copy of things that get modified by the validation process. Make sure that \n",
    "                # the model being trained and the allocation policy components are not being modified and we always start\n",
    "                # validation from the same starting point.\n",
    "                validation_model = copy.deepcopy(model)\n",
    "                copy_D = copy.deepcopy(D)\n",
    "                copy_Q = copy.deepcopy(Q)\n",
    "                copy_E = copy.deepcopy(E)\n",
    "                copy_A = copy.deepcopy(A)\n",
    "                \n",
    "                validation_model, copy_D, copy_Q, copy_E, copy_A, journal, test_result_dict = test_trading_system(validation_model, valid_seq, valid_labels, copy_D, copy_Q, copy_E, copy_A, percentiles, basefn=basefn+'/saved_models/'+str(i)+'_'+str(trial), scale=scale, offset=offset, iter_per_seq=iter_per_seq, lr = 0.001, dr = 1, verbosity=0)\n",
    "                \n",
    "                trial_results.append(test_result_dict)                \n",
    "\n",
    "            \n",
    "            mean_trial_MDA = np.mean([v['MDA'] for v in trial_results])\n",
    "            mean_trial_MSE = np.mean([v['MSE'] for v in trial_results])\n",
    "            mean_trial_MAE = np.mean([v['MAE'] for v in trial_results])\n",
    "            mean_trial_MAPE = np.mean([v['MAPE'] for v in trial_results])\n",
    "            mean_trial_RXCORR = np.mean([v['RXCORR'] for v in trial_results])\n",
    "            mean_trial_num_trades = np.mean([v['num_trades'] for v in trial_results])\n",
    "            trial_returns = [v['trade_return'] for v in trial_results]\n",
    "            mean_trial_trade_return = np.mean(trial_returns)\n",
    "            median_trial_trade_return = np.median(trial_returns)\n",
    "            min_trial_trade_return = np.min(trial_returns)\n",
    "            max_trial_trade_return = np.max(trial_returns)\n",
    "            range_trial_trade_return = max_trial_trade_return - min_trial_trade_return\n",
    "            std_trial_trade_return = np.std(trial_returns)\n",
    "            \n",
    "            print('Trading Validation - ',\n",
    "                'MDA:{:2.2f}'.format(mean_trial_MDA),\n",
    "                '  Returns Correl:{:2.2f}'.format(mean_trial_RXCORR),\n",
    "                '  Num Trades:{:4}'.format(mean_trial_num_trades),\n",
    "                '  Return%:{:2.2f}'.format(mean_trial_trade_return))\n",
    "            \n",
    "            with open(basefn + 'trade_validation.csv', 'a', newline='') as myfile:\n",
    "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow([i,mean_trial_MDA, mean_trial_MSE,\n",
    "                            mean_trial_MAE, mean_trial_MAPE,\n",
    "                            mean_trial_RXCORR, mean_trial_num_trades, \n",
    "                            mean_trial_trade_return, median_trial_trade_return,\n",
    "                            min_trial_trade_return, max_trial_trade_return,\n",
    "                            range_trial_trade_return, std_trial_trade_return])\n",
    "\n",
    "    if plot>=1:\n",
    "        plot_gradients(model, ave_grads, max_grads, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plotly_gradients(model, min_grads, max_grads, ave_grads, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_hidden(h, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_lstm_output(lstm_out, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_weights(model, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_losses(train_mses, val_mses, title='Model Training: Training Loss vs Validation Loss', basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_returns_hist(val_pred_rt, val_act_rt, title='Model Training: Predicted vs Actual Returns', basefn=basefn+'both_', display_plot=plot, save_plot=1)\n",
    "        plot_returns_hist(val_pred_rt, val_pred_rt, title='Model Training: Predicted Returns', basefn=basefn+'pred_', display_plot=plot, save_plot=1)\n",
    "        plot_returns_hist(val_act_rt, val_act_rt, title='Model Training: Actual Returns', basefn=basefn+'act_', display_plot=plot, save_plot=1)    \n",
    "            \n",
    "    return model, result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a model instance and trains it on the training set\n",
    "\n",
    "def create_train_model(df, resume_dir='', resume_epoch=-1, basefn='', scale=1, offset=1, arch='LH', window_size = 22, epochs=20, iter_per_seq=1, max_iter=1600, num_layers=2, hidden_size=64, dropout=0.5, lr=0.001, dr=1, wd=0.0, percentiles=[0,10,20,30,40,50,60], trading_validation_period = 100, valid_seq=[], valid_labels=[], verbosity=0, plot=0):\n",
    "\n",
    "    # Generate training set\n",
    "    train_seq, train_labels = create_input_sequences_from_df(df, window_size)\n",
    "\n",
    "    # Convert our list of lists to Tensors\n",
    "    train_seq = torch.FloatTensor(train_seq)\n",
    "    train_labels = torch.FloatTensor(train_labels)\n",
    "       \n",
    "    if verbosity>=1:\n",
    "        print(\"Building LSTM Model with the following parameters:\")\n",
    "        print(\"Architecture:\", arch)\n",
    "        print(\"Num layers:\", num_layers)\n",
    "        print(\"Hidden size:\", hidden_size)\n",
    "        print(\"Dropout:\", dropout)\n",
    "        print(\"Learning Rate:\", lr)\n",
    "        print(\"LR Decay Rate:\", dr)\n",
    "        print(\"Weight Decay:\", wd)\n",
    "        print(\"Window size:\", window_size)\n",
    "        print(\"Num Epochs:\", epochs)                \n",
    "        print(\"Iterations per seq:\", iter_per_seq)\n",
    "        print(\"Start training...\")\n",
    "\n",
    "           \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # If we are starting from scratch, create a brand new model\n",
    "    if resume_dir=='':\n",
    "        model = NeilLSTM(input_size=6, window_size=window_size, arch=arch, hidden_size=hidden_size, output_size=window_size, num_layers=num_layers, dropout=dropout)\n",
    "        last = 'NONE'\n",
    "    else: # Otherwise, load it from disk\n",
    "        # Special case, load the last model in directory\n",
    "        if resume_epoch == -1:\n",
    "            files = glob.glob(resume_dir + '/saved_models/*.mdl')\n",
    "            last = max(files, key=os.path.getctime)\n",
    "            model = torch.load(last)\n",
    "            if verbosity >= 1:\n",
    "                print(\"Loaded existing model:\", last)\n",
    "\n",
    "# Dump the model configuration and results to log file\n",
    "    with open(basefn + 'train.csv', 'w', newline='') as myfile:\n",
    "        \n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Norm Scale:', scale])\n",
    "        wr.writerow(['Norm Offset:', offset])\n",
    "        wr.writerow(['Arch:', arch])\n",
    "        wr.writerow(['Window Size:', window_size])\n",
    "        wr.writerow(['Hidden Size:', hidden_size])\n",
    "        wr.writerow(['Num Layers:', num_layers])        \n",
    "        wr.writerow(['Dropout:', dropout])                \n",
    "        wr.writerow(['Learning Rate:', lr]) \n",
    "        wr.writerow(['LR Decay Rate:', dr])\n",
    "        wr.writerow(['Weight Decay:', wd])        \n",
    "        wr.writerow(['Num Epochs:', epochs])\n",
    "        wr.writerow(['Iterations Per Sequence:', iter_per_seq])\n",
    "        wr.writerow(['Start Epoch:', resume_epoch])\n",
    "        wr.writerow(['Resume-from model path:', last])\n",
    "        wr.writerow(['Training Start Date:', df['Date'].iloc[0]])\n",
    "        wr.writerow(['Training End Date:', df['Date'].iloc[-1]])                    \n",
    "                \n",
    "    model.to(device)\n",
    "\n",
    "    # Stop one short of the end as we use the t+1 for validation during training\n",
    "    model, result_dict = train_modelQ(model, train_seq, train_labels, scale=scale, offset=offset, train_start=0, \n",
    "                                     train_length=len(train_seq)-1, epochs=epochs, iter_per_seq=iter_per_seq, \n",
    "                                     max_iter=max_iter, lr=lr, dr=dr, wd=wd, verbosity=verbosity, basefn=basefn, \n",
    "                                     plot=plot, trading_validation_period=trading_validation_period, \n",
    "                                     percentiles=percentiles, valid_seq=valid_seq, valid_labels=valid_labels)\n",
    "        \n",
    "    # Save the model with the unique filename\n",
    "    torch.save(model,basefn + '_train.mdl')\n",
    "    \n",
    "    return model, result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm_xcorrel(a, b):\n",
    "    c = np.corrcoef(a, b)\n",
    "\n",
    "    return c[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the interim metrics per the paper table 8 - MDA, MAPE, MAE, MSE\n",
    "# Also added cross-correlation\n",
    "\n",
    "# Pass in lists of next day predicted and actual returns, predicted and actual prices\n",
    "def compute_metrics(pred_rt, act_rt, pred_price, act_price):\n",
    "    \n",
    "    len_data = len(pred_rt)\n",
    "\n",
    "    product = pred_rt * act_rt\n",
    "    abs_price_diff = np.abs(act_price - pred_price)\n",
    "    \n",
    "    MDA = 100 * len(np.where(product > 0)[0]) / len_data\n",
    "    MAPE = 100 * np.sum(abs_price_diff / np.abs(act_price)) / len_data\n",
    "    MAE = np.sum(abs_price_diff) / len_data\n",
    "    MSE = np.sum(abs_price_diff ** 2) / len_data\n",
    "    \n",
    "    price_xcorrel = compute_norm_xcorrel(pred_price, act_price)\n",
    "    returns_xcorrel = compute_norm_xcorrel(pred_rt, act_rt)\n",
    "    \n",
    "    metrics_dict = {'N':len_data, 'MDA':MDA, 'MAPE': MAPE, 'MAE': MAE, 'MSE':MSE, 'PXCORR':price_xcorrel, \n",
    "                    'RXCORR':returns_xcorrel}\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call this routine whenever a new predicted return is generated (each new day)\n",
    "\n",
    "# inputs:\n",
    "# D - a list of all the predicted returns, by trading day, to date\n",
    "# Q - a list of the bin cut-offs\n",
    "# new_pred_return - the new predicted return from the model\n",
    "# percentiles - a list of percentiles used to determine the bins (e.g. [0,10,20,30,40,50,60])\n",
    "\n",
    "# returns:\n",
    "# D - Updated\n",
    "# Q - updated\n",
    "\n",
    "def update_DQ(D, Q, new_pred_return, percentiles):\n",
    "\n",
    "    # Append the new predicted return to the existing list\n",
    "    D = np.append(D,new_pred_return)\n",
    "    \n",
    "    # If the predicted return is negative, it won't affect the binning calculation\n",
    "#    if new_pred_return <= 0:\n",
    "#        return D, Q\n",
    "    \n",
    "    # Percentile the positive returns\n",
    "    returns = np.array(D)\n",
    "#    Q = np.percentile(returns[returns >= 0], percentiles)\n",
    "    Q = np.percentile(abs(returns), percentiles)\n",
    "    \n",
    "    # Q now contains the cutoff values for each bin.  Each bin will contain approximately 10% of the positive\n",
    "    # returns except the last one which is an amalgamation of 4 bins so it will contain approx 40%\n",
    "        \n",
    "    # return updated D and Q\n",
    "    return D, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call this routine whenever a new sell is executed (and therefore we have a new expected value for a bin)\n",
    "\n",
    "def update_EA(E, A, profit, purchase_bin):\n",
    "\n",
    "    # Append the new profit amount to the correct bin in E        \n",
    "    E[purchase_bin] = E[purchase_bin] + profit\n",
    "    \n",
    "    # Update A - bins with positive total profits are set to 1 (a buy signal)\n",
    "    # bins with negative profits are set to 0 - a do nothing signal\n",
    "    # bin 0 is the unique, sell signal\n",
    "    A = (E > 0).astype(int)    \n",
    "    \n",
    "    return E, A\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function combines model training (updates), predicting next day return, trading and updating the trading\n",
    "# policy each day.\n",
    "# Much of the code is a repeat / combo of the above two seperate routines of training the model and \n",
    "# genertaing the policy. This is different as we are now \"live\" and updating the model / policy only on\n",
    "# previously unseen data.\n",
    "# Also, although the model is using Adj Close as the label for training, what we need to record for evaluation\n",
    "# is the Open price for purchases and sales (assuming we are running the model overnight between two trade\n",
    "# days).The model updates and issues trades which will be filled at the next trading day open.\n",
    "\n",
    "# predictor can be \"pytorch_lstm\", \"random\", \"prescient\", \"drunk_genius\"\n",
    "\n",
    "def test_trading_system(model, test_seq, test_labels, D, Q, E, A, percentiles, predictor=\"pytorch_lstm\", drunk_genius_accuracy=0.5, basefn='', scale=1, offset=1, iter_per_seq=1, lr = 0.001, dr = 1, verbosity=0):\n",
    "    input_size = 6\n",
    "        \n",
    "    print(basefn)\n",
    "    \n",
    "    loss_function = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer = optimizer, gamma = dr)\n",
    "    \n",
    "    batch_size = 1  # batch mode isn't used actually but including for future possible use\n",
    "            \n",
    "    holding = False;\n",
    "    journal = []   \n",
    "    total_profit_open = 0\n",
    "    total_profit_adj_close = 0\n",
    "    C = np.zeros(shape=(len(E)))\n",
    "    \n",
    "    # Keep list of predicted and actual returns and prices (for metrics reporting)\n",
    "    test_pred_rt = []\n",
    "    test_act_rt = []\n",
    "    test_pred_price = []\n",
    "    test_act_price = []    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    trades_fn = basefn + '_trades.csv'\n",
    "    losses_fn = basefn + '_losses.csv'\n",
    "    \n",
    "    # Write headings for trades file\n",
    "    with open(trades_fn, 'w', newline='') as myfile:    \n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Day','Adj Close','Pred Rt', 'Act Rt','Buy/Sell','Adj Cls Sell Price','Open Sell Price',\n",
    "                     'Bin','AdjCls Profit','Open Profit','Acc Profit Adj Cls','Acc Profit Open',\n",
    "                     'E0','E1','E2','E3','E4','E5','E6','E7',\n",
    "                     'A0','A1','A2','A3','A4','A5','A6','A7',                     \n",
    "                     'C0','C1','C2','C3','C4','C5','C6','C7',\n",
    "                     'Q0','Q1','Q2','Q3','Q4','Q5','Q6'])\n",
    "\n",
    "    # Write headings for losses file\n",
    "    with open(losses_fn, 'w', newline='') as myfile:    \n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        heading_list=['Day','Trainloss','TestPred', 'TestAct', 'TestPredRt', 'TestActRt', 'TestLoss']\n",
    "        for i in range(len(test_seq[0])):\n",
    "            heading_list.append('TP'+str(i))\n",
    "        for i in range(len(test_seq[0])):\n",
    "            heading_list.append('TL'+str(i))            \n",
    "        for i in range(len(test_seq[0])):\n",
    "            heading_list.append('VP'+str(i))            \n",
    "        for i in range(len(test_seq[0])):\n",
    "            heading_list.append('VL'+str(i))                        \n",
    "        wr.writerow(heading_list)\n",
    "        \n",
    "    total_profit = 0\n",
    "    num_trades = 0\n",
    "    \n",
    "    for j in range(0, len(test_seq) - 2):      \n",
    "\n",
    "        # Send input / label data to Cuda if available\n",
    "        train_inputs = test_seq[j].to(device)\n",
    "        train_labels = test_labels[j].to(device)\n",
    "                \n",
    "#        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#        my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer = optimizer, gamma = dr)\n",
    "                \n",
    "\n",
    "        test_log = []\n",
    "        \n",
    "        # Reset the learning rate each time for the inner loop\n",
    "#        optimizer.param_groups[0]['lr'] = lr        \n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # How many times we train on each sample as we go\n",
    "        for iter in range(iter_per_seq):\n",
    "\n",
    "            # Initialise hidden states before every epoch\n",
    "            h = model.init_hidden(batch_size)  \n",
    "                                    \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            train_y_pred, h, lstm_out = model(train_inputs, h, verbose=0)\n",
    "               \n",
    "            train_test_loss = loss_function(train_y_pred, train_labels)\n",
    "               \n",
    "            # Compute gradients and update the model\n",
    "            train_test_loss.backward()\n",
    "            optimizer.step()\n",
    "            my_lr_scheduler.step()\n",
    "                       \n",
    "        # Having updated the model with \"todays\" inputs, we now predict \"tomorrows\" return\n",
    "        model.eval()\n",
    "            \n",
    "        inputs = test_seq[j+1].to(device)\n",
    "        labels = test_labels[j+1].to(device)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            h = model.init_hidden(batch_size)\n",
    "        \n",
    "            y_pred, h, lstm_out = model(inputs, h)\n",
    "            test_adj_close = inputs[-1][-1].item()                \n",
    "            test_pred = y_pred[-1].item()\n",
    "\n",
    "            test_truth = labels[-1].item()\n",
    "            test_actual_return = (denormalise_value(test_truth, scale, offset) / denormalise_value(test_adj_close, scale, offset)) - 1            \n",
    "            \n",
    "            # All trades are predicated on \"test_predicted_return\".  We mess with that here to implement the different kinds\n",
    "            # of predictor - \"pytorch_lstm\", \"random\" or \"prescient\". We save the actual predicted return though and update\n",
    "            # Q & Q with that, not the messed with value.\n",
    "            \n",
    "            pytorch_lstm_test_predicted_return =  (denormalise_value(test_pred, scale, offset) / denormalise_value(test_adj_close, scale, offset)) - 1\n",
    "            \n",
    "            if predictor == \"pytorch_lstm\":  # Usual behavior\n",
    "                test_predicted_return = pytorch_lstm_test_predicted_return\n",
    "            elif predictor == \"random\":\n",
    "                test_predicted_return = random.choice(D)   # pick a random return from D\n",
    "            elif predictor == \"prescient\":\n",
    "                test_predicted_return = test_actual_return    # Make the predicted return the actual return\n",
    "            elif predictor == \"drunk_genius\":   # Mix of prescient / random according to drunk_genius_accuracy\n",
    "                if random.random() <= drunk_genius_accuracy:\n",
    "                    test_predicted_return = test_actual_return\n",
    "                else:\n",
    "                    test_predicted_return = random.choice(D)   # pick a random return from D                \n",
    "\n",
    "            test_pred_price.append(test_pred)\n",
    "            test_act_price.append(test_truth)            \n",
    "            test_loss = (test_pred - test_truth)**2\n",
    "            \n",
    "            test_pred_rt.append(test_predicted_return)\n",
    "            test_act_rt.append(test_actual_return)\n",
    "            \n",
    "        if verbosity >= 3:\n",
    "            print(j, '{:1.2f}'.format(test_adj_close), '{:1.4f}'.format(test_predicted_return))\n",
    "            \n",
    "        test_log = [j, test_adj_close, test_predicted_return, test_actual_return]\n",
    "            \n",
    "        # Sell if return is negative or if it's the last day of trading and we're holding the asset\n",
    "        if ((test_predicted_return < 0 or j == len(test_seq) - 3)) and holding:\n",
    "            open_sell_price = denormalise_value(test_seq[j+2][-1][0].item(), scale, offset) # Next day open\n",
    "            sell_price = denormalise_value(test_adj_close, scale, offset)\n",
    "            profit = sell_price - purchase_price\n",
    "            total_profit += profit\n",
    "            num_trades += 1\n",
    "            E, A = update_EA(E, A, profit, purchase_bin)\n",
    "            if verbosity >= 3:\n",
    "                print(\"E\", E)\n",
    "                print(\"A\", A)\n",
    "            holding = False\n",
    "            \n",
    "            total_profit_open = total_profit_open + (open_sell_price - open_purchase_price)\n",
    "            total_profit_adj_close = total_profit_adj_close + profit\n",
    "            journal.append((-1, j+2+len(inputs), sell_price, total_profit_adj_close, open_sell_price, total_profit_open))\n",
    "            \n",
    "            if verbosity >= 2:\n",
    "                print(\"Executed sell at ${:1.2f}\".format(sell_price), \"on day\", j, \"Profit: ${:1.4f}\".format(profit),\n",
    "                     \"Total Profit: ${:1.4f}\".format(total_profit))\n",
    "                \n",
    "            test_log += (['Sell', sell_price, open_sell_price, purchase_bin, profit, open_sell_price - open_purchase_price, \n",
    "                          total_profit_adj_close, total_profit_open] + E.tolist() + A.tolist() + C.tolist() + Q.tolist())\n",
    "\n",
    "        # Buy\n",
    "        if test_predicted_return >= 0 and not holding:\n",
    "            return_bin = np.digitize(test_predicted_return, Q)\n",
    "            if verbosity >= 3:\n",
    "                print(\"Q\",Q,\"return_bin\", return_bin)\n",
    "            if A[return_bin] > 0:\n",
    "                purchase_bin = return_bin\n",
    "                C[purchase_bin] = C[purchase_bin] + 1\n",
    "                num_trades += 1\n",
    "                open_purchase_price = denormalise_value(test_seq[j+2][-1][0].item(), scale, offset) # Next day open\n",
    "                purchase_price = denormalise_value(test_adj_close, scale, offset)\n",
    "                holding = True\n",
    "                journal.append((1, j+2+len(inputs), purchase_price, total_profit_adj_close, open_purchase_price, total_profit_open))\n",
    "                \n",
    "                if verbosity >= 2:\n",
    "                    print(\"Executed buy at ${:1.2f}\".format(purchase_price), \"on day \", j, \"bin\", return_bin)\n",
    "                    \n",
    "                test_log += (['Buy', purchase_price, open_purchase_price, purchase_bin, 'N/A', 'N/A', \n",
    "                              total_profit_adj_close, total_profit_open] + E.tolist() + A.tolist() + C.tolist() + Q.tolist())\n",
    "\n",
    "        D, Q = update_DQ(D, Q, pytorch_lstm_test_predicted_return, percentiles)\n",
    "        \n",
    "        # Append the metrics to the training log file\n",
    "        with open(trades_fn, 'a', newline='') as myfile:    \n",
    "            wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "            wr.writerow(test_log)\n",
    "            \n",
    "        # Make a record of the training / test losses\n",
    "        with open(losses_fn, 'a', newline='') as losses_file:\n",
    "            wr = csv.writer(losses_file, quoting=csv.QUOTE_ALL)\n",
    "            wr.writerow([j,train_test_loss.item(),test_pred, test_truth, \n",
    "                         test_predicted_return, test_actual_return, test_loss] \n",
    "                        + train_y_pred.tolist() + train_labels.tolist() + y_pred.tolist() + labels.tolist())\n",
    "        \n",
    "\n",
    "    # The following is using Close - Open prices as start / end prices which is wrong and in all versions prior to 17\n",
    "    # Item 0 is the Open price\n",
    "#    start_price = denormalise_value(test_seq[0][-1][0].item(), scale, offset)\n",
    "\n",
    "    # Item 3 is the Close price\n",
    "#    end_price = denormalise_value(test_seq[-1][-1][3].item(), scale, offset)\n",
    "\n",
    "    # First row, Last item is the Adj Close \n",
    "    start_price = denormalise_value(test_seq[0][-1][-1].item(), scale, offset)\n",
    "\n",
    "    # Last row, Last item is the Adj Close\n",
    "    end_price = denormalise_value(test_seq[-1][-1][-1].item(), scale, offset)\n",
    "    \n",
    "    if len(journal):\n",
    "        test_profit = journal[-1][-3]\n",
    "        test_return_pct = 100 * journal[-1][-3]/start_price\n",
    "    else:\n",
    "        test_profit = 0\n",
    "        test_return_pct = 0\n",
    "    \n",
    "    if verbosity >= 1:\n",
    "\n",
    "        print(\"Buy and Hold Baseline:\")\n",
    "        print(\"Price at start: ${:1.2f}\".format(start_price))\n",
    "        print(\"Price at end: ${:1.2f}\".format(end_price))\n",
    "        print(\"Difference: ${:1.2f}\".format(end_price - start_price))\n",
    "        print(\"Return:{:1.2f}%\".format(100*(end_price - start_price)/start_price))\n",
    "\n",
    "        print(\"\\nProfit from trading:{:1.2f}\".format(test_profit))\n",
    "        print(\"Return from trading:{:1.2f}%\".format(test_return_pct))\n",
    "        print(\"Num trades:{:3}\".format(num_trades))\n",
    "    \n",
    "        print(\"Length Returns:\", len(D))\n",
    "        print(\"Q:\\n\", Q)\n",
    "        print(\"E:\\n\", E)\n",
    "        print(\"A:\\n\", A)\n",
    "        print(\"C:\\n\", C)\n",
    "        \n",
    "        print(\"Test Time:\", (time.time()-start_time)/60)\n",
    "        \n",
    "    metrics_dict = compute_metrics(np.array(test_pred_rt),\n",
    "                                   np.array(test_act_rt),\n",
    "                                   np.array(test_pred_price),\n",
    "                                   np.array(test_act_price))\n",
    "\n",
    "    if verbosity >= 1:\n",
    "        print(\"N:\", metrics_dict['N'], \n",
    "              \"\\tMDA:{:1.2f}\".format(metrics_dict['MDA']), \n",
    "              \"\\tMAPE:{:1.2f}\".format(metrics_dict['MAPE']), \n",
    "              \"\\tMAE:{:1.5e}\".format(metrics_dict['MAE']), \n",
    "              \"\\tMSE:{:1.5e}\".format(metrics_dict['MSE']),\n",
    "              \"\\tPrice Correlation:{:1.2f}\".format(metrics_dict['PXCORR']),          \n",
    "              \"\\tReturns Correlation:{:1.2f}\".format(metrics_dict['RXCORR'])\n",
    "             )\n",
    "        \n",
    "    result_dict = {'bnh_profit': end_price - start_price, 'bnh_Return':100*(end_price - start_price)/start_price,\n",
    "              'num_trades':num_trades, \n",
    "              'trade_profit':test_profit, 'trade_return': test_return_pct, 'pred_rt':test_pred_rt, \n",
    "                  'act_rt':test_act_rt, 'pred_price':test_pred_price, 'act_price':test_act_price}\n",
    "\n",
    "    # Append the metrics to the training log file\n",
    "    with open(trades_fn, 'a', newline='') as myfile:    \n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Num Samples For Metrics:', metrics_dict['N']])\n",
    "        wr.writerow(['MDA:', metrics_dict['MDA']])\n",
    "        wr.writerow(['MAPE:', metrics_dict['MAPE']])\n",
    "        wr.writerow(['MAE:', metrics_dict['MAE']])\n",
    "        wr.writerow(['MSE:', metrics_dict['MSE']])\n",
    "        wr.writerow(['Price Correlation:', metrics_dict['PXCORR']])\n",
    "        wr.writerow(['Returns Correlation:', metrics_dict['RXCORR']])\n",
    "        \n",
    "        \n",
    "        wr.writerow(['Open Start Price:', start_price])        \n",
    "        wr.writerow(['Open End Price:', end_price])\n",
    "        wr.writerow(['Difference (Open to Open) $:', end_price-start_price])\n",
    "        wr.writerow(['Open Buy and Hold Return %:', 100*(end_price - start_price)/start_price])        \n",
    "        \n",
    "        wr.writerow(['Total profits from trading $:', test_profit])        \n",
    "        wr.writerow(['Return from trading %:', test_return_pct])\n",
    "        wr.writerow(['Total trades:', num_trades])\n",
    "        \n",
    "        wr.writerow(['Total Test Time:', (time.time()-start_time)/60])\n",
    "        \n",
    "    # Add the meytrics dict to the result dict\n",
    "    result_dict.update(metrics_dict)\n",
    "\n",
    "            \n",
    "    # return updated model, updated D, Q E and A, journal and results from this test period\n",
    "    return model, D, Q, E, A, journal, result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_allocation_policy(train_result_dict, percentiles, scale=1, offset=0, basefn='', verbosity=1):\n",
    "    \n",
    "    # Varios ways to avoid the initial training period where the model is way off\n",
    "    stop_idx = len(train_result_dict['val_pred_rt'])\n",
    "    # Just look at the last 120 time steps - very few data points though\n",
    "#    start_idx = stop_idx - 120\n",
    "\n",
    "    # Look at the last 80% of the time steps\n",
    "    start_idx = stop_idx - int(0.8 * stop_idx)\n",
    "    \n",
    "    # Point D at the training predicted returns - for the period we are interested in\n",
    "    D = np.array(train_result_dict['val_pred_rt'])[start_idx:stop_idx]\n",
    "\n",
    "    # Compute the percentiles of only the POSITIVE training returns\n",
    "    # This is what I was doing up to v12, changed in v13\n",
    "#    Q = np.percentile(D[D >= 0], percentiles)\n",
    "    \n",
    "    # Compute the percentiles of the absolute training returns, for the last N time steps\n",
    "    Q = np.percentile(abs(D), percentiles)\n",
    "       \n",
    "    if verbosity >= 1:\n",
    "        print(\"\\nComputing initial allocation policy from the training set...\")\n",
    "        print(\"Number of returns from training used for policy:\", len(D))\n",
    "        print(\"Initial Q:\\n\",Q)\n",
    "\n",
    "    # There will be 8 bins from 7 percentiles - anything below the lowest percentile is placed in bin 0\n",
    "    # Anything equal to or greater than the lowest percentile but less than the 2nd wil be in bin 1 etc\n",
    "    # Anything equal to or greater than the last percentile will be in the last bin.\n",
    "    \n",
    "    if verbosity >= 2:\n",
    "        binned_returns = np.digitize(D, Q)\n",
    "        unique, counts = np.unique(binned_returns, return_counts=True)\n",
    "        print(\"Unique bins:\", unique)\n",
    "        print(\"Counts / bin:\", counts)\n",
    "\n",
    "    # Generate the Expected Returns for each bin in Q from the training data\n",
    "    \n",
    "    holding = False\n",
    "    E = np.zeros(shape=(len(percentiles)+1))\n",
    "    C = np.zeros(shape=(len(percentiles)+1))    \n",
    "   \n",
    "    pred_rt = np.array(train_result_dict['val_pred_rt'])\n",
    "    act_rt = np.array(train_result_dict['val_act_rt'])\n",
    "    adj_close = np.array(train_result_dict['val_adj_close_price'])\n",
    "    \n",
    "    with open(basefn + '_init_alloc.csv', 'w', newline='') as myfile:    \n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Day','Adj Close','Pred Rt', 'Act Rt','Buy/Sell','Sell Price','Bin','Acc Profit','Total Profit',\n",
    "                     'E0','E1','E2','E3','E4','E5','E6','E7',\n",
    "                     'C0','C1','C2','C3','C4','C5','C6','C7',\n",
    "                     'D0','D1','D2','D3','D4','D5','D6'])\n",
    "        \n",
    "    total_profit = 0\n",
    "\n",
    "    # Walk through the returns in the known valid region of the end of the training data\n",
    "    for i in range(start_idx, stop_idx):\n",
    "    \n",
    "        # This accumulates a line of values for the allocation log file\n",
    "        init_alloc_results = []\n",
    "        \n",
    "        if verbosity >= 2:\n",
    "            print(i, '{:1.2f}'.format(adj_close[i]), '{:1.4f}'.format(pred_rt[i]))\n",
    "        \n",
    "        init_alloc_results=[i,adj_close[i],pred_rt[i], act_rt[i]]\n",
    "        \n",
    "        # Sell\n",
    "        if pred_rt[i] < 0 and holding:\n",
    "            sell_price = denormalise_value(adj_close[i], scale, offset)\n",
    "            profit = sell_price - purchase_price\n",
    "            total_profit += profit\n",
    "            E[purchase_bin] = E[purchase_bin] + profit\n",
    "            holding = False\n",
    "            if verbosity >= 2:\n",
    "                print(\"Executed sell at ${:1.2f}\".format(sell_price), \"on day\", i, \"Profit: ${:1.4f}\".format(profit))\n",
    "            init_alloc_results += (['Sell', sell_price, purchase_bin, profit, total_profit] + E.tolist() + C.tolist() + Q.tolist())\n",
    "\n",
    "        # Buy\n",
    "        if pred_rt[i] >= 0 and not holding:\n",
    "            return_bin = np.digitize(pred_rt[i], Q)\n",
    "            purchase_bin = return_bin\n",
    "            C[purchase_bin] = C[purchase_bin] + 1\n",
    "            purchase_price = denormalise_value(adj_close[i], scale, offset)\n",
    "            holding = True\n",
    "            if verbosity >= 2:\n",
    "                print(\"Executed buy at ${:1.2f}\".format(purchase_price), \"on day \", i, \"bin\", return_bin)\n",
    "            init_alloc_results += (['Buy', purchase_price, purchase_bin, 'N/A', total_profit] + E.tolist() + C.tolist() + Q.tolist())\n",
    "            \n",
    "        # Append the metrics to the training log file\n",
    "        with open(basefn + '_init_alloc.csv', 'a', newline='') as myfile:    \n",
    "            wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "            wr.writerow(init_alloc_results)\n",
    "\n",
    "    \n",
    "    # It's important to understand that bin 0 won't have any trades at this point because we gave it the training\n",
    "    # data with a certain lower positive return. This value defines the lowest cut off of the training data. However,\n",
    "    # once we start getting new data we will see values probaby lower than this lowest bin cut off.\n",
    "    \n",
    "    A = (E > 0).astype(int)\n",
    "    \n",
    "    with open(basefn + '_init_alloc.csv', 'a', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow([' ','A0','A1','A2','A3','A4','A5','A6','A7'])\n",
    "        wr.writerow(['Initial Allocation Policy:'] + A.tolist())\n",
    "                \n",
    "    if verbosity >= 1:\n",
    "        print(\"Expected Gains per Bin:\", E)\n",
    "        print(\"Trades per bin:\", C)\n",
    "        print(\"\\nInitial Allocation Policy:\",A)        \n",
    "        \n",
    "    return D,Q,E,A,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_dir - the root location of an existing run (including a saved_models directory) if we are picking up from a prevous run\n",
    "# resume_epoch - the epoch to resume from. Expect to find DQEAC_dictXXX.pkl and epochXXX.mdl files in a saved_models dir where\n",
    "#                XXX is the epoch number we wish to resume from.  -1 means start from the last.\n",
    "# train_epochs - how many epochs to train for (if starting from a pre-saved point, how many additonal epochs to train for)\n",
    "\n",
    "def run_hypers(train_start = '01-01-2005', train_end = '01-01-2008', valid_start = '01-02-2008', valid_end = '12-31-2009',\n",
    "               test_start = '01-01-2010', test_end = '12-20-2019', \n",
    "               resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=1, arch='LH', \n",
    "               num_layers=3, hidden_size=128, dropout=0.5, lr=0.01, dr=1.0, wd=0.0, trading_validation_period=100, \n",
    "               run_out_of_sample_test=0, train_only=0, verbosity=0, plot=0):\n",
    "\n",
    "    # If attempting to resume, check resume_dir/saved_models actually exists\n",
    "    if resume_dir != '':\n",
    "        if os.path.isdir(resume_dir + '/saved_models') == False:\n",
    "            print(\"Error: root directory for resume does not exist!\")\n",
    "            return\n",
    "    \n",
    "    hyper_results = []\n",
    "    \n",
    "    # Even if we're resuming, we will make a new directory for the new results\n",
    "    basefn = datetime.today().strftime('%Y-%m-%d-%H-%M-%S' + '/')\n",
    "    \n",
    "    # Make a results directory. If the 'directory' doesn't exist, create it\n",
    "    if os.path.isdir(basefn) == False:\n",
    "        os.mkdir(basefn)        \n",
    "                \n",
    "    hyper_results.append(basefn)\n",
    "    \n",
    "    # New additions to log file in CH15 - the root of a resumation and start epoch / how many epochs \n",
    "    # If resuming, put the location of the root directory. If starting from scratch put \"BASE\" in log field\n",
    "    if resume_dir=='':\n",
    "        hyper_results.append('BASE')\n",
    "    else:\n",
    "        hyper_results.append(resume_dir)\n",
    "        \n",
    "    hyper_results.append(resume_epoch)    \n",
    "    hyper_results.append(train_epochs)\n",
    "    \n",
    "    # Go get the data for the asset\n",
    "    abs_df = get_data(asset_name=asset, directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019')    \n",
    "    hyper_results.append(asset)\n",
    "\n",
    "    hyper_results.append(arch)        \n",
    "    hyper_results.append(iter_per_seq)\n",
    "    hyper_results.append(num_layers)        \n",
    "    hyper_results.append(window_size)        \n",
    "    hyper_results.append(hidden_size)        \n",
    "    hyper_results.append(lr)        \n",
    "    hyper_results.append(dr)\n",
    "    hyper_results.append(wd)        \n",
    "    hyper_results.append(dropout)      \n",
    "        \n",
    "    plotly_candlestick(abs_df, asset, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "    \n",
    "    # Add the Prev Adj Close, drop volume etc\n",
    "    abs_df = add_features_to_df(abs_df)\n",
    "    \n",
    "    # Normalise the entire dataset\n",
    "    df, scale, offset = normalise_df(abs_df)\n",
    "    \n",
    "    plotly_candlestick(df, asset, basefn=basefn, display_plot=plot, save_plot=1)    \n",
    "                \n",
    "        \n",
    "    # Mask off the training data and assign result to a train_asset dataframe\n",
    "    mask = (df['Date'] >= train_start) & (df['Date'] <= train_end)\n",
    "    train_asset_df = df.loc[mask]\n",
    "    \n",
    "    last_train_date = train_asset_df['Date'].iloc[-1]\n",
    "    print(\"last_train_date:\", last_train_date)\n",
    "    \n",
    "    loc_last_train_date = df.index[df['Date'] == last_train_date].tolist()[0]\n",
    "    print(\"loc_last_train_date:\", loc_last_train_date)\n",
    "    \n",
    "    backup_index = loc_last_train_date - window_size\n",
    "    print(\"backup_index:\", backup_index)\n",
    "    \n",
    "    backup_date = df['Date'].iloc[backup_index]\n",
    "    print(\"Backup date:\", backup_date)\n",
    "    \n",
    "    # Mask off the validation data and assign result to a valid_asset dataframe\n",
    "#    mask = (df['Date'] >= valid_start) & (df['Date'] <= valid_end)\n",
    "    mask = (df['Date'] >= backup_date) & (df['Date'] <= valid_end)\n",
    "    valid_asset_df = df.loc[mask]\n",
    "    \n",
    "    # Mask off the test data and assign result to a test_asset dataframe\n",
    "    mask = (df['Date'] >= test_start) & (df['Date'] <= test_end)\n",
    "    test_asset_df = df.loc[mask]\n",
    "        \n",
    "    # Reset the indices to start from 0 again for each of the dataframes\n",
    "    train_asset_df.index = np.arange(train_asset_df.shape[0])   \n",
    "    valid_asset_df.index = np.arange(valid_asset_df.shape[0])    \n",
    "    test_asset_df.index = np.arange(test_asset_df.shape[0]) \n",
    "    \n",
    "    # Generate validation attribute set\n",
    "    valid_seq, valid_labels = create_input_sequences_from_df(valid_asset_df, window_size)\n",
    "    \n",
    "    print(\"Train Start Date:\", train_asset_df['Date'].iloc[0])\n",
    "    print(\"Train End Date:\", train_asset_df['Date'].iloc[-1])\n",
    "    print(\"Train Length:\", len(train_asset_df))\n",
    "    print(\"Valid Start Date:\", valid_asset_df['Date'].iloc[0])\n",
    "    print(\"Valid End Date:\", valid_asset_df['Date'].iloc[-1])\n",
    "    print(\"Valid Length:\", len(valid_asset_df))\n",
    "\n",
    "    # Convert our list of lists to Tensors\n",
    "    valid_seq = torch.FloatTensor(valid_seq)\n",
    "    valid_labels = torch.FloatTensor(valid_labels)\n",
    "    \n",
    "        \n",
    "    percentiles = [0,10,20,30,40,50,60]\n",
    "#    percentiles = [0,10,20,30,40,50,60,70,80,90]    \n",
    "       \n",
    "    model, train_result_dict = create_train_model(train_asset_df, resume_dir=resume_dir, resume_epoch=resume_epoch, \n",
    "                                            basefn=basefn, scale=scale, offset=offset, arch=arch, \n",
    "                                            window_size = window_size, epochs=train_epochs,\n",
    "                                            iter_per_seq=iter_per_seq, max_iter=1E32, num_layers=num_layers,\n",
    "                                            hidden_size=hidden_size, dropout=dropout, lr=lr, dr=dr, wd=wd,\n",
    "                                            trading_validation_period=trading_validation_period,\n",
    "                                            percentiles=percentiles,\n",
    "                                            valid_seq=valid_seq, valid_labels=valid_labels,\n",
    "                                            verbosity=verbosity, plot=plot)        \n",
    "\n",
    "    # Append the metrics to the training log file\n",
    "    with open(basefn + 'train.csv', 'a', newline='') as myfile:    \n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Num Samples For Metrics:', train_result_dict['trStats_N']])\n",
    "        wr.writerow(['MDA:', train_result_dict['trMDA']])\n",
    "        wr.writerow(['MAPE:', train_result_dict['trMAPE']])\n",
    "        wr.writerow(['MAE:', train_result_dict['trMAE']])\n",
    "        wr.writerow(['AveTrMSE:', train_result_dict['trAvTrMSE']])        \n",
    "        wr.writerow(['AveValMSE:', train_result_dict['trAvValMSE']])\n",
    "        wr.writerow(['Price X-Correl:', train_result_dict['trPXCORR']])        \n",
    "        wr.writerow(['Returns X-Correl:', train_result_dict['trRXCORR']])    \n",
    "        \n",
    "    hyper_results.append(train_result_dict['trAvTrMSE'])\n",
    "    hyper_results.append(train_result_dict['trAvValMSE'])    \n",
    "    hyper_results.append(train_result_dict['trMDA'])\n",
    "    \n",
    "    if train_only:\n",
    "        return model, [], train_result_dict\n",
    "    \n",
    "    # MODEL TRAINING COMPLETE - NOW WE BUILD THE INITIAL ALLOCATION POLICY\n",
    "        \n",
    "    D,Q,E,A,C = generate_initial_allocation_policy(train_result_dict, percentiles, scale=scale, offset=offset, basefn=basefn, verbosity=verbosity)\n",
    "\n",
    "    policy_dict = {'initial_D':D,'initial_Q':Q,'initial_E':E,'initial_A':A,'initial_C':C}\n",
    "                   \n",
    "        \n",
    "    print(\"\\nPERFORMING VALIDATION...\")\n",
    "        \n",
    "    model, D, Q, E, A, journal, test_result_dict = test_trading_system(model, valid_seq, valid_labels, D, Q, E, A, percentiles, basefn=basefn+'_val', scale=scale, offset=offset, iter_per_seq=iter_per_seq, lr = 0.001, dr = 1, verbosity=verbosity)\n",
    "\n",
    "    result_dict = {'val_profit':test_result_dict['trade_profit'], 'val_return_pct':test_result_dict['trade_return']}\n",
    "        \n",
    "    hyper_results.append(test_result_dict['MDA'])    \n",
    "    hyper_results.append(test_result_dict['MSE'])\n",
    "    hyper_results.append(test_result_dict['num_trades'])    \n",
    "    hyper_results.append(test_result_dict['PXCORR'])\n",
    "    hyper_results.append(test_result_dict['RXCORR'])              \n",
    "    hyper_results.append(test_result_dict['trade_profit'])\n",
    "    hyper_results.append(test_result_dict['trade_return'])         \n",
    "    \n",
    "    policy_dict['post_val_D'] = D\n",
    "    policy_dict['post_val_Q'] = Q\n",
    "    policy_dict['post_val_E'] = E\n",
    "    policy_dict['post_val_A'] = A\n",
    "                \n",
    "    if run_out_of_sample_test:\n",
    "        \n",
    "        if verbosity >= 1:\n",
    "            print(\"\\nEVALUATING TEST SET...\")    \n",
    "    \n",
    "        # Generate test attribute set\n",
    "        test_seq, test_labels = create_input_sequences_from_df(test_asset_df, window_size)\n",
    "\n",
    "        # Convert our list of lists to Tensors\n",
    "        test_seq = torch.FloatTensor(test_seq)\n",
    "        test_labels = torch.FloatTensor(test_labels)\n",
    "\n",
    "        model, D, Q, E, A, journal, test_result_dict = test_trading_system(model, test_seq, test_labels, D, Q, E, A, percentiles, basefn=basefn+'test', scale=scale, offset=offset, iter_per_seq=iter_per_seq, lr = 0.001, dr = 1, verbosity=verbosity)\n",
    "    \n",
    "        result_dict['test_profit'] = test_result_dict['trade_profit']\n",
    "        result_dict['test_return_pct'] = test_result_dict['trade_return']\n",
    "        \n",
    "        policy_dict['post_test_D'] = D\n",
    "        policy_dict['post_test_Q'] = Q\n",
    "        policy_dict['post_test_E'] = E\n",
    "        policy_dict['post_test_A'] = A\n",
    "        \n",
    "    with open('hyper_log.csv', 'a', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(hyper_results + policy_dict['initial_E'].tolist() + policy_dict['initial_C'].tolist() + policy_dict['initial_A'].tolist())\n",
    "        \n",
    "    with open(basefn + 'policy_dict.pkl','wb') as fp:\n",
    "        pickle.dump(policy_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                    \n",
    "    return model, journal, result_dict, policy_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2015', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(resume_dir='', resume_epoch=-1, window_size=22, asset='SPY', train_epochs=3000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(resume_dir='', resume_epoch=-1, window_size=44, asset='SPY', train_epochs=3000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=3000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=32, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=3000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2006', train_end = '01-01-2009', valid_start = '01-02-2009', valid_end = '12-31-2010', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2007', train_end = '01-01-2010', valid_start = '01-02-2010', valid_end = '12-31-2011', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2008', train_end = '01-01-2011', valid_start = '01-02-2011', valid_end = '12-31-2012', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2009', train_end = '01-01-2012', valid_start = '01-02-2012', valid_end = '12-31-2013', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2010', train_end = '01-01-2013', valid_start = '01-02-2013', valid_end = '12-31-2014', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2011', train_end = '01-01-2014', valid_start = '01-02-2014', valid_end = '12-31-2015', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2012', train_end = '01-01-2015', valid_start = '01-02-2015', valid_end = '12-31-2016', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2013', train_end = '01-01-2016', valid_start = '01-02-2016', valid_end = '12-31-2017', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2014', train_end = '01-01-2017', valid_start = '01-02-2017', valid_end = '12-31-2018', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2015', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2012', train_end = '01-01-2015', valid_start = '01-02-2015', valid_end = '12-31-2016', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2013', train_end = '01-01-2016', valid_start = '01-02-2016', valid_end = '12-31-2017', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2014', train_end = '01-01-2017', valid_start = '01-02-2017', valid_end = '12-31-2018', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2015', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This extends the training period while keeping a constant length validation period\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2015', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2014', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2013', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2012', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=3000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2011', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=3500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result, policy_dict = run_hypers(train_start = '01-01-2010', train_end = '01-01-2018', valid_start = '01-02-2018', valid_end = '12-18-2019', resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=4000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(resume_dir='', resume_epoch=-1, window_size=22, asset='SPY', train_epochs=3000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=32, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(resume_dir='', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-3, dr=0.995, wd=0, trading_validation_period=50, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of resuming training on a previous run\n",
    "model, journal, result, policy_dict = run_hypers(resume_dir='CH14 - Exp 2 - 2000 epochs/2021-03-01-20-54-12', resume_epoch=-1, window_size=11, asset='SPY', train_epochs=2000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=10, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_out_of_sample_test(model, D, Q, E, A, basefn='', asset='SPY', window_size=11, iter_per_seq=3, lr=1E-3, dr=0):\n",
    "    \n",
    "    # Go get the data for the asset\n",
    "    abs_df = get_data(asset_name=asset, directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019')\n",
    "\n",
    "    # Add the Prev Adj Close, drop volume etc\n",
    "    abs_df = add_features_to_df(abs_df)\n",
    "    \n",
    "    # Normalise the entire dataset\n",
    "    df, scale, offset = normalise_df(abs_df)\n",
    "    \n",
    "    # Out of sample test set\n",
    "    test_start = '01-01-2010'\n",
    "    test_end = '12-20-2019'\n",
    "    \n",
    "#    test_asset_dict = {}\n",
    "       \n",
    "#    backup_index = len(test_asset_df) - window_size\n",
    "#    backup_date = df['Date'].iloc[backup_index]\n",
    "    \n",
    "    # Mask off the test data and assign result to a test_asset dataframe\n",
    "    mask = (df['Date'] >= test_start) & (df['Date'] <= test_end)\n",
    "    test_asset_df = df.loc[mask]\n",
    "    \n",
    "    # Reset the indices to start from 0 again for each of the dataframes\n",
    "    test_asset_df.index = np.arange(test_asset_df.shape[0]) \n",
    "    \n",
    "    # Generate test attribute set\n",
    "    test_seq, test_labels = create_input_sequences_from_df(test_asset_df, window_size)\n",
    "\n",
    "    # Convert our list of lists to Tensors\n",
    "    test_seq = torch.FloatTensor(test_seq)\n",
    "    test_labels = torch.FloatTensor(test_labels)\n",
    "        \n",
    "    percentiles = [0,10,20,30,40,50,60]\n",
    "\n",
    "    model, D, Q, E, A, journal, test_result_dict = test_trading_system(model, test_seq, test_labels, D, Q, E, A, percentiles, basefn=basefn, scale=scale, offset=offset, iter_per_seq=iter_per_seq, lr = lr, dr = dr, verbosity=0)\n",
    "    \n",
    "    return model, D, Q, E, A, test_result_dict\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trading_validation(model, D, Q, E, A, predictor=\"pytorch_lstm\", drunk_genius_accuracy=0.5, valid_start='01-02-2008', valid_end='12-31-2009', basefn='', asset='SPY', window_size=11, iter_per_seq=3, lr=1E-3, dr=0):\n",
    "    \n",
    "    \n",
    "    # Go get the data for the asset\n",
    "    abs_df = get_data(asset_name=asset, directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019')\n",
    "\n",
    "    # Add the Prev Adj Close, drop volume etc\n",
    "    abs_df = add_features_to_df(abs_df)\n",
    "    \n",
    "    # Normalise the entire dataset\n",
    "    df, scale, offset = normalise_df(abs_df)\n",
    "    \n",
    "    # Training set\n",
    "#    train_start = '01-01-2005'\n",
    "#    train_end = '01-01-2008'    \n",
    "            \n",
    "    # Mask off the training data and assign result to a train_asset dataframe\n",
    "#    mask = (df['Date'] >= train_start) & (df['Date'] <= train_end)\n",
    "#    train_asset_df = df.loc[mask]\n",
    "    \n",
    "#    backup_index = len(train_asset_df) - window_size\n",
    "#    backup_date = df['Date'].iloc[backup_index]\n",
    "    \n",
    "    # Mask off the validation data and assign result to a valid_asset dataframe\n",
    "\n",
    "    mask = (df['Date'] >= valid_start) & (df['Date'] <= valid_end)\n",
    "    valid_asset_df = df.loc[mask]\n",
    "           \n",
    "    # Reset the indices to start from 0 again for each of the dataframes\n",
    "#    train_asset_df.index = np.arange(train_asset_df.shape[0])   \n",
    "    valid_asset_df.index = np.arange(valid_asset_df.shape[0])    \n",
    "    \n",
    "    print(\"Valid Start Date:\", valid_asset_df['Date'].iloc[0])\n",
    "    print(\"Valid End Date:\", valid_asset_df['Date'].iloc[-1])\n",
    "    print(\"Valid Length:\", len(valid_asset_df))\n",
    "\n",
    "    # Generate validation attribute set\n",
    "    valid_seq, valid_labels = create_input_sequences_from_df(valid_asset_df, window_size)\n",
    "\n",
    "    # Convert our list of lists to Tensors\n",
    "    valid_seq = torch.FloatTensor(valid_seq)\n",
    "    valid_labels = torch.FloatTensor(valid_labels)\n",
    "                    \n",
    "    percentiles = [0,10,20,30,40,50,60]\n",
    "\n",
    "    model, D, Q, E, A, journal, test_result_dict = test_trading_system(model, valid_seq, valid_labels, D, Q, E, A, percentiles, \n",
    "                        predictor=predictor, drunk_genius_accuracy=drunk_genius_accuracy, basefn=basefn, scale=scale, offset=offset, iter_per_seq=iter_per_seq, lr = lr, \n",
    "                        dr = dr, verbosity=0)\n",
    "    \n",
    "#    print(test_result_dict)\n",
    "    return model, D, Q, E, A, test_result_dict\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function runs a validation / test repeatability evaluation on a saved model from training\n",
    "\n",
    "def run_trading_trials(predictor='pytorch_lstm', drunk_genius_accuracy=0.5, valid_start='01-02-2008', valid_end='12-31-2009',savedfn='', model_num=-1, num_trials=10, run_test=0, iter_per_seq=3, lr=1E-3, dr=0):\n",
    "\n",
    "    model_fn = savedfn + 'epoch' + str(model_num) + '.mdl'\n",
    "    print(model_fn)\n",
    "    \n",
    "    DQEA_fn = savedfn + 'DQEAC_dict' + str(model_num) + '.pkl'\n",
    "    print(DQEA_fn)\n",
    "    \n",
    "    resultsfn = datetime.today().strftime('%Y-%m-%d-%H-%M-%S' + '/')\n",
    "    \n",
    "    # Make a results directory. If the 'directory' doesn't exist, create it\n",
    "    if os.path.isdir(resultsfn) == False:\n",
    "        os.mkdir(resultsfn)       \n",
    "\n",
    "    with open(resultsfn + 'val_results.csv', 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['N', 'iter_per_seq', 'lr', 'dr', 'num_trades', 'trade_return'])     \n",
    "\n",
    "    with open(resultsfn + 'test_results.csv', 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['N', 'num_trades', 'trade_return'])\n",
    "            \n",
    "    with open(resultsfn + 'val_test_summary.csv', 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['N','iter_per_seq', 'lr', 'dr', 'mean_val_trades','mean_val_returns','std_val_returns','min_val_returns',\n",
    "                     'max_val_returns', 'mean_MDA', 'mean_RtCorr', 'mean_MSE', 'mean_MAE', 'mean_MAPE',\n",
    "                     'mean_test_trades', 'mean_test_returns', 'std_test_returns', 'min_test_returns',\n",
    "                     'max_test_returns'])\n",
    "    \n",
    "    val_trades = []\n",
    "    test_trades = []\n",
    "    val_mda = []\n",
    "    val_mae = []\n",
    "    val_mape = []\n",
    "    val_rxcorr = []\n",
    "    val_mse = []\n",
    "    val_returns = []\n",
    "    test_returns = []\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        saved_model = torch.load(model_fn)\n",
    "    \n",
    "        with open(DQEA_fn, 'rb') as fp:\n",
    "            saved_DQEAC = pickle.load(fp)\n",
    "        \n",
    "        D, Q, E, A, C = saved_DQEAC['D'], saved_DQEAC['Q'], saved_DQEAC['E'], saved_DQEAC['A'], saved_DQEAC['C']    \n",
    "    \n",
    "        model, D, Q, E, A, result_dict = run_trading_validation(saved_model, D, Q, E, A, predictor=predictor, \n",
    "                                                                drunk_genius_accuracy=drunk_genius_accuracy,\n",
    "                                                                valid_start=valid_start, valid_end=valid_end, \n",
    "                                                                basefn=resultsfn+str(i)+'_', iter_per_seq=iter_per_seq, \n",
    "                                                                lr=lr, dr=dr)\n",
    "        \n",
    "        print(\"Val:\", i, iter_per_seq, lr,dr, result_dict['num_trades'], result_dict['trade_return'], \n",
    "              result_dict['MDA'], result_dict['RXCORR'], result_dict['MSE'])\n",
    "        \n",
    "        val_returns.append(result_dict['trade_return'])\n",
    "        val_trades.append(result_dict['num_trades'])\n",
    "        val_mda.append(result_dict['MDA'])\n",
    "        val_mae.append(result_dict['MAE'])        \n",
    "        val_mape.append(result_dict['MAPE'])                \n",
    "        val_rxcorr.append(result_dict['RXCORR'])\n",
    "        val_mse.append(result_dict['MSE'])\n",
    "        \n",
    "        with open(resultsfn + 'val_results.csv', 'a', newline='') as myfile:\n",
    "            wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "            wr.writerow([i, iter_per_seq, lr, dr, result_dict['num_trades'],result_dict['trade_return'], result_dict['MDA'],\n",
    "                        result_dict['RXCORR'], result_dict['MSE'], result_dict['MAE'], result_dict['MAPE']])\n",
    "    \n",
    "        if run_test:\n",
    "            model, D, Q, E, A, test_result_dict = run_out_of_sample_test(model, D, Q, E, A, basefn=resultsfn+str(i)+'_', iter_per_seq=iter_per_seq, lr=lr, dr=dr)\n",
    "            print(\"Test:\", i, test_result_dict['num_trades'], test_result_dict['trade_return'])\n",
    "            test_returns.append(test_result_dict['trade_return'])\n",
    "            test_trades.append(test_result_dict['num_trades'])    \n",
    "        \n",
    "            with open(resultsfn + 'test_results.csv', 'a', newline='') as myfile:\n",
    "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow([i,test_result_dict['num_trades'],test_result_dict['trade_return']])\n",
    "\n",
    "    if run_test:\n",
    "        print(model_num, np.mean(val_trades),np.mean(val_returns), np.mean(test_trades),np.mean(test_returns))\n",
    "    else:\n",
    "        print(model_num, np.mean(val_trades),np.mean(val_returns))\n",
    "    \n",
    "    with open(resultsfn + 'val_test_summary.csv', 'a', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        if run_test:\n",
    "            wr.writerow([num_trials,iter_per_seq, lr, dr,np.mean(val_trades),np.mean(val_returns),np.std(val_returns),\n",
    "                         np.min(val_returns),np.max(val_returns), np.mean(val_mda), np.mean(val_rxcorr), np.mean(val_mse),\n",
    "                         np.mean(val_mae), np.mean(val_mape), \n",
    "                         np.mean(test_trades),np.mean(test_returns),np.std(test_returns),np.min(test_returns),np.max(test_returns)])\n",
    "        else:\n",
    "            wr.writerow([i,iter_per_seq, lr, dr,np.mean(val_trades),np.mean(val_returns),np.std(val_returns),np.min(val_returns),\n",
    "                         np.max(val_returns), np.mean(val_mda), np.mean(val_rxcorr), np.mean(val_mse), np.mean(val_mae), \n",
    "                        np.mean(val_mape)])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ND\\Anaconda3\\envs\\mlp\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-11-10-48/0_\n",
      "Val: 0 8 0.0001 1 152 -7.133539521489531 46.15384615384615 0.03460598060563963 0.0001487827371172557\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/1_\n",
      "Val: 1 8 0.0001 1 167 0.7092765891398379 45.74898785425101 0.05953682972960117 0.00014379050859905033\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/2_\n",
      "Val: 2 8 0.0001 1 151 -9.220177529004477 46.35627530364373 -0.0008317498034556882 0.0001556641817022675\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/3_\n",
      "Val: 3 8 0.0001 1 138 -6.939473528516862 45.95141700404859 0.003200609224104021 0.00015085230915534034\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/4_\n",
      "Val: 4 8 0.0001 1 148 -2.165026894285193 45.95141700404859 0.012563977892862338 0.00015019030252363198\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/5_\n",
      "Val: 5 8 0.0001 1 164 -1.9933383129341147 45.34412955465587 0.008963126428420651 0.00015495997915586834\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/6_\n",
      "Val: 6 8 0.0001 1 154 -5.057996887237744 47.16599190283401 0.02757820464531916 0.00015016109419855312\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/7_\n",
      "Val: 7 8 0.0001 1 172 2.6503665952460436 46.35627530364373 0.05349636662320923 0.00014486501026902707\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/8_\n",
      "Val: 8 8 0.0001 1 160 0.10084693771299742 47.77327935222672 0.037355011573531105 0.0001484250924762641\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/9_\n",
      "Val: 9 8 0.0001 1 156 3.8635284358925133 48.38056680161943 0.020736721907639127 0.00015963774604897308\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/10_\n",
      "Val: 10 8 0.0001 1 151 -10.145904989342386 44.93927125506073 0.0033226398664510325 0.00015571254666012398\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/11_\n",
      "Val: 11 8 0.0001 1 165 13.5839415404608 47.77327935222672 0.06256171647298656 0.00014660285888146298\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/12_\n",
      "Val: 12 8 0.0001 1 154 -7.618761250110167 44.73684210526316 0.0009545894315585961 0.00015494913796889457\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/13_\n",
      "Val: 13 8 0.0001 1 154 -11.418825046929875 45.1417004048583 -0.006479510675169854 0.0001526513357451126\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/14_\n",
      "Val: 14 8 0.0001 1 149 -15.46153853439972 46.558704453441294 0.0036640767588025864 0.00016134387341123856\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/15_\n",
      "Val: 15 8 0.0001 1 139 -7.439556785362929 46.15384615384615 0.017337101240182156 0.00015038166060914288\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/16_\n",
      "Val: 16 8 0.0001 1 148 -9.507585029539317 45.34412955465587 -0.006155590595869337 0.00015679621809585356\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/17_\n",
      "Val: 17 8 0.0001 1 149 -4.214357269198056 46.558704453441294 -0.007310480420598098 0.0001671918470993443\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/18_\n",
      "Val: 18 8 0.0001 1 162 -0.24259891774422065 48.38056680161943 -0.015088653336753919 0.00016184896025789748\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/19_\n",
      "Val: 19 8 0.0001 1 159 3.3335011111227804 46.76113360323887 0.024161548821844053 0.0001569152480321537\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/20_\n",
      "Val: 20 8 0.0001 1 145 -6.2077971279440005 47.36842105263158 -0.0072985682895805246 0.0001723074754794111\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/21_\n",
      "Val: 21 8 0.0001 1 154 -11.687618304163875 44.73684210526316 0.013113962546570813 0.0001451497963099663\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/22_\n",
      "Val: 22 8 0.0001 1 157 3.609714679224159 46.35627530364373 0.02537714964912971 0.00015014441811880347\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/23_\n",
      "Val: 23 8 0.0001 1 155 -7.842738457949735 46.963562753036435 0.024998706092741227 0.00015143024687623298\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-11-10-48/24_\n",
      "Val: 24 8 0.0001 1 164 -0.43668283056603624 46.76113360323887 0.023257049631247632 0.00016343082897681875\n",
      "750 154.68 -3.8752936531167643\n"
     ]
    }
   ],
   "source": [
    "# This is the last 2 years of the rolling period\n",
    "# savedfn = 'CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/'\n",
    "# run_trading_trials(valid_start='01-01-2018', valid_end='12-19-2019',savedfn=savedfn, model_num=900, num_trials=10, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# This is the best performing period and model I saw in the rolling experiment\n",
    "# saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2009 - 2021-03-13-14-20-53/saved_models'\n",
    "#run_trading_trials(valid_start='12-15-2006', valid_end='12-31-2008',savedfn=savedfn, model_num=850, num_trials=10, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# \n",
    "saved_fn = 'Ch15 - CH16 - Exp8 - Expanding training period/3 year partial - 2021-03-16-13-05-13/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2017', valid_end='12-18-2019',savedfn=savedfn, model_num=750, num_trials=25, run_test=0, iter_per_seq=8, lr=1E-4, dr=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ND\\Anaconda3\\envs\\mlp\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-08-37-48/0_\n",
      "Val: 0 3 0.001 1 247 18.906955076724934 54.65587044534413 -0.012027313183830744 0.00019432880197716397\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/1_\n",
      "Val: 1 3 0.001 1 218 -9.593433053516762 50.607287449392715 -0.038044944010464536 0.00018804706080234517\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/2_\n",
      "Val: 2 3 0.001 1 243 10.298968874147286 51.21457489878542 0.011770920479365447 0.00020452177835113166\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/3_\n",
      "Val: 3 3 0.001 1 232 -9.959280213727768 47.97570850202429 -0.054904206315936524 0.00021113992771034656\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/4_\n",
      "Val: 4 3 0.001 1 230 11.978797932944037 50.0 -0.02340183748142567 0.000205015511577252\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/5_\n",
      "Val: 5 3 0.001 1 230 10.149665171021608 51.012145748987855 -0.026175697198647548 0.00019659277476500423\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/6_\n",
      "Val: 6 3 0.001 1 274 6.902106163084292 46.963562753036435 -0.018093199458628792 0.00021912814573839959\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/7_\n",
      "Val: 7 3 0.001 1 216 10.048833166516234 48.78542510121458 -0.02534230773042786 0.00019288375429528747\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/8_\n",
      "Val: 8 3 0.001 1 240 19.843975028666613 50.40485829959514 0.022170340361517424 0.00019443606493803946\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/9_\n",
      "Val: 9 3 0.001 1 218 2.5570280743253955 52.42914979757085 -0.032610446949491556 0.00021539248095999813\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/10_\n",
      "Val: 10 3 0.001 1 212 -12.034831807904126 48.78542510121458 -0.048586850879219864 0.00022707933154965797\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/11_\n",
      "Val: 11 3 0.001 1 220 -4.020295756187673 48.987854251012145 -0.05405680311693637 0.00018608534034061805\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/12_\n",
      "Val: 12 3 0.001 1 221 -1.284225989078119 51.012145748987855 -0.06565145698599685 0.00019352271820728735\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/13_\n",
      "Val: 13 3 0.001 1 226 -0.5300243381282085 48.78542510121458 0.06209128832871398 0.00019898372231237532\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/14_\n",
      "Val: 14 3 0.001 1 247 6.495283774479239 50.607287449392715 -0.002343981413971357 0.00018818237215910186\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/15_\n",
      "Val: 15 3 0.001 1 241 13.878824604731223 54.45344129554656 0.07733708839051302 0.00019888013663851227\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/16_\n",
      "Val: 16 3 0.001 1 233 22.438374948386866 51.821862348178136 -0.010210732871826153 0.00019947140624234125\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/17_\n",
      "Val: 17 3 0.001 1 242 3.3223684048405677 46.963562753036435 0.03068366516766596 0.0001969471575508576\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/18_\n",
      "Val: 18 3 0.001 1 230 0.36963272834318506 54.25101214574899 0.04429975797177777 0.0001885588735540664\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/19_\n",
      "Val: 19 3 0.001 1 230 8.018215594074519 47.77327935222672 -0.05151628563926729 0.0002031439209991331\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/20_\n",
      "Val: 20 3 0.001 1 223 22.6286852396426 48.582995951417004 -0.016164513552087312 0.00019466675493695897\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/21_\n",
      "Val: 21 3 0.001 1 194 -0.45162798475414967 49.59514170040486 -0.01390045276278944 0.0001984182239256747\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/22_\n",
      "Val: 22 3 0.001 1 234 15.853502381420869 52.22672064777328 0.00813995562798157 0.0001920735722001523\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/23_\n",
      "Val: 23 3 0.001 1 221 15.59225935396056 47.36842105263158 -0.055890441392444506 0.00022469917191481552\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-37-48/24_\n",
      "Val: 24 3 0.001 1 228 1.71332872345522 52.63157894736842 0.03443825274665869 0.00023980693897792586\n",
      "750 230.0 6.524923443898738\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/0_\n",
      "Val: 0 3 0.001 1 230 1.3475696691691856 52.42914979757085 0.010110967632544092 0.000210522423203163\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/1_\n",
      "Val: 1 3 0.001 1 242 32.946422169129235 57.89473684210526 0.07961134784292269 0.0001894503771823469\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/2_\n",
      "Val: 2 3 0.001 1 215 16.521744009336167 56.2753036437247 0.08422008674552255 0.00019676655070236657\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/3_\n",
      "Val: 3 3 0.001 1 252 37.89995828240945 55.87044534412956 0.17433393800847782 0.0001863553318750881\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/4_\n",
      "Val: 4 3 0.001 1 228 -0.7130203442906773 56.88259109311741 0.08230969716517418 0.00020100151370662696\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/5_\n",
      "Val: 5 3 0.001 1 260 35.90283290802239 56.88259109311741 0.160990477441527 0.00017004041198537964\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/6_\n",
      "Val: 6 3 0.001 1 239 43.15205849563892 56.68016194331984 0.08177238043722744 0.000172289377273212\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/7_\n",
      "Val: 7 3 0.001 1 242 14.416311066708154 57.89473684210526 0.1608304429879163 0.00018935664575511936\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/8_\n",
      "Val: 8 3 0.001 1 220 24.78628584977736 55.66801619433198 0.09729083772960709 0.00016648084743468508\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/9_\n",
      "Val: 9 3 0.001 1 210 26.42509637387796 54.04858299595141 0.1755736817281729 0.00021327021252941737\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/10_\n",
      "Val: 10 3 0.001 1 245 25.618718095496728 52.63157894736842 0.10109157880025227 0.00017529793054465935\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/11_\n",
      "Val: 11 3 0.001 1 246 13.300253901944602 49.59514170040486 0.013687982974134335 0.00020014347244796618\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-08-45-23/12_\n",
      "Val: 12 3 0.001 1 220 24.969081750957695 55.87044534412956 0.08115633324451639 0.00020651094046361166\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/13_\n",
      "Val: 13 3 0.001 1 237 15.991650978452899 54.04858299595141 0.06454254983403594 0.00021835112882689618\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/14_\n",
      "Val: 14 3 0.001 1 236 33.3793940976012 59.311740890688256 0.1775547069115341 0.0002012032220092522\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/15_\n",
      "Val: 15 3 0.001 1 249 43.420800979967005 59.716599190283404 0.16817927364412608 0.00021602174710860406\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/16_\n",
      "Val: 16 3 0.001 1 211 2.5010808119695134 53.036437246963565 0.10306382192206022 0.00019611150811611863\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/17_\n",
      "Val: 17 3 0.001 1 226 11.142656278451362 56.68016194331984 0.08171332521641543 0.0001977184320906825\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/18_\n",
      "Val: 18 3 0.001 1 241 29.08648367634905 56.477732793522264 0.10004049963308734 0.00018767086629331833\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/19_\n",
      "Val: 19 3 0.001 1 231 19.75055138846252 56.88259109311741 0.12293005977472804 0.00022590450966044644\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/20_\n",
      "Val: 20 3 0.001 1 228 15.816133522667537 51.61943319838057 0.06803072545980081 0.00021263688503577697\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/21_\n",
      "Val: 21 3 0.001 1 219 18.388197843747538 57.28744939271255 0.19285319928291444 0.0001971041547893304\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/22_\n",
      "Val: 22 3 0.001 1 241 12.900893637188272 53.64372469635627 0.056135256847190354 0.00017468149563814117\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/23_\n",
      "Val: 23 3 0.001 1 211 20.93767419497848 54.45344129554656 0.10281340550352806 0.00019688243231990042\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-45-23/24_\n",
      "Val: 24 3 0.001 1 224 20.153812207049725 54.45344129554656 0.11344308071622947 0.0002042466729184422\n",
      "750 232.12 21.60170567380249\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/0_\n",
      "Val: 0 3 0.001 1 247 30.445377196858015 59.10931174089069 0.34211172846340804 0.0001784537151532701\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/1_\n",
      "Val: 1 3 0.001 1 246 21.2960696845861 59.51417004048583 0.2922620628984246 0.0001847726525794126\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/2_\n",
      "Val: 2 3 0.001 1 258 33.20391546815565 59.51417004048583 0.19964498792979068 0.00020370840178448774\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/3_\n",
      "Val: 3 3 0.001 1 223 26.018114199951352 58.70445344129555 0.27236676175487806 0.0001905637481906537\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/4_\n",
      "Val: 4 3 0.001 1 244 32.371414529681225 58.70445344129555 0.2617854268088592 0.00017877541822013183\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/5_\n",
      "Val: 5 3 0.001 1 234 45.68294748334274 61.74089068825911 0.25383637767368644 0.00019413751662159974\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/6_\n",
      "Val: 6 3 0.001 1 228 44.76080996611716 62.550607287449395 0.1550144552049006 0.00019230156079847287\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/7_\n",
      "Val: 7 3 0.001 1 240 35.77600517568862 62.955465587044536 0.26440911257121047 0.00021655144062195057\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/8_\n",
      "Val: 8 3 0.001 1 257 36.66056924921644 58.502024291497975 0.23961519931697722 0.00019211392710726235\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/9_\n",
      "Val: 9 3 0.001 1 223 33.5921340667052 59.91902834008097 0.23423026530583158 0.00021418144465870837\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/10_\n",
      "Val: 10 3 0.001 1 219 31.29266201087823 61.94331983805668 0.22022218951221853 0.00022543615386203547\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/11_\n",
      "Val: 11 3 0.001 1 232 35.08162595447249 59.51417004048583 0.24391808594936548 0.00019665310397614828\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/12_\n",
      "Val: 12 3 0.001 1 250 28.328839921042267 58.502024291497975 0.12432797307694471 0.00019930908596124146\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/13_\n",
      "Val: 13 3 0.001 1 253 24.3234699058728 58.906882591093115 0.23018937548142185 0.00020367674585178083\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/14_\n",
      "Val: 14 3 0.001 1 196 22.009061655782293 61.1336032388664 0.24077294409245587 0.0001854617880493243\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/15_\n",
      "Val: 15 3 0.001 1 244 30.4677232487436 59.10931174089069 0.12926871990464137 0.0001782763312498945\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/16_\n",
      "Val: 16 3 0.001 1 232 28.799085135738785 56.68016194331984 0.19277428199646507 0.00022072567901082677\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/17_\n",
      "Val: 17 3 0.001 1 238 41.60294577644072 62.550607287449395 0.29258573571908203 0.0002072290678011061\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/18_\n",
      "Val: 18 3 0.001 1 241 42.3009612337128 60.32388663967611 0.17324785582135846 0.00022311793255239728\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/19_\n",
      "Val: 19 3 0.001 1 249 15.726577583237543 59.716599190283404 0.2227087257017598 0.00016343037211456808\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/20_\n",
      "Val: 20 3 0.001 1 235 29.713706769568198 59.91902834008097 0.15932373092733584 0.00020128472355268847\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/21_\n",
      "Val: 21 3 0.001 1 235 31.923627365927455 58.70445344129555 0.2726849046101968 0.0001692849946991931\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/22_\n",
      "Val: 22 3 0.001 1 243 45.835933715468 60.931174089068826 0.30378733351951154 0.00017081522082176354\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-08-53-20/23_\n",
      "Val: 23 3 0.001 1 218 41.233339927871256 57.08502024291498 0.15086594813442877 0.00025117119715107965\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-08-53-20/24_\n",
      "Val: 24 3 0.001 1 218 36.20514972304706 60.526315789473685 0.2542338276025989 0.00022913872219390124\n",
      "750 236.12 32.98608267792424\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/0_\n",
      "Val: 0 3 0.001 1 240 43.71196418221878 64.17004048582996 0.3750972625432654 0.00018204916251974003\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/1_\n",
      "Val: 1 3 0.001 1 208 40.70703545176169 63.36032388663968 0.3761610132794404 0.00021415611009434793\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/2_\n",
      "Val: 2 3 0.001 1 265 49.2701981383411 61.74089068825911 0.32328993393932315 0.0001937075594778073\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/3_\n",
      "Val: 3 3 0.001 1 229 9.705467950380175 63.76518218623482 0.3764445384879401 0.0001819379711951969\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/4_\n",
      "Val: 4 3 0.001 1 255 33.55484734059378 66.39676113360323 0.2793430772439769 0.00019740118447803237\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/5_\n",
      "Val: 5 3 0.001 1 239 39.54616970420752 65.9919028340081 0.3840393981766273 0.00017490064989787\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/6_\n",
      "Val: 6 3 0.001 1 227 19.108578766075105 64.17004048582996 0.23696004810616442 0.0002280250767908572\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/7_\n",
      "Val: 7 3 0.001 1 227 30.579692439493474 65.38461538461539 0.33807328028642275 0.0001753690275885355\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/8_\n",
      "Val: 8 3 0.001 1 260 23.696305052163375 61.94331983805668 0.3707874694801601 0.0002028372374169723\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/9_\n",
      "Val: 9 3 0.001 1 261 32.935177463789856 63.1578947368421 0.33559421865154937 0.00020440384058096817\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/10_\n",
      "Val: 10 3 0.001 1 257 48.62446682759523 63.76518218623482 0.2606000606021458 0.00020643101561267126\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/11_\n",
      "Val: 11 3 0.001 1 243 46.821479125577426 67.00404858299595 0.438549845615031 0.00020239910391229419\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/12_\n",
      "Val: 12 3 0.001 1 228 55.46313821802196 67.00404858299595 0.30966335419501045 0.0001873265472326843\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/13_\n",
      "Val: 13 3 0.001 1 262 30.650707308339967 66.19433198380567 0.37511585037797635 0.00018331168438203866\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/14_\n",
      "Val: 14 3 0.001 1 261 42.81231607567196 64.77732793522267 0.3228225109635983 0.00020295212752007643\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/15_\n",
      "Val: 15 3 0.001 1 257 35.54440157871648 58.906882591093115 0.2616738862889432 0.00021153248972586433\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/16_\n",
      "Val: 16 3 0.001 1 235 30.736583705411892 63.96761133603239 0.31142440092675294 0.00020502630250057876\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/17_\n",
      "Val: 17 3 0.001 1 251 48.40043586020822 62.955465587044536 0.4022896396087717 0.00017055188824131553\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/18_\n",
      "Val: 18 3 0.001 1 233 27.115684053678848 63.76518218623482 0.28217359601499453 0.00021639058403838374\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/19_\n",
      "Val: 19 3 0.001 1 243 47.25067593916254 63.1578947368421 0.2870828726250246 0.0002370128272789498\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/20_\n",
      "Val: 20 3 0.001 1 239 53.40988190282527 67.61133603238866 0.34457081176765947 0.00019570896764505767\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/21_\n",
      "Val: 21 3 0.001 1 225 55.235403815144686 65.9919028340081 0.41586396423529204 0.00020879015858413105\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/22_\n",
      "Val: 22 3 0.001 1 238 47.123891513130864 69.02834008097166 0.3231988330404631 0.0001931529521012369\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/23_\n",
      "Val: 23 3 0.001 1 239 38.52697231072189 65.78947368421052 0.3833694221336351 0.00017301123282988337\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-01-09/24_\n",
      "Val: 24 3 0.001 1 235 59.59157727716674 66.59919028340082 0.34969958000761986 0.00023627103901574992\n",
      "750 242.28 39.60492208001595\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/0_\n",
      "Val: 0 3 0.001 1 238 50.46475320229054 70.24291497975709 0.4033251220386254 0.0001846484937887317\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/1_\n",
      "Val: 1 3 0.001 1 253 64.66835715295146 70.64777327935222 0.501202232784558 0.00019222850810384564\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/2_\n",
      "Val: 2 3 0.001 1 247 62.55183929030563 73.48178137651821 0.44125986162291597 0.00021437983023334207\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/3_\n",
      "Val: 3 3 0.001 1 237 49.57999051710134 69.63562753036437 0.47738245206399427 0.00021285732077800263\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/4_\n",
      "Val: 4 3 0.001 1 257 52.319969797966344 69.23076923076923 0.4061000420771865 0.0002124299105816733\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/5_\n",
      "Val: 5 3 0.001 1 263 55.283871033802704 71.05263157894737 0.3267419832877997 0.00023147292474875507\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/6_\n",
      "Val: 6 3 0.001 1 243 42.66678450079161 67.61133603238866 0.36925490574394515 0.00019866454864937805\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/7_\n",
      "Val: 7 3 0.001 1 255 50.43117439163167 65.58704453441295 0.4383009429498217 0.00017791682266100854\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/8_\n",
      "Val: 8 3 0.001 1 233 63.94415183615189 70.04048582995951 0.3702196782230754 0.00018277367849997033\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/9_\n",
      "Val: 9 3 0.001 1 245 45.66048196579617 67.61133603238866 0.4091514368605 0.0001831235130116539\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-09-09-00/10_\n",
      "Val: 10 3 0.001 1 256 57.33700191005537 71.25506072874494 0.47537549209828106 0.0001846640234630816\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/11_\n",
      "Val: 11 3 0.001 1 244 53.26810304302032 68.62348178137651 0.46648357821384806 0.00020068882540650443\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/12_\n",
      "Val: 12 3 0.001 1 251 55.074867353245736 68.62348178137651 0.3701168245961607 0.00017512991244511713\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/13_\n",
      "Val: 13 3 0.001 1 248 55.0860254459809 67.61133603238866 0.4408885134277899 0.00021749728559016548\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/14_\n",
      "Val: 14 3 0.001 1 235 52.264007602402835 65.58704453441295 0.4614590589735348 0.0001771313927264132\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/15_\n",
      "Val: 15 3 0.001 1 255 60.45766747954537 71.86234817813765 0.460900718202335 0.00021577071149498142\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/16_\n",
      "Val: 16 3 0.001 1 236 55.78400954351697 72.46963562753037 0.5788872496208446 0.00019845172545482605\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/17_\n",
      "Val: 17 3 0.001 1 260 80.74945804506022 69.23076923076923 0.5349689563551181 0.00015975357840117692\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/18_\n",
      "Val: 18 3 0.001 1 265 41.72615817920921 72.2672064777328 0.39379655146730475 0.00017763162028394314\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/19_\n",
      "Val: 19 3 0.001 1 247 45.70540553428548 70.04048582995951 0.4167185393098279 0.0001824856112983029\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/20_\n",
      "Val: 20 3 0.001 1 253 64.60489400719942 71.65991902834008 0.4829073989684483 0.00021503362022893535\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/21_\n",
      "Val: 21 3 0.001 1 243 63.72769349835001 71.05263157894737 0.48978595834841254 0.00017733319726094752\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/22_\n",
      "Val: 22 3 0.001 1 238 42.793688392484256 70.24291497975709 0.42032384091061775 0.0002470375138806235\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/23_\n",
      "Val: 23 3 0.001 1 257 57.85952977795733 71.65991902834008 0.4059330715502094 0.000246119532930853\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-09-00/24_\n",
      "Val: 24 3 0.001 1 216 64.04485840171324 70.24291497975709 0.42469310333988103 0.00020577235780926709\n",
      "750 247.0 55.52218967611264\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/0_\n",
      "Val: 0 3 0.001 1 236 66.84087454417985 74.89878542510121 0.597308679109866 0.0002100914920020958\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/1_\n",
      "Val: 1 3 0.001 1 239 64.08603970837248 74.89878542510121 0.5297254766477871 0.0001815264354726521\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/2_\n",
      "Val: 2 3 0.001 1 234 62.428570141348175 74.49392712550608 0.5172189758403184 0.00023026652795626857\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/3_\n",
      "Val: 3 3 0.001 1 251 63.58579069292181 73.48178137651821 0.5600452626994498 0.00022389272061132268\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/4_\n",
      "Val: 4 3 0.001 1 246 74.84415543731158 76.92307692307692 0.612844557393254 0.00019545355354137013\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/5_\n",
      "Val: 5 3 0.001 1 260 63.76126633572583 72.67206477732793 0.5876138458164475 0.00019780722840916732\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/6_\n",
      "Val: 6 3 0.001 1 257 65.03414308701122 75.50607287449392 0.4874457961815946 0.0001974118940459594\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/7_\n",
      "Val: 7 3 0.001 1 239 65.26931572060501 72.46963562753037 0.506828913113232 0.00017698905657641324\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/8_\n",
      "Val: 8 3 0.001 1 239 71.58907009273278 77.7327935222672 0.5167579300089251 0.00022291449520158986\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/9_\n",
      "Val: 9 3 0.001 1 235 56.14242145965297 73.07692307692308 0.6184775522537183 0.00021261892134542931\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/10_\n",
      "Val: 10 3 0.001 1 241 72.8321177617932 71.86234817813765 0.524408607874953 0.00017266357945708424\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/11_\n",
      "Val: 11 3 0.001 1 232 68.0950937458623 72.2672064777328 0.5199325943462267 0.00017905971838723327\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/12_\n",
      "Val: 12 3 0.001 1 240 65.14616902395005 75.91093117408907 0.5921921455620288 0.00017484080948616096\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/13_\n",
      "Val: 13 3 0.001 1 251 66.03450223908168 75.10121457489879 0.49415883200866734 0.00017475329628970313\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/14_\n",
      "Val: 14 3 0.001 1 268 71.89885500488921 76.92307692307692 0.5019508413884136 0.0002034080625557699\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/15_\n",
      "Val: 15 3 0.001 1 241 79.31235782291401 72.8744939271255 0.5979379513952979 0.00018741479424451586\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/16_\n",
      "Val: 16 3 0.001 1 245 77.52440188768853 76.51821862348179 0.6179821589020118 0.00020559713242213399\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/17_\n",
      "Val: 17 3 0.001 1 240 66.92669419506282 73.27935222672065 0.45358240802791844 0.00018843399237436823\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/18_\n",
      "Val: 18 3 0.001 1 266 76.87116813343336 77.32793522267207 0.6256502332682065 0.00020347935336248357\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/19_\n",
      "Val: 19 3 0.001 1 250 59.5991484134311 75.10121457489879 0.5123655978761895 0.00023912554561952298\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/20_\n",
      "Val: 20 3 0.001 1 235 60.07323743576953 74.49392712550608 0.5238685701006733 0.00019750976406399934\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/21_\n",
      "Val: 21 3 0.001 1 231 53.62271744445805 74.89878542510121 0.433207846342522 0.00021096932414252085\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-09-16-37/22_\n",
      "Val: 22 3 0.001 1 268 76.58366954033202 75.30364372469636 0.5595791979792173 0.0002067364550117651\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/23_\n",
      "Val: 23 3 0.001 1 247 75.51611244728325 72.06477732793522 0.4337039673651633 0.0002989888092951921\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-16-37/24_\n",
      "Val: 24 3 0.001 1 251 55.56759899197948 75.91093117408907 0.5334642307739766 0.00019426006501735259\n",
      "750 245.68 67.16741965231162\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/0_\n",
      "Val: 0 3 0.001 1 229 94.11323631890812 84.21052631578948 0.6635383607927144 0.00020467644953253098\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/1_\n",
      "Val: 1 3 0.001 1 234 78.80478854908704 79.35222672064778 0.6585724525034423 0.00019649596265947357\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/2_\n",
      "Val: 2 3 0.001 1 235 75.16890193018452 84.61538461538461 0.7301877741079468 0.0001718804787896477\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/3_\n",
      "Val: 3 3 0.001 1 229 89.23068222141765 79.95951417004049 0.6599227023727718 0.00019109052925719513\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/4_\n",
      "Val: 4 3 0.001 1 243 85.74412469209376 79.1497975708502 0.6213074958868128 0.00021851123185945376\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/5_\n",
      "Val: 5 3 0.001 1 239 86.98344503253172 79.75708502024291 0.5838592374575056 0.0002272885804752455\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/6_\n",
      "Val: 6 3 0.001 1 242 85.88962490723812 77.32793522267207 0.6640400640175094 0.0002472498675306184\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/7_\n",
      "Val: 7 3 0.001 1 254 58.169326636679855 78.34008097165992 0.6254841490650441 0.00017306574923868856\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/8_\n",
      "Val: 8 3 0.001 1 241 98.39485424855651 81.17408906882591 0.6301104574577512 0.00018195219312809995\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/9_\n",
      "Val: 9 3 0.001 1 248 88.45051769569609 81.98380566801619 0.6635335182674786 0.00019835199100777596\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/10_\n",
      "Val: 10 3 0.001 1 237 70.33110564257873 78.34008097165992 0.5560794642614624 0.0001995229723472051\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/11_\n",
      "Val: 11 3 0.001 1 240 75.54594451614975 77.32793522267207 0.5660882243797503 0.00021780470432654312\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/12_\n",
      "Val: 12 3 0.001 1 249 99.10029748329977 82.99595141700405 0.7282694357520102 0.00020334140288584966\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/13_\n",
      "Val: 13 3 0.001 1 245 92.63502348285775 79.35222672064778 0.64687878400775 0.0001766095848722243\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/14_\n",
      "Val: 14 3 0.001 1 236 79.09964921354602 80.36437246963563 0.7455937801346552 0.0001963694678449289\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/15_\n",
      "Val: 15 3 0.001 1 211 84.17632306355662 79.1497975708502 0.7368746038787807 0.00017474798562538277\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/16_\n",
      "Val: 16 3 0.001 1 253 68.47963578869529 78.94736842105263 0.7252897365226444 0.00019334500044587653\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/17_\n",
      "Val: 17 3 0.001 1 249 83.10874357069642 80.56680161943319 0.6298687253308328 0.00020190861911146055\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/18_\n",
      "Val: 18 3 0.001 1 247 91.41805666090917 82.38866396761134 0.7706881112164851 0.000223504207488764\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/19_\n",
      "Val: 19 3 0.001 1 241 84.68028298110137 79.95951417004049 0.710489257629941 0.0001947557468894566\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/20_\n",
      "Val: 20 3 0.001 1 247 81.38416267529801 79.95951417004049 0.6234582403521266 0.0002033385058621199\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/21_\n",
      "Val: 21 3 0.001 1 263 85.64329119426762 80.76923076923077 0.5838362032267079 0.00017491348226190596\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/22_\n",
      "Val: 22 3 0.001 1 243 90.81715931940688 81.98380566801619 0.7345883580671455 0.00019098184147041953\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/23_\n",
      "Val: 23 3 0.001 1 237 77.59154457579864 81.37651821862349 0.6285526391598706 0.00018930031314666379\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-24-14/24_\n",
      "Val: 24 3 0.001 1 233 82.71303895516596 79.75708502024291 0.6561040802530351 0.0002097125878575076\n",
      "750 241.0 83.50695045422884\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/0_\n",
      "Val: 0 3 0.001 1 245 95.97220264301782 88.46153846153847 0.794916703125269 0.00019384044242689024\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/1_\n",
      "Val: 1 3 0.001 1 237 102.72122252148579 88.46153846153847 0.7767283580557737 0.0001851642226905845\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/2_\n",
      "Val: 2 3 0.001 1 253 87.28207035863223 85.22267206477733 0.7364395042890972 0.0001984534317524569\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/3_\n",
      "Val: 3 3 0.001 1 247 94.01616598940274 84.41295546558705 0.7279556981900474 0.0002004345833670561\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/4_\n",
      "Val: 4 3 0.001 1 247 105.16626796517444 84.41295546558705 0.7775250361535063 0.00021257243171847738\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/5_\n",
      "Val: 5 3 0.001 1 239 86.99089222317284 84.81781376518218 0.7642825794174791 0.0001916512582990554\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/6_\n",
      "Val: 6 3 0.001 1 244 99.03690004366128 86.84210526315789 0.7922076833376407 0.00019924140920047424\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/7_\n",
      "Val: 7 3 0.001 1 233 89.6748465890023 85.62753036437248 0.7067668078679363 0.00019830994786585888\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-09-31-50/8_\n",
      "Val: 8 3 0.001 1 232 88.23030813613956 84.61538461538461 0.7416850221088753 0.00018666965781007685\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/9_\n",
      "Val: 9 3 0.001 1 255 88.87606781997991 85.62753036437248 0.7610994857056502 0.00018126012064743446\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/10_\n",
      "Val: 10 3 0.001 1 250 82.17552113345302 86.03238866396761 0.6705428601862746 0.00022201002966106722\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/11_\n",
      "Val: 11 3 0.001 1 245 97.12574962551643 86.43724696356276 0.765126936769635 0.00022531135272719336\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/12_\n",
      "Val: 12 3 0.001 1 247 75.43396039219226 81.57894736842105 0.654971333109397 0.00019173722239949756\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/13_\n",
      "Val: 13 3 0.001 1 243 88.89101745413032 85.02024291497976 0.7620725373664256 0.00018601854962059365\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/14_\n",
      "Val: 14 3 0.001 1 239 88.48776260882616 84.61538461538461 0.7636977349885236 0.00023523904637524237\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/15_\n",
      "Val: 15 3 0.001 1 251 89.94368165921765 82.5910931174089 0.7648972495876358 0.0001782942473363964\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/16_\n",
      "Val: 16 3 0.001 1 245 88.6184595352548 85.82995951417004 0.7017067196838955 0.00017954757677522305\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/17_\n",
      "Val: 17 3 0.001 1 243 93.46746468850168 86.23481781376518 0.7118467149810953 0.00020764052982602757\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/18_\n",
      "Val: 18 3 0.001 1 219 90.35427169610573 85.82995951417004 0.6957614190634426 0.00023164522675835127\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/19_\n",
      "Val: 19 3 0.001 1 229 91.01871431600199 81.57894736842105 0.7186891835548529 0.0001849136850559164\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/20_\n",
      "Val: 20 3 0.001 1 227 102.74738848788108 87.24696356275304 0.7925838831263707 0.00019675171257350555\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/21_\n",
      "Val: 21 3 0.001 1 233 92.37750330405761 86.43724696356276 0.7697354812393873 0.00023053721690475222\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/22_\n",
      "Val: 22 3 0.001 1 223 93.39654539218397 85.22267206477733 0.6515231336820979 0.00021678159797990277\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/23_\n",
      "Val: 23 3 0.001 1 258 83.09386412262185 85.22267206477733 0.7518253647959579 0.0001861041309707055\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-31-50/24_\n",
      "Val: 24 3 0.001 1 238 98.71592717235441 83.80566801619433 0.7634032494392267 0.00018033886258886142\n",
      "750 240.88 91.75259103511873\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/0_\n",
      "Val: 0 3 0.001 1 224 102.33306514908747 91.70040485829959 0.7982567633979755 0.00019117756713286796\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/1_\n",
      "Val: 1 3 0.001 1 223 104.59892703451958 90.89068825910931 0.8350469284321304 0.00020945552009322656\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/2_\n",
      "Val: 2 3 0.001 1 241 104.87877534535616 91.70040485829959 0.8604642235757103 0.00020370774194908146\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/3_\n",
      "Val: 3 3 0.001 1 239 100.38823437447196 89.47368421052632 0.8513852325818613 0.00019295901860388\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/4_\n",
      "Val: 4 3 0.001 1 233 87.30449256987669 89.47368421052632 0.8076191230051206 0.00018766368469211214\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/5_\n",
      "Val: 5 3 0.001 1 241 106.23385343131768 91.49797570850203 0.8512816932504653 0.00018994856955482217\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/6_\n",
      "Val: 6 3 0.001 1 229 95.12864963758233 87.24696356275304 0.8303688860834539 0.00020636741054599794\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/7_\n",
      "Val: 7 3 0.001 1 253 115.75649710742304 89.87854251012146 0.8673693859930751 0.0001754744100154503\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/8_\n",
      "Val: 8 3 0.001 1 235 111.26954607965119 91.70040485829959 0.8782893330835694 0.00021264219229930802\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/9_\n",
      "Val: 9 3 0.001 1 245 105.01327426644536 89.87854251012146 0.8363250842825191 0.0001812580426243772\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/10_\n",
      "Val: 10 3 0.001 1 240 93.3443150052052 88.25910931174089 0.84321148929557 0.00018757994520410303\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/11_\n",
      "Val: 11 3 0.001 1 245 89.70100210215226 87.24696356275304 0.7346820541736473 0.00018626243388503229\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/12_\n",
      "Val: 12 3 0.001 1 227 106.86473068044195 90.89068825910931 0.8156958632987259 0.00018372419129959\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/13_\n",
      "Val: 13 3 0.001 1 231 107.14095470178866 89.47368421052632 0.7936867300165962 0.00019648022217229856\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/14_\n",
      "Val: 14 3 0.001 1 230 91.03365051026553 89.67611336032388 0.8004847966053864 0.0001613021992127209\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/15_\n",
      "Val: 15 3 0.001 1 253 96.03566429544911 89.67611336032388 0.8095442382567467 0.00016452092433319565\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/16_\n",
      "Val: 16 3 0.001 1 249 102.94898679077828 91.09311740890688 0.8210670001209149 0.00021899729096382895\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/17_\n",
      "Val: 17 3 0.001 1 245 113.77060747845078 92.10526315789474 0.8604868897131297 0.00019271653249732548\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/18_\n",
      "Val: 18 3 0.001 1 245 106.96183236968335 90.68825910931174 0.7896635142107209 0.00020481923282835424\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/19_\n",
      "Val: 19 3 0.001 1 255 95.04273740081213 90.08097165991903 0.818309652860081 0.00019088685357748455\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-09-39-23/20_\n",
      "Val: 20 3 0.001 1 233 103.6918377106147 89.06882591093117 0.8211216049654335 0.0001959261303046462\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/21_\n",
      "Val: 21 3 0.001 1 239 106.9207779952889 89.27125506072875 0.8387391333416466 0.00020848000294192278\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/22_\n",
      "Val: 22 3 0.001 1 241 86.68483911960114 87.4493927125506 0.7446549827577189 0.0002262607383759258\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/23_\n",
      "Val: 23 3 0.001 1 241 103.038600969718 88.46153846153847 0.8455458303322488 0.00017781692818234654\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-39-23/24_\n",
      "Val: 24 3 0.001 1 251 106.60352647932146 89.67611336032388 0.9009192383248381 0.00021091821580886122\n",
      "750 239.52 101.70757514421211\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/0_\n",
      "Val: 0 3 0.001 1 233 114.59554474726467 94.33198380566802 0.9206355975554759 0.0001951081518700953\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/1_\n",
      "Val: 1 3 0.001 1 233 116.54781524591748 95.34412955465586 0.8669036484957907 0.00021008414431129902\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/2_\n",
      "Val: 2 3 0.001 1 234 119.70582130106634 95.74898785425101 0.9405887918050684 0.00018539676925327674\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/3_\n",
      "Val: 3 3 0.001 1 231 116.51425584842852 93.92712550607287 0.9251132128462156 0.00019185840956400797\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/4_\n",
      "Val: 4 3 0.001 1 227 125.20808260837981 95.95141700404858 0.930757885007035 0.0001865639231915964\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/5_\n",
      "Val: 5 3 0.001 1 225 111.3703213379676 93.92712550607287 0.9199670748241465 0.00017906879659317868\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/6_\n",
      "Val: 6 3 0.001 1 231 114.39398228406576 94.73684210526316 0.9617942850778854 0.00019102731408966535\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/7_\n",
      "Val: 7 3 0.001 1 247 113.10609168583719 94.73684210526316 0.9367105635818368 0.00018466893106546052\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/8_\n",
      "Val: 8 3 0.001 1 241 116.02150180988333 95.1417004048583 0.9175022424287671 0.0002031636013802433\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/9_\n",
      "Val: 9 3 0.001 1 233 117.66393961011534 95.34412955465586 0.9260671264420897 0.0001824429776762051\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/10_\n",
      "Val: 10 3 0.001 1 241 104.53169474716374 94.33198380566802 0.9015245833310238 0.00021448113716211056\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/11_\n",
      "Val: 11 3 0.001 1 233 111.93777725432116 93.92712550607287 0.9119363114486537 0.00018732464086905774\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/12_\n",
      "Val: 12 3 0.001 1 237 113.6436901468713 95.74898785425101 0.9223658956055212 0.0001973911453896697\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/13_\n",
      "Val: 13 3 0.001 1 229 111.81080317655268 95.34412955465586 0.9545954527556513 0.0001781921274873768\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/14_\n",
      "Val: 14 3 0.001 1 227 110.33262170023829 93.7246963562753 0.904696079974102 0.0001880652874981002\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/15_\n",
      "Val: 15 3 0.001 1 227 113.46447672219948 94.33198380566802 0.9263039186041178 0.0002086671931708394\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/16_\n",
      "Val: 16 3 0.001 1 233 115.3943847424383 95.74898785425101 0.9147551259833285 0.00020834492037420687\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/17_\n",
      "Val: 17 3 0.001 1 234 111.04563159128364 94.12955465587045 0.9149492633372602 0.0001777835689996937\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/18_\n",
      "Val: 18 3 0.001 1 239 112.3147481608898 94.93927125506073 0.9245328899453281 0.00017720593666572824\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/19_\n",
      "Val: 19 3 0.001 1 231 114.26701417958033 94.93927125506073 0.8838069157447975 0.00019739558290540198\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/20_\n",
      "Val: 20 3 0.001 1 241 113.48688698687782 94.93927125506073 0.9249195769621024 0.00022018040592292716\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/21_\n",
      "Val: 21 3 0.001 1 237 108.14886109699128 94.93927125506073 0.9113517683993706 0.00016910829583942417\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/22_\n",
      "Val: 22 3 0.001 1 239 109.18292300534387 94.73684210526316 0.894969670834675 0.00019963116649521386\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/23_\n",
      "Val: 23 3 0.001 1 239 115.80503301883613 96.96356275303644 0.9007060717998102 0.00017396558991850805\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-46-57/24_\n",
      "Val: 24 3 0.001 1 235 105.47242261455796 93.52226720647774 0.8745037838818392 0.0001992164162141554\n",
      "750 234.28 113.43865302492287\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch750.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict750.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/0_\n",
      "Val: 0 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00019848225920781452\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/1_\n",
      "Val: 1 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00019677103694122156\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/2_\n",
      "Val: 2 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00019216322966442246\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/3_\n",
      "Val: 3 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00021332177293096485\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/4_\n",
      "Val: 4 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00019512641498568866\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/5_\n",
      "Val: 5 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00018474391444874754\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/6_\n",
      "Val: 6 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00018982616410139668\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-09-54-28/7_\n",
      "Val: 7 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00017645553390966884\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/8_\n",
      "Val: 8 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00019526949133782484\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/9_\n",
      "Val: 9 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00018007028907294912\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/10_\n",
      "Val: 10 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00018817647228185116\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/11_\n",
      "Val: 11 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00021583165486500713\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/12_\n",
      "Val: 12 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00016684036809141124\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/13_\n",
      "Val: 13 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00022083070983402065\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/14_\n",
      "Val: 14 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00018922974601956433\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/15_\n",
      "Val: 15 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00017357674585286267\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/16_\n",
      "Val: 16 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.0002430190469643997\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/17_\n",
      "Val: 17 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00020637907050129027\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/18_\n",
      "Val: 18 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.0001704121121648448\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/19_\n",
      "Val: 19 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.0001890660277766386\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/20_\n",
      "Val: 20 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00019842503479717037\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/21_\n",
      "Val: 21 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00020500140836006368\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/22_\n",
      "Val: 22 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00017505904964224185\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/23_\n",
      "Val: 23 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00024445723937005146\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-18 00:00:00\n",
      "Valid Length: 507\n",
      "2021-03-17-09-54-28/24_\n",
      "Val: 24 3 0.001 1 231 125.62992183056957 99.59514170040485 1.0 0.00025226566274442596\n",
      "750 231.0 125.62992183056957\n"
     ]
    }
   ],
   "source": [
    "saved_fn = 'Ch15 - CH16 - Exp8 - Expanding training period/3 year partial - 2021-03-16-13-05-13/saved_models'\n",
    "for drunk_genius_accuracy in np.arange(0,1.1,0.1):\n",
    "    run_trading_trials(predictor=\"drunk_genius\", drunk_genius_accuracy=drunk_genius_accuracy, valid_start='12-13-2017', valid_end='12-18-2019',savedfn=savedfn, model_num=750, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch1050.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict1050.pkl\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ND\\Anaconda3\\envs\\mlp\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-18-02-07/0_\n",
      "Val: 0 3 0.001 1 73 -18.694769470467115 51.888667992047715 -0.006991849304677796 0.0043355595822443934\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/1_\n",
      "Val: 1 3 0.001 1 108 9.29975998748533 54.27435387673956 0.0029968163903502845 0.0036985772455767514\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/2_\n",
      "Val: 2 3 0.001 1 76 -7.647854057124448 50.89463220675945 0.018644999197724204 0.0032595657856788578\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/3_\n",
      "Val: 3 3 0.001 1 93 -14.269216941748885 49.90059642147117 -0.000224466943508298 0.004915943413500126\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/4_\n",
      "Val: 4 3 0.001 1 92 -26.45141909826697 46.71968190854871 -0.035545937447736736 0.002924730723409767\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/5_\n",
      "Val: 5 3 0.001 1 119 -17.03605650815021 49.30417495029821 0.003802422651785665 0.003922856943304491\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/6_\n",
      "Val: 6 3 0.001 1 84 17.27392460925496 50.69582504970179 0.026871938048847764 0.0029970910672479363\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/7_\n",
      "Val: 7 3 0.001 1 94 9.564869814160772 51.29224652087475 -0.012300349420199213 0.0026362816554925264\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/8_\n",
      "Val: 8 3 0.001 1 106 3.915702299798263 48.31013916500994 0.0023376078118297955 0.003209587558132819\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/9_\n",
      "Val: 9 3 0.001 1 94 18.10332188365326 49.90059642147117 0.011779294838069969 0.00416865715744839\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/10_\n",
      "Val: 10 3 0.001 1 95 17.226370569789136 48.111332007952285 0.02189718391815877 0.004820144708156546\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/11_\n",
      "Val: 11 3 0.001 1 96 -4.418753655410179 47.912524850894634 -0.027236624304823348 0.003649614767879843\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/12_\n",
      "Val: 12 3 0.001 1 91 -8.048957667256822 48.9065606361829 0.013035825614136189 0.003519910706682787\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/13_\n",
      "Val: 13 3 0.001 1 95 1.713142022471824 50.29821073558648 0.019821843894686636 0.003855380497739222\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/14_\n",
      "Val: 14 3 0.001 1 99 2.216182499886447 48.508946322067594 -0.0026960167619999565 0.003149655410151615\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/15_\n",
      "Val: 15 3 0.001 1 102 -12.420119209510654 48.31013916500994 -0.03004927268707015 0.0027137538614148294\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/16_\n",
      "Val: 16 3 0.001 1 107 -2.216166182590508 50.49701789264414 0.019482224127667175 0.004511259731020301\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/17_\n",
      "Val: 17 3 0.001 1 110 3.9225120513036056 48.111332007952285 -0.003022922748039723 0.0033159805702476577\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/18_\n",
      "Val: 18 3 0.001 1 91 -14.445952293616973 51.29224652087475 -0.018441078147585364 0.005774925807730355\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/19_\n",
      "Val: 19 3 0.001 1 88 9.333806025462719 48.31013916500994 0.012468652533060356 0.00259664166370923\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/20_\n",
      "Val: 20 3 0.001 1 81 -24.751882981059218 49.10536779324055 0.001592913058061845 0.0033972455869734092\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/21_\n",
      "Val: 21 3 0.001 1 107 12.542488050858253 48.70775347912525 0.015714216523270135 0.002741679221901701\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/22_\n",
      "Val: 22 3 0.001 1 109 -5.458910563259371 48.31013916500994 0.010201421417742268 0.0033670025645087965\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/23_\n",
      "Val: 23 3 0.001 1 108 19.225005441113936 53.47912524850894 0.00472606669685683 0.003388597251790023\n",
      "Valid Start Date: 2007-12-14 00:00:00\n",
      "Valid End Date: 2009-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-02-07/24_\n",
      "Val: 24 3 0.001 1 63 -6.152303176003445 51.0934393638171 0.029779371736379966 0.0037232492834417953\n",
      "1050 95.24 -1.5070110619690522\n"
     ]
    }
   ],
   "source": [
    "# 2008\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2008 - 2021-03-03-17-09-15 LR1E-4 LRD0 - baseline from CH15 Exp2/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-14-2007', valid_end='12-31-2009',savedfn=savedfn, model_num=1050, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch850.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict850.pkl\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ND\\Anaconda3\\envs\\mlp\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-18-21-03/0_\n",
      "Val: 0 3 0.001 1 77 12.9585054771556 46.3220675944334 0.07596194857855629 0.005800155911935785\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/1_\n",
      "Val: 1 3 0.001 1 86 30.499374501096646 53.28031809145129 0.06738764633190543 0.0035737333870778745\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/2_\n",
      "Val: 2 3 0.001 1 93 14.066971791465665 48.508946322067594 0.08917500249795342 0.004439595097556912\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/3_\n",
      "Val: 3 3 0.001 1 42 -9.633207105656567 45.32803180914513 0.06421463019691313 0.0069895100811285015\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/4_\n",
      "Val: 4 3 0.001 1 72 26.36272982295253 51.491053677932406 0.054551921071041225 0.00718673135270485\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/5_\n",
      "Val: 5 3 0.001 1 81 22.168864571903697 50.29821073558648 0.04724539261212242 0.006209585758400068\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/6_\n",
      "Val: 6 3 0.001 1 99 40.246881038273294 52.68389662027833 0.11210501611069919 0.005725932308777536\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/7_\n",
      "Val: 7 3 0.001 1 64 4.388068684630251 46.91848906560636 0.08360900848817857 0.004335592137664281\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/8_\n",
      "Val: 8 3 0.001 1 92 16.341019850130667 49.10536779324055 0.05441483201501671 0.0052088794428496255\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/9_\n",
      "Val: 9 3 0.001 1 96 27.642533284539834 46.91848906560636 0.05353178982333642 0.007137800530806625\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/10_\n",
      "Val: 10 3 0.001 1 99 -3.782422954720325 47.31610337972167 0.041953171383823665 0.0047242062930609695\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/11_\n",
      "Val: 11 3 0.001 1 93 29.276709326697667 50.69582504970179 0.04074991183007499 0.003672503454614383\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/12_\n",
      "Val: 12 3 0.001 1 86 30.53367850198161 47.912524850894634 0.07300133305376365 0.006069524496561167\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/13_\n",
      "Val: 13 3 0.001 1 104 42.88644224922481 51.0934393638171 0.07883915546000493 0.005085677369427933\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/14_\n",
      "Val: 14 3 0.001 1 86 15.449568398561922 47.31610337972167 0.05538400700697835 0.0049947351823788596\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/15_\n",
      "Val: 15 3 0.001 1 74 22.52312743818569 45.52683896620278 0.07957116314091141 0.005926443029717389\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/16_\n",
      "Val: 16 3 0.001 1 94 20.454734241968946 50.89463220675945 0.08397131660811062 0.004049293559063791\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/17_\n",
      "Val: 17 3 0.001 1 78 16.352416421853242 49.90059642147117 0.03480360878999212 0.003899714338782814\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/18_\n",
      "Val: 18 3 0.001 1 79 10.101655117741405 50.09940357852883 0.014616092257326086 0.007949785305724546\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/19_\n",
      "Val: 19 3 0.001 1 77 -5.085129274041319 45.32803180914513 0.06842952003106763 0.008338944136086828\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/20_\n",
      "Val: 20 3 0.001 1 63 37.275722104481645 54.07554671968191 0.06551853388490887 0.004669844187008336\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/21_\n",
      "Val: 21 3 0.001 1 85 18.30648732940646 50.09940357852883 0.0754135309618357 0.005459481263388638\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/22_\n",
      "Val: 22 3 0.001 1 81 -1.9541029075540397 49.50298210735586 0.03291605763414478 0.0057588018191261385\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/23_\n",
      "Val: 23 3 0.001 1 69 -13.015639192915225 42.54473161033797 0.0708142813020508 0.0063579422840429585\n",
      "Valid Start Date: 2008-12-15 00:00:00\n",
      "Valid End Date: 2010-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-21-03/24_\n",
      "Val: 24 3 0.001 1 41 53.308216232367364 56.858846918489064 0.09760372266704426 0.005909193056017494\n",
      "850 80.44 18.306928197989258\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch650.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict650.pkl\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/0_\n",
      "Val: 0 3 0.001 1 69 -0.39825451872685647 49.007936507936506 0.01836002408347604 0.006784953057018983\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/1_\n",
      "Val: 1 3 0.001 1 89 -3.7607093776524096 49.007936507936506 0.01053164840479385 0.009332462291408983\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/2_\n",
      "Val: 2 3 0.001 1 102 -2.017538757761365 51.388888888888886 0.02392473544924542 0.008780564628040076\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/3_\n",
      "Val: 3 3 0.001 1 105 -12.326335593923655 50.595238095238095 0.01608478733386548 0.008355466417280114\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/4_\n",
      "Val: 4 3 0.001 1 101 -5.769373570256551 47.817460317460316 0.010963506301166845 0.007630971553310688\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/5_\n",
      "Val: 5 3 0.001 1 85 2.389166041102249 52.182539682539684 0.03156002510572151 0.009466619979059367\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/6_\n",
      "Val: 6 3 0.001 1 109 -0.24778338145598178 49.801587301587304 0.006358171702715375 0.00856278894678253\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/7_\n",
      "Val: 7 3 0.001 1 59 -10.954763938059072 50.3968253968254 0.025783785136145668 0.01231963915827282\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/8_\n",
      "Val: 8 3 0.001 1 71 14.388172839270776 52.57936507936508 0.026873221114793896 0.009533637394571078\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/9_\n",
      "Val: 9 3 0.001 1 86 5.344619253058625 48.214285714285715 0.02550592138054237 0.008666085525769376\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/10_\n",
      "Val: 10 3 0.001 1 95 10.414994265247529 52.57936507936508 0.026760498188218865 0.008631640568560013\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/11_\n",
      "Val: 11 3 0.001 1 85 -3.2209715640695924 46.62698412698413 0.02511507041051887 0.008141086129913608\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/12_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: 12 3 0.001 1 119 15.0252228970387 53.37301587301587 0.02028764379704021 0.009170862818661253\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/13_\n",
      "Val: 13 3 0.001 1 95 19.246117594146174 52.57936507936508 0.016177727276095268 0.007814309222277195\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/14_\n",
      "Val: 14 3 0.001 1 87 -12.618346664679336 48.01587301587302 -0.0004410918628924303 0.010200755227692948\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/15_\n",
      "Val: 15 3 0.001 1 97 8.052430680131133 48.41269841269841 0.0242897331648615 0.009355385775695862\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/16_\n",
      "Val: 16 3 0.001 1 95 -12.503320689322813 53.17460317460318 0.00721448136441386 0.009327812246762972\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/17_\n",
      "Val: 17 3 0.001 1 103 -5.742873771785481 50.992063492063494 0.022275206586499743 0.009724961625505176\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/18_\n",
      "Val: 18 3 0.001 1 83 -17.46749827242648 46.23015873015873 0.016998412380879572 0.009603797310058915\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/19_\n",
      "Val: 19 3 0.001 1 95 -1.5131611481496292 53.76984126984127 0.013639557762961758 0.005918370110140158\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/20_\n",
      "Val: 20 3 0.001 1 103 3.442159569368328 50.79365079365079 0.009317749464196837 0.005823881334470994\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/21_\n",
      "Val: 21 3 0.001 1 69 -14.23764860328536 47.817460317460316 0.015143412091949906 0.01053178322367642\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/22_\n",
      "Val: 22 3 0.001 1 95 -7.388749847062933 46.82539682539682 0.028137162757778254 0.008626088788243811\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/23_\n",
      "Val: 23 3 0.001 1 71 -0.34502482735503204 46.62698412698413 0.018900111740142334 0.009242555728190476\n",
      "Valid Start Date: 2009-12-14 00:00:00\n",
      "Valid End Date: 2011-12-30 00:00:00\n",
      "Valid Length: 517\n",
      "2021-03-17-18-28-31/24_\n",
      "Val: 24 3 0.001 1 91 9.892973722750433 50.595238095238095 0.01100453284352801 0.009011787432812415\n",
      "650 90.36 -0.8926599065543442\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch700.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict700.pkl\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/0_\n",
      "Val: 0 3 0.001 1 59 -4.487661323673044 49.10536779324055 -0.008056376790164842 0.005343031377202279\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/1_\n",
      "Val: 1 3 0.001 1 95 8.98332038410144 48.31013916500994 0.009565939196841372 0.006033842622728353\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/2_\n",
      "Val: 2 3 0.001 1 100 -0.7704835931311287 48.508946322067594 0.007847340500150093 0.004700234514940017\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/3_\n",
      "Val: 3 3 0.001 1 89 -2.073075645747601 44.93041749502982 0.009831329070462745 0.005316642218404829\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/4_\n",
      "Val: 4 3 0.001 1 89 -18.19698003523989 44.135188866799204 0.001524197458050153 0.004963040908365587\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/5_\n",
      "Val: 5 3 0.001 1 67 -6.830832963626093 48.70775347912525 0.015409516756337178 0.00555254018758874\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/6_\n",
      "Val: 6 3 0.001 1 71 -0.15092431482148097 49.90059642147117 0.0072350201233431595 0.0077288496403162925\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/7_\n",
      "Val: 7 3 0.001 1 93 8.752984294552212 47.713717693836976 0.0076212273020411425 0.00502442949208713\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/8_\n",
      "Val: 8 3 0.001 1 85 16.41780294469668 45.92445328031809 0.006643156154476687 0.004673909039234133\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/9_\n",
      "Val: 9 3 0.001 1 71 37.81567296267565 54.87077534791253 0.032049963136168605 0.006234671662742137\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/10_\n",
      "Val: 10 3 0.001 1 98 -0.1985802766239268 49.10536779324055 0.0064003391406552155 0.0048728412656201614\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/11_\n",
      "Val: 11 3 0.001 1 70 5.925325204550629 54.67196819085487 0.004190079416715177 0.0060417804330297215\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/12_\n",
      "Val: 12 3 0.001 1 101 21.286746915154925 48.9065606361829 0.013225698545763874 0.005144125821911733\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/13_\n",
      "Val: 13 3 0.001 1 98 -8.133412306291424 45.52683896620278 0.005637303366428894 0.004712845949331206\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/14_\n",
      "Val: 14 3 0.001 1 98 -14.16203763873894 48.111332007952285 -0.007428934607171816 0.004810042713160657\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/15_\n",
      "Val: 15 3 0.001 1 107 -2.859494340121513 45.92445328031809 0.0063145431178495935 0.0037344966733432\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/16_\n",
      "Val: 16 3 0.001 1 108 11.088193150115547 47.31610337972167 0.012568487760436113 0.00403203656365642\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/17_\n",
      "Val: 17 3 0.001 1 89 15.067548575302188 48.70775347912525 0.02318119739855288 0.007178853554679797\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/18_\n",
      "Val: 18 3 0.001 1 96 7.3311951426494915 46.71968190854871 -0.0030854883252709004 0.006249562601829086\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/19_\n",
      "Val: 19 3 0.001 1 122 16.838737461553404 51.888667992047715 0.008186758689112492 0.006447762209340954\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/20_\n",
      "Val: 20 3 0.001 1 93 7.688668873460184 49.30417495029821 0.00671684400421989 0.0063289286064893546\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/21_\n",
      "Val: 21 3 0.001 1 110 13.463085650628258 48.31013916500994 0.02035434557985819 0.004167603299699072\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/22_\n",
      "Val: 22 3 0.001 1 89 -13.693355012933996 46.12326043737575 0.003622160359136692 0.00443251464128206\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-36-02/23_\n",
      "Val: 23 3 0.001 1 85 4.75773825295178 47.912524850894634 0.0036784008704943824 0.005464736122786863\n",
      "Valid Start Date: 2010-12-13 00:00:00\n",
      "Valid End Date: 2012-12-31 00:00:00\n",
      "Valid Length: 516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-18-36-02/24_\n",
      "Val: 24 3 0.001 1 104 -6.664008499927466 45.52683896620278 0.01342805261481058 0.0043335447642798884\n",
      "700 91.48 3.887846954460636\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch450.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict450.pkl\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/0_\n",
      "Val: 0 3 0.001 1 91 30.44028627562901 50.398406374501995 0.034594999276304404 0.008837043515170676\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/1_\n",
      "Val: 1 3 0.001 1 84 31.01735896677717 50.0 0.030148826994522173 0.00898281383522813\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/2_\n",
      "Val: 2 3 0.001 1 97 30.076598766081712 51.59362549800797 0.025936307756561937 0.010267921685706276\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/3_\n",
      "Val: 3 3 0.001 1 94 35.016990708981574 50.398406374501995 0.03036191628036929 0.008069051257538144\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/4_\n",
      "Val: 4 3 0.001 1 99 32.89858034578153 52.98804780876494 0.03673895163320871 0.007728153112934968\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/5_\n",
      "Val: 5 3 0.001 1 97 29.096506548034974 51.39442231075697 0.02350470588736562 0.00855201774123534\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/6_\n",
      "Val: 6 3 0.001 1 108 24.764855802683922 48.20717131474104 0.02712388519249554 0.00778275610860427\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/7_\n",
      "Val: 7 3 0.001 1 109 39.45931452126005 52.58964143426295 0.037927614047895485 0.006923281298370249\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/8_\n",
      "Val: 8 3 0.001 1 96 41.5382395020249 49.40239043824701 0.032537283332919456 0.00877839111813664\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/9_\n",
      "Val: 9 3 0.001 1 77 32.19512118856348 51.79282868525896 0.025619730076223046 0.008432087568120738\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/10_\n",
      "Val: 10 3 0.001 1 100 25.2074954993724 44.62151394422311 0.025197577039256555 0.006823419030128279\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/11_\n",
      "Val: 11 3 0.001 1 117 19.08933046473828 47.211155378486055 0.016170034699734097 0.007794231127847358\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/12_\n",
      "Val: 12 3 0.001 1 111 45.2691317419771 53.58565737051793 0.034436387334841306 0.0076734078012820105\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/13_\n",
      "Val: 13 3 0.001 1 102 28.47210412709398 50.59760956175299 0.017969222383118145 0.00723779545200284\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/14_\n",
      "Val: 14 3 0.001 1 83 32.1713626444792 52.39043824701195 0.03654282428920228 0.008588555799761853\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/15_\n",
      "Val: 15 3 0.001 1 97 30.305968897888697 49.800796812749006 0.03179833888138896 0.0073219009675722525\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/16_\n",
      "Val: 16 3 0.001 1 89 32.35323979963845 51.39442231075697 0.030261581557883128 0.008520071335912436\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/17_\n",
      "Val: 17 3 0.001 1 101 38.58986849172395 49.800796812749006 0.04310048063815293 0.009137430495573825\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/18_\n",
      "Val: 18 3 0.001 1 81 31.2069927191687 48.20717131474104 0.03382859572019984 0.009768097067492203\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/19_\n",
      "Val: 19 3 0.001 1 106 27.223074376106837 50.0 0.03379002077872967 0.008701873030642442\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/20_\n",
      "Val: 20 3 0.001 1 75 45.2453684546428 54.38247011952191 0.034206359134074826 0.010859019774157775\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/21_\n",
      "Val: 21 3 0.001 1 86 34.31350427807591 51.19521912350598 0.03526185205543248 0.008346842912826473\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/22_\n",
      "Val: 22 3 0.001 1 109 38.51078507466556 49.20318725099602 0.03503145409046334 0.009452405871126371\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/23_\n",
      "Val: 23 3 0.001 1 93 22.543680160883103 50.0 0.028901777232206695 0.009725038925254205\n",
      "Valid Start Date: 2011-12-13 00:00:00\n",
      "Valid End Date: 2013-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-18-44-10/24_\n",
      "Val: 24 3 0.001 1 102 31.902569187758083 52.39043824701195 0.04093853541116692 0.009951002420816087\n",
      "450 96.16 32.356333141761255\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch650.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict650.pkl\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/0_\n",
      "Val: 0 3 0.001 1 86 5.375462101530943 43.737574552683895 0.11713039923165497 0.00486927193450095\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/1_\n",
      "Val: 1 3 0.001 1 118 25.775114882247255 50.69582504970179 0.11637586069439838 0.0060410737789236965\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/2_\n",
      "Val: 2 3 0.001 1 135 23.606402715101602 47.713717693836976 0.10952644338381091 0.005760548332461976\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/3_\n",
      "Val: 3 3 0.001 1 104 13.068853283710919 45.32803180914513 0.11993270372348078 0.0043172402085756975\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/4_\n",
      "Val: 4 3 0.001 1 141 23.01630560169799 50.29821073558648 0.12084201062757194 0.005467931446931047\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/5_\n",
      "Val: 5 3 0.001 1 154 23.037589304565515 48.31013916500994 0.10530545588942071 0.004467221984240042\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/6_\n",
      "Val: 6 3 0.001 1 151 22.30532381483682 48.111332007952285 0.10467122249720104 0.00581290218565133\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/7_\n",
      "Val: 7 3 0.001 1 125 17.704825109766404 45.32803180914513 0.1070808599950093 0.004873207961676244\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/8_\n",
      "Val: 8 3 0.001 1 125 6.875746471301881 46.3220675944334 0.1152598875380548 0.005451922361732755\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/9_\n",
      "Val: 9 3 0.001 1 110 7.558261186531958 46.52087475149106 0.10449485221974278 0.0059728947866483795\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/10_\n",
      "Val: 10 3 0.001 1 130 16.289884395248155 45.32803180914513 0.11374355630187047 0.0067976570839827785\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-18-51-54/11_\n",
      "Val: 11 3 0.001 1 127 2.4175231845201774 44.33399602385686 0.09951793817391383 0.00520011887498713\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/12_\n",
      "Val: 12 3 0.001 1 133 9.45685430772892 46.3220675944334 0.10322046052079437 0.006762258913519215\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/13_\n",
      "Val: 13 3 0.001 1 133 6.178883487608975 45.52683896620278 0.10513365103063647 0.00764923793845551\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/14_\n",
      "Val: 14 3 0.001 1 113 7.84279964575784 46.71968190854871 0.13854505163607658 0.004297954960858249\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/15_\n",
      "Val: 15 3 0.001 1 133 9.094192583130212 43.538767395626245 0.11418835607759162 0.004204869562624919\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/16_\n",
      "Val: 16 3 0.001 1 97 5.880284746842263 45.92445328031809 0.121362455779885 0.005153361752130042\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/17_\n",
      "Val: 17 3 0.001 1 147 4.57199705765412 42.94234592445328 0.10307102233683632 0.005988376646783105\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/18_\n",
      "Val: 18 3 0.001 1 127 11.632557939394474 44.33399602385686 0.11922567971150135 0.005321542315531891\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/19_\n",
      "Val: 19 3 0.001 1 139 20.378318988577224 47.912524850894634 0.11581731731382741 0.0060357557341568615\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/20_\n",
      "Val: 20 3 0.001 1 134 16.54586648962586 49.50298210735586 0.13251025726739588 0.0033407557917021174\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/21_\n",
      "Val: 21 3 0.001 1 147 14.711396624943637 46.52087475149106 0.10742774854301183 0.00560275428745563\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/22_\n",
      "Val: 22 3 0.001 1 138 8.688887138845493 46.91848906560636 0.10657537920732685 0.005368979187694444\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/23_\n",
      "Val: 23 3 0.001 1 129 3.192603681354476 45.92445328031809 0.0880704027454843 0.00791338888113381\n",
      "Valid Start Date: 2012-12-13 00:00:00\n",
      "Valid End Date: 2014-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-18-51-54/24_\n",
      "Val: 24 3 0.001 1 125 15.706794864543252 46.71968190854871 0.10825063370533006 0.005613865518231595\n",
      "650 128.04 12.836509184282656\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch1050.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict1050.pkl\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/0_\n",
      "Val: 0 3 0.001 1 154 13.362721256225365 48.9065606361829 -0.01219783174704071 0.00016835773437063887\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/1_\n",
      "Val: 1 3 0.001 1 125 8.587552627629071 50.29821073558648 -0.043942304311237045 0.00013403686093004855\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/2_\n",
      "Val: 2 3 0.001 1 172 8.326541757890775 47.713717693836976 0.019803332482885915 8.642485584845932e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/3_\n",
      "Val: 3 3 0.001 1 164 0.3480786539209217 48.111332007952285 -0.02290976640544478 8.444491548161156e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/4_\n",
      "Val: 4 3 0.001 1 180 23.244744375079126 51.29224652087475 0.036793993152296485 8.118732065301702e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/5_\n",
      "Val: 5 3 0.001 1 152 7.309545472482447 50.29821073558648 -0.017022113182466957 8.286215529651106e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/6_\n",
      "Val: 6 3 0.001 1 148 18.931905738828874 49.10536779324055 -0.0026128180861405156 8.160757001626614e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/7_\n",
      "Val: 7 3 0.001 1 158 12.264118616363415 49.70178926441352 -0.03883434774172221 8.195805709104163e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/8_\n",
      "Val: 8 3 0.001 1 174 4.503220950839087 50.69582504970179 -0.002879538935184031 7.967824465382397e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/9_\n",
      "Val: 9 3 0.001 1 166 23.65258339841834 50.29821073558648 0.01747890634618523 7.997246372824807e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/10_\n",
      "Val: 10 3 0.001 1 130 -13.427938990544869 47.31610337972167 -0.04976059821048491 0.00016997179179485425\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/11_\n",
      "Val: 11 3 0.001 1 164 4.33460000129133 50.09940357852883 0.09900879319189625 7.062257503173282e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/12_\n",
      "Val: 12 3 0.001 1 154 1.1802329287280047 48.70775347912525 -0.05772452202957558 8.549232169814797e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/13_\n",
      "Val: 13 3 0.001 1 160 11.225305614406171 48.70775347912525 -0.015108386393589255 8.223766941358894e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/14_\n",
      "Val: 14 3 0.001 1 160 10.507450410602397 48.70775347912525 -0.001144495826130863 9.267628024525874e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/15_\n",
      "Val: 15 3 0.001 1 156 12.639402020193442 50.89463220675945 0.026324109116809703 7.846213144412208e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/16_\n",
      "Val: 16 3 0.001 1 156 24.729452729182718 50.09940357852883 0.017177765667701513 7.995832724770143e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/17_\n",
      "Val: 17 3 0.001 1 144 2.3495153584970705 49.70178926441352 -0.05656824198361504 0.00020753432745753187\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/18_\n",
      "Val: 18 3 0.001 1 158 16.217965863192298 49.70178926441352 -0.014130724478794762 7.947721897657694e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/19_\n",
      "Val: 19 3 0.001 1 162 14.727824468350901 50.69582504970179 -0.04042068508146264 8.262843413434677e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/20_\n",
      "Val: 20 3 0.001 1 154 23.576524428136075 52.88270377733598 -0.031457374736025105 9.258793746718766e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/21_\n",
      "Val: 21 3 0.001 1 162 15.706743549717544 50.89463220675945 0.009985780304016903 8.609293646197482e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/22_\n",
      "Val: 22 3 0.001 1 174 13.547645574477023 53.08151093439364 0.03376219519371011 7.641385789661405e-05\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-19-00-07/23_\n",
      "Val: 23 3 0.001 1 142 3.6547554119212293 49.10536779324055 -0.0561762096582935 0.00016555158226849593\n",
      "Valid Start Date: 2013-12-13 00:00:00\n",
      "Valid End Date: 2015-12-31 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-00-07/24_\n",
      "Val: 24 3 0.001 1 128 -4.345442184209056 47.11729622266402 -0.05176313204689035 8.489255757443771e-05\n",
      "1050 155.88 10.28620200126479\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch650.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict650.pkl\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/0_\n",
      "Val: 0 3 0.001 1 162 8.083221738910066 54.07554671968191 0.13916981268018877 8.202280836257311e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/1_\n",
      "Val: 1 3 0.001 1 152 3.261136090938887 51.888667992047715 0.14908937658809718 7.013768041999674e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/2_\n",
      "Val: 2 3 0.001 1 156 6.901686868320285 52.88270377733598 0.14235873204731064 8.313324718659752e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/3_\n",
      "Val: 3 3 0.001 1 164 18.08273266238217 54.07554671968191 0.146302384232911 6.963296255829877e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/4_\n",
      "Val: 4 3 0.001 1 163 7.641314914042146 51.888667992047715 0.09851258342525035 7.229857682328833e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/5_\n",
      "Val: 5 3 0.001 1 160 -3.7221601310713943 53.08151093439364 0.12368464806169004 7.341691380843255e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/6_\n",
      "Val: 6 3 0.001 1 160 2.708848592045404 53.47912524850894 0.11553739889874426 7.363078201150054e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/7_\n",
      "Val: 7 3 0.001 1 177 10.009164338055509 52.485089463220675 0.13932850458542526 7.088871593326153e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/8_\n",
      "Val: 8 3 0.001 1 165 16.53140334650681 54.27435387673956 0.154284961714513 6.906088592007843e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/9_\n",
      "Val: 9 3 0.001 1 153 -2.0796128610696107 52.087475149105366 0.10642242243995594 7.091064184690842e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/10_\n",
      "Val: 10 3 0.001 1 173 11.526874157392612 54.07554671968191 0.1940469270443935 7.051991222034651e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/11_\n",
      "Val: 11 3 0.001 1 140 22.24676667005399 55.46719681908549 0.17157581957077492 8.237852830424593e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/12_\n",
      "Val: 12 3 0.001 1 157 6.997788723877935 51.888667992047715 0.08491450884353974 8.056951269571658e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/13_\n",
      "Val: 13 3 0.001 1 151 7.03620424228839 51.29224652087475 0.06616054836273491 7.494059829611705e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/14_\n",
      "Val: 14 3 0.001 1 158 19.504367825369187 51.29224652087475 0.14277236064983995 7.050567851737067e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/15_\n",
      "Val: 15 3 0.001 1 165 7.084203548613057 52.485089463220675 0.15837922673939575 6.789581573204556e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/16_\n",
      "Val: 16 3 0.001 1 162 5.484864118780867 53.47912524850894 0.1975769696605614 7.6054777906595e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/17_\n",
      "Val: 17 3 0.001 1 160 10.422154434903316 54.87077534791253 0.15278780865742428 7.621615421344768e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/18_\n",
      "Val: 18 3 0.001 1 168 -2.776003090453184 50.49701789264414 0.11387704032859333 7.916644860849285e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/19_\n",
      "Val: 19 3 0.001 1 168 12.7324214776814 53.08151093439364 0.09525975506171923 7.885846413282142e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/20_\n",
      "Val: 20 3 0.001 1 150 11.449996370057322 53.47912524850894 0.1963470647336854 6.583371643403134e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/21_\n",
      "Val: 21 3 0.001 1 163 8.573118045664774 50.49701789264414 0.1191790727185422 7.920626101119729e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/22_\n",
      "Val: 22 3 0.001 1 149 9.403990404127024 51.68986083499006 0.16218083259622695 7.45785951923305e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/23_\n",
      "Val: 23 3 0.001 1 161 5.014187024319415 52.485089463220675 0.20533699749245055 7.369418903366748e-05\n",
      "Valid Start Date: 2014-12-15 00:00:00\n",
      "Valid End Date: 2016-12-30 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-08-18/24_\n",
      "Val: 24 3 0.001 1 160 14.946488645682248 53.6779324055666 0.16631378073956185 6.70620673766758e-05\n",
      "650 159.88 8.682606326296746\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch900.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict900.pkl\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/0_\n",
      "Val: 0 3 0.001 1 184 32.71029534961059 52.087475149105366 0.3219242512069142 4.331397895865539e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/1_\n",
      "Val: 1 3 0.001 1 186 26.943018613285446 54.87077534791253 0.2872665925598594 3.7462975715633175e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/2_\n",
      "Val: 2 3 0.001 1 197 32.24058125856567 56.858846918489064 0.2667497312537032 3.8662788351342e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/3_\n",
      "Val: 3 3 0.001 1 190 27.30135460293036 55.864811133200796 0.27909244928175025 3.8824417287127364e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/4_\n",
      "Val: 4 3 0.001 1 207 28.429582997437947 52.485089463220675 0.2730723900038742 4.2062889064061634e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/5_\n",
      "Val: 5 3 0.001 1 186 28.09069480857647 52.286282306163024 0.17419121244675934 4.210829085487306e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/6_\n",
      "Val: 6 3 0.001 1 201 34.56978388195639 54.27435387673956 0.2842965258355272 3.891511792924336e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/7_\n",
      "Val: 7 3 0.001 1 179 29.05914085301258 52.68389662027833 0.26722750504872755 4.210958716560619e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/8_\n",
      "Val: 8 3 0.001 1 167 29.126933939744646 55.268389662027836 0.27614720216670496 4.6266978013344044e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-19-16-53/9_\n",
      "Val: 9 3 0.001 1 187 29.620898781210688 55.06958250497018 0.27239485723035645 3.838205108637282e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/10_\n",
      "Val: 10 3 0.001 1 192 28.323153708797346 50.49701789264414 0.2918050493208907 4.1343198183656335e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/11_\n",
      "Val: 11 3 0.001 1 190 29.325496690087896 54.67196819085487 0.24087599556290964 4.263863849127081e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/12_\n",
      "Val: 12 3 0.001 1 188 28.65236138692989 54.87077534791253 0.30558698741526147 3.997468020734312e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/13_\n",
      "Val: 13 3 0.001 1 188 30.313300214586235 55.06958250497018 0.3039714271718403 3.585172996876595e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/14_\n",
      "Val: 14 3 0.001 1 200 20.919047693439172 56.262425447316105 0.2957161642804538 4.349309563714346e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/15_\n",
      "Val: 15 3 0.001 1 186 29.974370255418027 54.07554671968191 0.24767045961961495 4.260127991680115e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/16_\n",
      "Val: 16 3 0.001 1 190 32.434248559229715 54.07554671968191 0.21660596499623505 4.610068616590863e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/17_\n",
      "Val: 17 3 0.001 1 170 21.451793570811947 51.491053677932406 0.21020698865396056 4.743679913212464e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/18_\n",
      "Val: 18 3 0.001 1 192 30.037340718092658 52.88270377733598 0.15978161625873197 5.056720447953919e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/19_\n",
      "Val: 19 3 0.001 1 181 31.281804737451708 53.6779324055666 0.20593248857173302 5.281414399616345e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/20_\n",
      "Val: 20 3 0.001 1 179 38.54050822431487 55.46719681908549 0.29969375562783074 4.3104219990490884e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/21_\n",
      "Val: 21 3 0.001 1 194 24.03762290959784 53.28031809145129 0.20894553063297922 4.612058550247634e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/22_\n",
      "Val: 22 3 0.001 1 177 32.83624329721437 55.66600397614314 0.27637451964526516 3.805417275845582e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/23_\n",
      "Val: 23 3 0.001 1 190 34.773214598327606 54.27435387673956 0.24866420624805827 4.8161413855637384e-05\n",
      "Valid Start Date: 2015-12-14 00:00:00\n",
      "Valid End Date: 2017-12-29 00:00:00\n",
      "Valid Length: 516\n",
      "2021-03-17-19-16-53/24_\n",
      "Val: 24 3 0.001 1 183 22.60428685105456 52.087475149105366 0.2382314173786922 4.7648989791041895e-05\n",
      "900 187.36 29.343883140067383\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch300.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict300.pkl\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/0_\n",
      "Val: 0 3 0.001 1 154 -1.5889797093065496 48.40637450199203 -0.0017417337638287534 0.00012945982702524222\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/1_\n",
      "Val: 1 3 0.001 1 158 -5.2566521386315435 49.40239043824701 0.0020271520559966144 0.00012862084271277754\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/2_\n",
      "Val: 2 3 0.001 1 166 18.74922252371563 51.99203187250996 0.032986992977298936 0.00012994444709049194\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/3_\n",
      "Val: 3 3 0.001 1 171 6.461558306752121 50.398406374501995 -0.024638668514859637 0.00012822253527126987\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/4_\n",
      "Val: 4 3 0.001 1 166 -2.7408860452900785 51.59362549800797 -0.03234388055753443 0.00015526120795028076\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/5_\n",
      "Val: 5 3 0.001 1 168 -0.20742450211426994 51.19521912350598 0.026297453294748353 0.00012040792753697827\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/6_\n",
      "Val: 6 3 0.001 1 166 12.587724098798281 50.59760956175299 0.05245295996841357 0.00011879800844139575\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/7_\n",
      "Val: 7 3 0.001 1 162 -3.0190058293757405 50.59760956175299 -0.006016311762548066 0.00014988552434705183\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/8_\n",
      "Val: 8 3 0.001 1 170 7.997571731471696 51.19521912350598 0.03581855650526113 0.0001184807879877854\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/9_\n",
      "Val: 9 3 0.001 1 166 -8.95527306573107 49.00398406374502 0.007493968751799161 0.00013389283158444118\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/10_\n",
      "Val: 10 3 0.001 1 176 13.029073901925612 51.99203187250996 0.05039144276092139 0.00012794673570884761\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/11_\n",
      "Val: 11 3 0.001 1 170 4.797621010954112 50.199203187250994 0.019625169558878077 0.00011652714058398597\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/12_\n",
      "Val: 12 3 0.001 1 172 8.434498554970705 51.19521912350598 0.0018073163140303638 0.00013175154428585688\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/13_\n",
      "Val: 13 3 0.001 1 176 7.732713823628876 49.800796812749006 -0.028571354350369876 0.00012785925169624539\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/14_\n",
      "Val: 14 3 0.001 1 160 -0.6355901180620895 50.99601593625498 0.05514818646602599 0.00011464722082752054\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/15_\n",
      "Val: 15 3 0.001 1 170 0.4148843174391452 50.398406374501995 0.024930547831563118 0.00011414376456516686\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/16_\n",
      "Val: 16 3 0.001 1 156 -7.631181280496357 48.80478087649402 -0.01680391670085989 0.00013014331497404884\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/17_\n",
      "Val: 17 3 0.001 1 166 4.400384470514994 51.39442231075697 0.01261497173926899 0.00013051952864217886\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/18_\n",
      "Val: 18 3 0.001 1 168 -0.7458997596905701 49.40239043824701 0.025274848325765424 0.00012269555700932712\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/19_\n",
      "Val: 19 3 0.001 1 155 -2.6569906851944043 50.199203187250994 -0.03204589494744295 0.00014564735124050743\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/20_\n",
      "Val: 20 3 0.001 1 170 8.535962237342543 51.99203187250996 0.024676830475867637 0.0001163546189055992\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17-19-26-15/21_\n",
      "Val: 21 3 0.001 1 168 13.086434915572422 51.99203187250996 0.04108792943181974 0.00012479046488808124\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/22_\n",
      "Val: 22 3 0.001 1 178 -3.8354366646083884 49.601593625498005 -0.021858656720119572 0.00013104147220747284\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/23_\n",
      "Val: 23 3 0.001 1 170 -3.305862101765168 51.79282868525896 0.04712071860232758 0.00011954888625318414\n",
      "Valid Start Date: 2016-12-13 00:00:00\n",
      "Valid End Date: 2018-12-31 00:00:00\n",
      "Valid Length: 515\n",
      "2021-03-17-19-26-15/24_\n",
      "Val: 24 3 0.001 1 164 7.09714842481421 52.58964143426295 -0.016184398675422925 0.00013066263542980822\n",
      "300 166.64 2.909824656705365\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/epoch900.mdl\n",
      "CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models/DQEAC_dict900.pkl\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/0_\n",
      "Val: 0 3 0.001 1 139 -0.47033182730072454 49.596774193548384 -0.04157370188563563 0.00020483453073660482\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/1_\n",
      "Val: 1 3 0.001 1 131 6.79384936774925 49.395161290322584 -0.002321133851558064 0.0001922247786366478\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/2_\n",
      "Val: 2 3 0.001 1 149 18.862180840311844 48.38709677419355 0.035996517036738604 0.00021038997365103245\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/3_\n",
      "Val: 3 3 0.001 1 155 10.478222618479677 48.99193548387097 0.03518534004299831 0.00016359160784689346\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/4_\n",
      "Val: 4 3 0.001 1 133 15.834874698233165 48.99193548387097 -0.011587172657218666 0.00020075421299095428\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/5_\n",
      "Val: 5 3 0.001 1 141 4.244302830442485 50.806451612903224 0.002793458900331599 0.00019318400095115037\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/6_\n",
      "Val: 6 3 0.001 1 137 8.148888627370967 48.99193548387097 -0.01971499303134242 0.0001942622390081902\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/7_\n",
      "Val: 7 3 0.001 1 135 -0.40319361915290347 49.193548387096776 0.024540649231725754 0.00021511625978418294\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/8_\n",
      "Val: 8 3 0.001 1 139 -4.367506273286402 49.395161290322584 -0.006445856520484439 0.00017937598418829177\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/9_\n",
      "Val: 9 3 0.001 1 133 -2.6727231003769636 46.774193548387096 -0.04489823348126514 0.0002085566763641658\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/10_\n",
      "Val: 10 3 0.001 1 133 -4.0464348428092505 46.16935483870968 0.04528918189956604 0.0001795212830081999\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/11_\n",
      "Val: 11 3 0.001 1 135 -3.732843456029966 47.37903225806452 0.048657421199007136 0.00019014648332558556\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/12_\n",
      "Val: 12 3 0.001 1 129 0.20153259678367708 49.193548387096776 0.030915007867973684 0.00019264173793784805\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/13_\n",
      "Val: 13 3 0.001 1 135 1.104948351613532 49.395161290322584 -0.020158575742243473 0.00021334625224100497\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/14_\n",
      "Val: 14 3 0.001 1 147 6.9804950498545395 50.604838709677416 0.09616287175163647 0.00016518234659410494\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/15_\n",
      "Val: 15 3 0.001 1 138 4.905031561603149 48.58870967741935 0.05126811711363844 0.0001751646533721866\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/16_\n",
      "Val: 16 3 0.001 1 141 -4.524276580223086 46.975806451612904 -0.024004693182627896 0.00020379340934837783\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/17_\n",
      "Val: 17 3 0.001 1 131 -2.150144459569092 47.58064516129032 0.008649074198048761 0.0001978234448719025\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/18_\n",
      "Val: 18 3 0.001 1 153 4.845273344662128 50.806451612903224 0.022107413908364938 0.00021743234307947337\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/19_\n",
      "Val: 19 3 0.001 1 139 22.401013556237345 51.61290322580645 0.1377861684789991 0.0001819708019921017\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/20_\n",
      "Val: 20 3 0.001 1 151 21.882078618089245 51.00806451612903 0.07659579150680274 0.00017370139164734862\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/21_\n",
      "Val: 21 3 0.001 1 151 12.441772168849395 48.79032258064516 0.07099787645249996 0.00017253464688447986\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/22_\n",
      "Val: 22 3 0.001 1 131 3.6358000062982962 50.20161290322581 -0.001251713485363357 0.00020997687488536458\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/23_\n",
      "Val: 23 3 0.001 1 157 7.853957776836154 51.41129032258065 -0.015301572831104749 0.00019311995883471156\n",
      "Valid Start Date: 2017-12-13 00:00:00\n",
      "Valid End Date: 2019-12-20 00:00:00\n",
      "Valid Length: 509\n",
      "2021-03-17-19-34-16/24_\n",
      "Val: 24 3 0.001 1 143 -1.6909692316827756 48.185483870967744 -0.02937220340776156 0.00019535176271233144\n",
      "900 140.24 5.062231944919348\n"
     ]
    }
   ],
   "source": [
    "# 2009\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2009 - 2021-03-13-14-20-53/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2008', valid_end='12-31-2010',savedfn=savedfn, model_num=850, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2010\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2010 - 2021-03-13-21-37-25/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2009', valid_end='12-31-2011',savedfn=savedfn, model_num=650, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2011\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2011 - 2021-03-14-04-34-53/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2010', valid_end='12-31-2012',savedfn=savedfn, model_num=700, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2012\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2012 - 2021-03-14-11-33-41/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2011', valid_end='12-31-2013',savedfn=savedfn, model_num=450, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2013\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2013 - 2021-03-14-18-33-45/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2012', valid_end='12-31-2014',savedfn=savedfn, model_num=650, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2014\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2014 - 2021-03-15-01-30-56/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2013', valid_end='12-31-2015',savedfn=savedfn, model_num=1050, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2015\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2015 - 2021-03-15-08-29-15/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2014', valid_end='12-31-2016',savedfn=savedfn, model_num=650, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2016\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2016 - 2021-03-15-13-41-40/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2015', valid_end='12-31-2017',savedfn=savedfn, model_num=900, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2017\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2017 - 2021-03-15-18-54-04/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2016', valid_end='12-31-2018',savedfn=savedfn, model_num=300, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n",
    "# 2018\n",
    "saved_fn = 'CH15 - Exp7 - Roll forward train validation period/2018 - 2021-03-16-00-08-34/saved_models'\n",
    "run_trading_trials(predictor=\"pytorch_lstm\", valid_start='12-13-2017', valid_end='12-31-2019',savedfn=savedfn, model_num=900, num_trials=25, run_test=0, iter_per_seq=3, lr=1E-3, dr=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result, policy_dict = run_hypers(window_size=11, asset='SPY', train_epochs=4000, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=10, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('policy_dict.pkl','wb') as fp:\n",
    "    pickle.dump(policy_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=10, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=10, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, trading_validation_period=10, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=2, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=4, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=5, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=6, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.5, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.99, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for trial in range(100):\n",
    "    iter_per_seq = random.choice([10, 20, 30, 40, 50, 60 ,70, 80, 90, 100])\n",
    "    window_size = random.choice([11, 22, 44])\n",
    "    hidden_size = random.choice([32, 64, 128])\n",
    "    num_layers = random.choice([2, 3])\n",
    "    arch = random.choice(['LH','AH'])\n",
    "    dropout = random.choice([0, 0.5, 0.7])\n",
    "    lr = random.choice([1E-3, 5E-4, 1E-4, 5E-5, 1E-5])\n",
    "    dr = random.choice([0.9, 0.93, 0.95, 0.97, 0.99, 1])\n",
    "    model, journal, result = run_hypers(window_size=window_size, asset='SPY', train_epochs=1, iter_per_seq=iter_per_seq, arch=arch, num_layers=num_layers, hidden_size=hidden_size, dropout=dropout, lr=lr, dr=dr, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in range(10):\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=40, arch='AH', num_layers=2, hidden_size=64, dropout=0.7, lr=1E-4, dr=0.95, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in range(10):\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.7, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)\n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.1, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.2, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.3, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.4, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.5, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.6, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.7, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.8, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=0.9, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    \n",
    "model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=2, hidden_size=32, dropout=1, lr=1E-3, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=1, plot=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=2, plot=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=2, plot=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=2, plot=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=2, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=2, plot=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=3, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=2, plot=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=4, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=2, plot=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=5, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=2, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1500, iter_per_seq=6, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=1E-4, dr=1, wd=0, run_out_of_sample_test=0, train_only=0, verbosity=2, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=1, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.99, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.99, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.99, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.99, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.99, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.9, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.9, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.9, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.9, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.9, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.90, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.91, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.92, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.93, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.94, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.96, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.97, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.98, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.99, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.90, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.91, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.92, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.93, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.94, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.96, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.97, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.98, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.99, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.00001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.000001, dr=0.95, wd=0, run_out_of_sample_test=0, verbosity=1, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=0.999, wd=0, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=0.999, wd=1E-8, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=0.999, wd=1E-7, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=0.999, wd=1E-6, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=0.999, wd=1E-5, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=0.999, wd=1E-4, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=0.999, wd=1E-3, run_out_of_sample_test=0, verbosity=2, plot=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# r1 - r8 run on 16/2/21-18/2/21\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=1, wd=5E-6, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, wd=5E-6, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, wd=5E-6, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, wd=5E-6, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, wd=5E-6, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.0001, dr=1, wd=5E-6, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.0001, dr=1, wd=5E-6, run_out_of_sample_test=0, verbosity=2, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=11, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.0001, dr=1, wd=5E-6, run_out_of_sample_test=0, verbosity=2, plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_synthetic_stock(source_asset_name='SPY', new_name='SYN', directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019', trend_list=[(10,37),(7,17),(3,7)], adj_close_start=85, price_slope=0, close_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_synthetic_stock(source_asset_name='SPY', new_name='SYN2', directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019', trend_list=[(10,33),(5,17)], adj_close_start=85, price_slope=0, close_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_synthetic_stock(source_asset_name='SPY', new_name='SYN3', directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019', trend_list=[(10,33),(5,17)], adj_close_start=85, price_slope=0.01, close_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_synthetic_stock(source_asset_name='SPY', new_name='SYN4', directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='12-20-2019', trend_list=[(10,33),(5,17),(3,11),(2,3)], adj_close_start=85, price_slope=0.01, close_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_synthetic_stock(source_asset_name='SPY', new_name='SYN4S', directory='../../../data/yahoo_data', start_date='01-01-2005', stop_date='03-31-2005', trend_list=[(10,33),(5,17),(3,11),(2,3)], adj_close_start=85, price_slope=0.01, close_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_win_leg()\n",
    "epochs_win_leg()\n",
    "iterations_lr_leg()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPY Num Iterations Leg - using optimum settings from SYN4 experiments\n",
    "def spy_iterations_leg():\n",
    "    %mkdir \"num_iter\"\n",
    "    %cd num_iter\n",
    "    \n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=50, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=200, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=300, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=400, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    %cd ..\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPY Num Iterations Leg - using optimum settings from SYN4 experiments\n",
    "def spy_iterations_leg2():\n",
    "    %mkdir \"num_iter2\"\n",
    "    %cd num_iter\n",
    "    \n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1100, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1200, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1300, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1400, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=1500, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "#    model, journal, result = run_hypers(window_size=44, asset='SPY', train_epochs=1, iter_per_seq=400, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spy_iterations_leg2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num Iterations Leg - using optimum settings from SYN4 experiments\n",
    "def iterations_leg():\n",
    "    %mkdir \"num_iter\"\n",
    "    %cd num_iter\n",
    "    \n",
    "    model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=5, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=20, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=40, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=80, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    %cd ..\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_leg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations, Window size leg\n",
    "def iterations_win_leg():\n",
    "    %mkdir \"iter_win_len\"\n",
    "    %cd iter_win_len\n",
    "    model, journal, result = run_hypers(window_size=1, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=2, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=3, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=7, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=11, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=88, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    %cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs, Window size leg\n",
    "def epochs_win_leg():\n",
    "    %mkdir \"epoch_win_len\"\n",
    "    %cd epoch_win_len\n",
    "\n",
    "    model, journal, result = run_hypers(window_size=1, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=2, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=3, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=7, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=11, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=44, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=88, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations, Learning rate leg\n",
    "def iterations_lr_leg():\n",
    "    %mkdir \"iter_lr\"\n",
    "    %cd iter_lr\n",
    "    \n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.000001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.00001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.01, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.1, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch, Learning rate leg\n",
    "def epoch_lr_leg():\n",
    "    %mkdir \"epoch_lr\"\n",
    "    %cd epoch_lr\n",
    "    \n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.000001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.00001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.0001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.01, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.1, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    \n",
    "    %cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations, Hidden size leg\n",
    "def iterations_hidden_size_leg():\n",
    "    %mkdir \"iter_hidden_len\"\n",
    "    %cd iter_hidden_len\n",
    "    \n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=2, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=4, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=8, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=16, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=32, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=1, iter_per_seq=10, arch='LH', num_layers=3, hidden_size=256, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    \n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs, Hidden size leg\n",
    "def epochs_hidden_size_leg():\n",
    "    %mkdir \"epoch_hidden_len\"\n",
    "    %cd epoch_hidden_len\n",
    "    \n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=2, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=4, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=8, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=16, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=32, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=64, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=128, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    model, journal, result = run_hypers(window_size=22, asset='SYN4', train_epochs=10, iter_per_seq=1, arch='LH', num_layers=3, hidden_size=256, dropout=0.5, lr=0.001, dr=1, run_out_of_sample_test=0, verbosity=1, plot=1)\n",
    "    \n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything past here is graveyard / experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE OLD (SLOW) VERSION OF TRAIN_MODEL - IT WAS REPLACED BY TRAIN_MODELQ\n",
    "\n",
    "# Trains the given LSTM model. Also collects validation data (predicting the next day) and collects stats\n",
    "# for both.  These are used to observe training vs validation but also to construct the first allocation policy.\n",
    "\n",
    "def train_model(model, train_seq, train_labels, scale=1, offset=1, train_start=0, train_length=1, epochs = 20, iter_per_seq=1, max_iter=1600, lr = 0.001, dr=0.999, wd=0.0, verbosity=0, basefn='',percentiles=[0,10,20,30,40,50,60], trading_validation_period=100, valid_seq=[], valid_labels=[], plot=0):\n",
    "    input_size = 6\n",
    "    \n",
    "    \n",
    "    # if plot level is 4, plot graphs on screen for every inner loop training run\n",
    "    if plot == 4:\n",
    "        dump_log_interval = 1\n",
    "    else:\n",
    "        dump_log_interval = 10 # otherwise do it every 10\n",
    "        \n",
    "    loss_function = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = wd)\n",
    "    my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer = optimizer, gamma = dr)\n",
    "    \n",
    "    batch_size = 1  # batch mode isn't used actually but including for future possible use\n",
    "    \n",
    "    with open(basefn + 'train.csv', 'a', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Epc','AvTrLoss','AvTrMSE','AvValMSE','MdnTrMSE','MdnValMSE','ValMDA','ValMAPE','ValMAE','PXcorr','RXcorr',\n",
    "                     'EpcSecs','TtlMins'])\n",
    "        \n",
    "    with open(basefn + 'trade_validation.csv', 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Epoch','MDA','MSE','MAE','MAPE','X-Correl','Num-trades','AveRt%','MdnRT%','MinRt%','MaxRt%',\n",
    "                    'RangeRt%','StdDevRt%'])\n",
    "            \n",
    "    # Outputs a summary line for each Epoch\n",
    "    if verbosity == 1:\n",
    "        print('Epc  AvTrLoss  AvTrMSE   AvValMSE  MdnTrMSE  MdnValMSE  ValMDA    ValMAPE  ValMAE    PXcorr  RXcorr Secs    TTlMins')\n",
    "\n",
    "    # Outputs a summary line for each sequence in each epoch\n",
    "    if verbosity == 2:\n",
    "        print('EPc  Seq#   TrLoss    TrMSE     PredR   ActRt   ValLoss   VAdjC    VPred   VAct      VPredRt   VActRt   RunMDA')            \n",
    "                            \n",
    "    \n",
    "#    train_losses = []\n",
    "#    val_adj_close_price = []\n",
    "    ave_grads = []\n",
    "    max_grads = []\n",
    "    min_grads = []\n",
    "    \n",
    "    # If the number of epochs is high, just sample the gradients stochastically to avoid retaining too much\n",
    "    # data.\n",
    "    if (epochs * train_length) > 1000:\n",
    "        sample_grads = 1000.0 / (epochs * train_length)\n",
    "    else:\n",
    "        sample_grads = 1.0\n",
    "\n",
    "    start_time = time.time()        \n",
    "\n",
    "    # How many times through the entire training set\n",
    "    for i in range(epochs):\n",
    "        train_losses = []\n",
    "        val_adj_close_price = []        \n",
    "        train_mses = []\n",
    "        val_mses = []\n",
    "        val_pred_rt = []\n",
    "        val_act_rt = []\n",
    "        val_pred_price = []\n",
    "        val_act_price = []        \n",
    "        running_mda = 0\n",
    "        epoch_start_time = time.time()\n",
    "        # Each sample in the training set\n",
    "        for j in range(train_start, train_start + train_length):      \n",
    "\n",
    "            # Reset the learning rate each time for the inner loop\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "            \n",
    "            t_mse_list = []\n",
    "            v_mse_list = []\n",
    "            il_ave_grads = []\n",
    "            il_max_grads = []\n",
    "            \n",
    "#            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = wd)\n",
    "#            my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer = optimizer, gamma = dr)\n",
    "            \n",
    "#            if j%dump_log_interval == 0:\n",
    "#                dump_log = 1\n",
    "#            else:\n",
    "            # Disable inner loop instrumentations for now\n",
    "            dump_log = 0\n",
    "            \n",
    "            # How many times we train on each sample as we go\n",
    "            for iter in range(iter_per_seq):\n",
    "                # Send input / label data to Cuda if available\n",
    "                inputs = train_seq[j].to(device)\n",
    "                labels = train_labels[j].to(device)\n",
    "        \n",
    "                model.train()\n",
    "            \n",
    "                # Initialise hidden states before every training event\n",
    "                h = model.init_hidden(batch_size)  \n",
    "                                    \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                y_pred, h, lstm_out = model(inputs, h)\n",
    "            \n",
    "                if dump_log:\n",
    "                    tp = y_pred[-1].item()\n",
    "                    ta = labels[-1].item()\n",
    "                    t_mse = (tp-ta)**2\n",
    "\n",
    "                # y_pred and labels are both size T - sequence to sequence loss function\n",
    "                train_loss = loss_function(y_pred, labels)\n",
    "            \n",
    "                # Compute gradients and update the model\n",
    "                train_loss.backward()\n",
    "                                \n",
    "                optimizer.step()\n",
    "\n",
    "                my_lr_scheduler.step()\n",
    "                \n",
    "                # Do an inner loop validation\n",
    "                if dump_log:\n",
    "                    inputs = train_seq[j+1].to(device)\n",
    "                    labels = train_labels[j+1].to(device)\n",
    "            \n",
    "                    with torch.no_grad():\n",
    "                        h = model.init_hidden(batch_size)\n",
    "                        y_pred, h, lstm_out = model(inputs, h)\n",
    "                \n",
    "                        vp = y_pred[-1].item()\n",
    "                        va = labels[-1].item()\n",
    "                        v_mse = (vp-va)**2\n",
    "                \n",
    "                    # write detailed training log\n",
    "                    with open(basefn + 'train_inner.csv', 'a', newline='') as myfile:        \n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow([j,iter,train_loss.item(),tp,ta,t_mse,vp,va,v_mse])\n",
    "                    \n",
    "                    t_mse_list.append(t_mse)\n",
    "                    v_mse_list.append(v_mse)\n",
    "\n",
    "                    # Grab the inner loop grads - only if we're plotting as we go\n",
    "                    if plot >= 3:                    \n",
    "                        il_ave_grad = []\n",
    "                        il_max_grad = []\n",
    "                        for n,p in model.named_parameters():\n",
    "                            if (p.requires_grad) and (\"bias\" not in n):\n",
    "                                il_ave_grad.append(p.grad.abs().mean())\n",
    "                                il_max_grad.append(p.grad.abs().max())\n",
    "                        il_ave_grads.append(il_ave_grad)\n",
    "                        il_max_grads.append(il_max_grad)\n",
    "            \n",
    "            # After the inner loop completes, plot the inner-loop charts if enabled\n",
    "            if dump_log and plot >= 3:\n",
    "                plot_losses(t_mse_list, v_mse_list, title='Train / Validation Loss. Seq:'+str(j), basefn=basefn, display_plot=1, save_plot=0)\n",
    "                print(\"last tp:\",tp,\"\\tlast ta:\",ta,\"\\tlast t_mse:\",t_mse)\n",
    "                print(\"last vp:\",vp,\"\\tlast va:\",va,\"\\tlast v_mse:\",v_mse)\n",
    "            \n",
    "                plot_gradients(model, il_ave_grads, il_max_grads, basefn=basefn, display_plot=1, save_plot=0)\n",
    "\n",
    "            # Sample stochastically the last set of gradients after the inner loop for plotting later\n",
    "            if plot and (random.random() < sample_grads):\n",
    "                ave_grad=[]\n",
    "                max_grad=[]\n",
    "                min_grad=[]\n",
    "                for n,p in model.named_parameters():\n",
    "                    if (p.requires_grad) and (\"bias\" not in n):\n",
    "                        ave_grad.append(p.grad.abs().mean())\n",
    "                        max_grad.append(p.grad.abs().max())\n",
    "                        min_grad.append(p.grad.abs().min())\n",
    "                ave_grads.append(ave_grad)\n",
    "                max_grads.append(max_grad)\n",
    "                min_grads.append(min_grad)            \n",
    "            \n",
    "            # Capture the (snapshot) metrics from the last inner loop cycle\n",
    "            training_loss = train_loss.item()  # This is the sequence to sequence training loss                        \n",
    "            train_adj_close = inputs[-1][-1].item()   # Adj close at t=0\n",
    "            train_pred = y_pred[-1].item()  # Next day predicted Adj close\n",
    "            train_truth = labels[-1].item()  # Next day actual Adj close\n",
    "            train_mse = (train_pred - train_truth)**2   # MSE of just the predicted value vs truth\n",
    "            train_predicted_return = (denormalise_value(train_pred, scale, offset) / denormalise_value(train_adj_close, scale, offset)) - 1            \n",
    "            train_actual_return = (denormalise_value(train_truth, scale, offset) / denormalise_value(train_adj_close, scale, offset)) - 1\n",
    "\n",
    "            # Outer loop validation at the end of inner loop training - we always do this regardless of what\n",
    "            # validation we did in the inner loop (which is usually sampled)\n",
    "            model.eval()\n",
    "            \n",
    "            inputs = train_seq[j+1].to(device)\n",
    "            labels = train_labels[j+1].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = model.init_hidden(batch_size)\n",
    "        \n",
    "                y_pred, h, lstm_out = model(inputs, h)\n",
    "                    \n",
    "                valid_adj_close = inputs[-1][-1].item()                \n",
    "                valid_pred = y_pred[-1].item()\n",
    "                valid_truth = labels[-1].item()\n",
    "                valid_loss = (valid_pred - valid_truth)**2  # Just the mse of the valid predicted value vs truth\n",
    "            \n",
    "                valid_predicted_return = (denormalise_value(valid_pred, scale, offset) / denormalise_value(valid_adj_close, scale, offset)) - 1\n",
    "                valid_actual_return = (denormalise_value(valid_truth, scale, offset) / denormalise_value(valid_adj_close, scale, offset)) - 1\n",
    "\n",
    "                if (valid_predicted_return * valid_actual_return >= 0):\n",
    "                    running_mda += 1                \n",
    "                \n",
    "                # If enabled, print results line at the end of inner loop training on each sequence\n",
    "                if (verbosity==2):\n",
    "                    print('{:4}'.format(i),\n",
    "                            '{:4}'.format(j), \n",
    "                          '  {:1.1e}'.format(training_loss),\n",
    "                          '  {:1.1e}'.format(train_mse),\n",
    "                          ' {: 2.3f}'.format(100.0*train_predicted_return), \n",
    "                          ' {: 2.3f}'.format(100.0*train_actual_return),\n",
    "                          '  {:1.1e}'.format(valid_loss), \n",
    "                          ' {: 1.4f}'.format(valid_adj_close), \n",
    "                          ' {: 1.4f}'.format(valid_pred), \n",
    "                          ' {: 1.4f}'.format(valid_truth),\n",
    "                          ' {: 2.4f}'.format(100.0*valid_predicted_return), \n",
    "                          ' {: 2.4f}'.format(100.0*valid_actual_return),\n",
    "                          '  {:2.2f}'.format(100.0*running_mda/(j+1)))\n",
    "                    \n",
    "                # Keep lists of the results of train / validation for each sequence for passing back up the stack\n",
    "                train_losses.append(training_loss)\n",
    "                train_mses.append(train_mse)\n",
    "                val_mses.append(valid_loss)\n",
    "                val_pred_rt.append(valid_predicted_return)\n",
    "                val_act_rt.append(valid_actual_return)\n",
    "                val_pred_price.append(valid_pred)\n",
    "                val_act_price.append(valid_truth)\n",
    "                val_adj_close_price.append(valid_adj_close)\n",
    "                \n",
    "            # End of outer loop                                        \n",
    "           \n",
    "        elapsed_secs = time.time()-start_time\n",
    "        \n",
    "        # We report stats on the last portion of the training\n",
    "        stats_len = int(0.5 * len(train_losses))\n",
    "            \n",
    "        metrics_dict = compute_metrics(np.array(val_pred_rt[-stats_len:]),\n",
    "                                   np.array(val_act_rt[-stats_len:]),\n",
    "                                   np.array(val_pred_price[-stats_len:]),\n",
    "                                   np.array(val_act_price[-stats_len:]))\n",
    "\n",
    "        # This is the results we'll pass back up the stack for the entire training\n",
    "        result_dict = {'trStats_N':stats_len, 'AvTrLoss':np.mean(train_losses[-stats_len:]),\n",
    "                   'trAvTrMSE':np.mean(train_mses[-stats_len:]),\n",
    "                   'trAvValMSE':np.mean(val_mses[-stats_len:]),\n",
    "                   'trMdnTrMSE':np.median(train_mses[-stats_len:]),\n",
    "                   'trMdnValMSE':np.median(val_mses[-stats_len:]),\n",
    "                   'train_mses':train_mses, 'valid_mses':val_mses, 'val_pred_rt':val_pred_rt, 'val_act_rt':val_act_rt, \n",
    "                   'val_pred_price':val_pred_price, 'val_act_price':val_act_price, \n",
    "                   'val_adj_close_price': val_adj_close_price,\n",
    "                    'trMDA': metrics_dict['MDA'],\n",
    "                    'trMAPE': metrics_dict['MAPE'],\n",
    "                    'trMAE': metrics_dict['MAE'],\n",
    "                    'trPXCORR': metrics_dict['PXCORR'],\n",
    "                    'trRXCORR': metrics_dict['RXCORR'],\n",
    "                    'epoch_train_time':time.time()-epoch_start_time,\n",
    "                   'train_time':elapsed_secs}\n",
    "        \n",
    "#        result_dict.update(metrics_dict)\n",
    "        \n",
    "        # Output summary stats at end of outer loop training  \n",
    "        if (verbosity == 1):\n",
    "            print('{:4}'.format(i),'{:4.2e}'.format(result_dict['AvTrLoss']),\n",
    "                          ' {:1.2e}'.format(result_dict['trAvTrMSE']),\n",
    "                          ' {:4.2e}'.format(result_dict['trAvValMSE']), \n",
    "                          ' {:1.2e}'.format(result_dict['trMdnTrMSE']),\n",
    "                          ' {:4.2e}'.format(result_dict['trMdnValMSE']),                  \n",
    "                          '  {:2.2f}'.format(result_dict['trMDA']), \n",
    "                          '    {:2.2f}'.format(result_dict['trMAPE']), \n",
    "                          '    {:2.2e}'.format(result_dict['trMAE']),\n",
    "                          '{: 1.2f}'.format(result_dict['trPXCORR']), \n",
    "                          '  {: 1.2f}'.format(result_dict['trRXCORR']),      \n",
    "                          '  {:2.2f}'.format(result_dict['epoch_train_time']),                  \n",
    "                          '  {:3.1f}'.format(result_dict['train_time']/60.0))\n",
    "            \n",
    "        with open(basefn + 'train.csv', 'a', newline='') as myfile:\n",
    "            wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "            wr.writerow([i, result_dict['AvTrLoss'],\n",
    "                        result_dict['trAvTrMSE'],\n",
    "                        result_dict['trAvValMSE'],\n",
    "                        result_dict['trMdnTrMSE'],\n",
    "                        result_dict['trMdnValMSE'],\n",
    "                        result_dict['trMDA'],\n",
    "                        result_dict['trMAPE'],\n",
    "                        result_dict['trMAE'],\n",
    "                        result_dict['trPXCORR'],\n",
    "                        result_dict['trRXCORR'],\n",
    "                        result_dict['epoch_train_time'],\n",
    "                        result_dict['train_time']/60.0,\n",
    "                        ])\n",
    "        \n",
    "        # Periodically perform a trading validation \n",
    "        if i%trading_validation_period == 0:\n",
    "            D,Q,E,A,C = generate_initial_allocation_policy(result_dict, percentiles=percentiles, scale=scale, offset=offset, basefn=basefn, verbosity=0)\n",
    "            \n",
    "            # Save both the model and the initial allocation policy so we can recreate for validation / test after training\n",
    "            # (pick the best model out of a complete training run after analysing the data)\n",
    "            \n",
    "            # Make a results directory. If the 'directory' doesn't exist, create it\n",
    "            if os.path.isdir(basefn + '/saved_models') == False:\n",
    "                os.mkdir(basefn + '/saved_models')\n",
    "            \n",
    "            torch.save(model,basefn + '/saved_models/epoch' + str(i) + '.mdl')\n",
    "            \n",
    "            with open(basefn + '/saved_models/DQEAC_dict' + str(i) + '.pkl','wb') as fp:\n",
    "                pickle.dump({'D':D, 'Q':Q, 'E':E, 'A':A, 'C':C}, fp, protocol=pickle.HIGHEST_PROTOCOL)            \n",
    "\n",
    "            # Note - prior to version 15, I wasn't deep copying the D,Q,E,A which means they would have been being updated\n",
    "            # by trading validation.\n",
    "            trial_results = []\n",
    "            for trial in range(10):\n",
    "                # For each trial make a deep copy of things that get modified by the validation process. Make sure that \n",
    "                # the model being trained and the allocation policy components are not being modified and we always start\n",
    "                # validation from the same starting point.\n",
    "                validation_model = copy.deepcopy(model)\n",
    "                copy_D = copy.deepcopy(D)\n",
    "                copy_Q = copy.deepcopy(Q)\n",
    "                copy_E = copy.deepcopy(E)\n",
    "                copy_A = copy.deepcopy(A)\n",
    "                \n",
    "                validation_model, copy_D, copy_Q, copy_E, copy_A, journal, test_result_dict = test_trading_system(validation_model, valid_seq, valid_labels, copy_D, copy_Q, copy_E, copy_A, percentiles, basefn=basefn+'/saved_models/'+str(i)+'_'+str(trial), scale=scale, offset=offset, iter_per_seq=iter_per_seq, lr = 0.001, dr = 1, verbosity=0)\n",
    "                \n",
    "                trial_results.append(test_result_dict)                \n",
    "\n",
    "            \n",
    "            mean_trial_MDA = np.mean([v['MDA'] for v in trial_results])\n",
    "            mean_trial_MSE = np.mean([v['MSE'] for v in trial_results])\n",
    "            mean_trial_MAE = np.mean([v['MAE'] for v in trial_results])\n",
    "            mean_trial_MAPE = np.mean([v['MAPE'] for v in trial_results])\n",
    "            mean_trial_RXCORR = np.mean([v['RXCORR'] for v in trial_results])\n",
    "            mean_trial_num_trades = np.mean([v['num_trades'] for v in trial_results])\n",
    "            trial_returns = [v['trade_return'] for v in trial_results]\n",
    "            mean_trial_trade_return = np.mean(trial_returns)\n",
    "            median_trial_trade_return = np.median(trial_returns)\n",
    "            min_trial_trade_return = np.min(trial_returns)\n",
    "            max_trial_trade_return = np.max(trial_returns)\n",
    "            range_trial_trade_return = max_trial_trade_return - min_trial_trade_return\n",
    "            std_trial_trade_return = np.std(trial_returns)\n",
    "            \n",
    "            print('Trading Validation - ',\n",
    "                'MDA:{:2.2f}'.format(mean_trial_MDA),\n",
    "                '  Returns Correl:{:2.2f}'.format(mean_trial_RXCORR),\n",
    "                '  Num Trades:{:4}'.format(mean_trial_num_trades),\n",
    "                '  Return%:{:2.2f}'.format(mean_trial_trade_return))\n",
    "            \n",
    "            with open(basefn + 'trade_validation.csv', 'a', newline='') as myfile:\n",
    "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow([i,mean_trial_MDA, mean_trial_MSE,\n",
    "                            mean_trial_MAE, mean_trial_MAPE,\n",
    "                            mean_trial_RXCORR, mean_trial_num_trades, \n",
    "                            mean_trial_trade_return, median_trial_trade_return,\n",
    "                            min_trial_trade_return, max_trial_trade_return,\n",
    "                            range_trial_trade_return, std_trial_trade_return])\n",
    "\n",
    "    if plot>=1:\n",
    "        plot_gradients(model, ave_grads, max_grads, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plotly_gradients(model, min_grads, max_grads, ave_grads, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_hidden(h, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_lstm_output(lstm_out, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_weights(model, basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_losses(train_mses, val_mses, title='Model Training: Training Loss vs Validation Loss', basefn=basefn, display_plot=plot, save_plot=1)\n",
    "        plot_returns_hist(val_pred_rt, val_act_rt, title='Model Training: Predicted vs Actual Returns', basefn=basefn+'both_', display_plot=plot, save_plot=1)\n",
    "        plot_returns_hist(val_pred_rt, val_pred_rt, title='Model Training: Predicted Returns', basefn=basefn+'pred_', display_plot=plot, save_plot=1)\n",
    "        plot_returns_hist(val_act_rt, val_act_rt, title='Model Training: Actual Returns', basefn=basefn+'act_', display_plot=plot, save_plot=1)    \n",
    "            \n",
    "    return model, result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "val_results = []\n",
    "for i in range(10):\n",
    "    print(\"\\nTrial:\", i)\n",
    "    print(\"********\\n\")\n",
    "    model, journal, result = run_hypers(verbosity = 1, plot = 1)\n",
    "    test_results.append(result['test_return_pct'])\n",
    "    val_results.append(result['val_return_pct'])\n",
    "    \n",
    "print(np.mean(np.array(val_results)))\n",
    "print(np.std(np.array(val_results)))\n",
    "\n",
    "print(np.mean(np.array(test_results)))\n",
    "print(np.std(np.array(test_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"short\")\n",
    "\n",
    "for name in model.named_parameters():\n",
    "    print(name[0])\n",
    "    print(name[1][:])\n",
    "\n",
    "print(model.lstm.weight_ih_l0.size())\n",
    "print(model.lstm.bias_ih_l0.size())\n",
    "print(model.lstm.weight_hh_l0.size())\n",
    "print(model.lstm.bias_hh_l0.size())\n",
    "\n",
    "\n",
    "print(model.lstm.weight_hh_l1.size())\n",
    "print(model.lstm.weight_ih_l1.size())\n",
    "\n",
    "print(model.lstm.weight_hh_l2.size())\n",
    "print(model.lstm.weight_ih_l2.size())\n",
    "\n",
    "print(model.linear.weight.size())\n",
    "print(model.linear.bias.size())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first asset in list of assets as the source\n",
    "assets = ['SPY', 'DIA', 'ONEQ', 'IWM']\n",
    "\n",
    "print(asset_list)\n",
    "syn_df = asset_dict[asset_list[0]].copy()\n",
    "\n",
    "display(syn_df.head(5))\n",
    "print(syn_df.describe())    \n",
    "\n",
    "asset_dict['SYN'] = syn_df \n",
    "\n",
    "trend_list = [(1, 20)]\n",
    "make_synthetic_df(asset_dict['SYN'], trend_list, 0, 0, 1.4)\n",
    "\n",
    "display(syn_df.head(5))\n",
    "print(syn_df.describe())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# norm_img=cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "# plt.imshow(img, cmap='gray')\n",
    "fig, ax = plt.subplots(1,6,figsize=(20,12))\n",
    "ax[0].imshow(model.lstm.weight_ih_l0.cpu().detach().numpy(), cmap='inferno')\n",
    "ax[1].imshow(model.lstm.weight_hh_l0.cpu().detach().numpy(), cmap='inferno')\n",
    "ax[2].imshow(model.lstm.weight_ih_l1.cpu().detach().numpy(), cmap='inferno')\n",
    "ax[3].imshow(model.lstm.weight_hh_l1.cpu().detach().numpy(), cmap='inferno')\n",
    "ax[4].imshow(model.lstm.weight_ih_l2.cpu().detach().numpy(), cmap='inferno')\n",
    "ax[5].imshow(model.lstm.weight_hh_l2.cpu().detach().numpy(), cmap='inferno')\n",
    "\n",
    "# ih_l0 - has dimension 6 x 512\n",
    "\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock market indices\n",
    "# assets = ['^GSPC', '^DJI', '^IXIC', '^RUT']\n",
    "\n",
    "assets = ['SPY', 'DIA', 'ONEQ', 'IWM']\n",
    "\n",
    "asset_list = assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through index list, check if we already have the data (load it) or go get it from Yahoo! (save it)\n",
    "# Make a dictionary of dataframes containing all the data\n",
    "\n",
    "start_date = '01-01-2005'\n",
    "# stop_date = '05-01-2018' # First version of paper\n",
    "stop_date = '12-20-2019' # Final version of paper\n",
    "directory = '../../../data/yahoo_data'\n",
    "\n",
    "# If the 'directory' doesn't exist, create it\n",
    "#if os.path.isdir(directory) == False:\n",
    "#    os.mkdir(directory)\n",
    "\n",
    "asset_dict = {}\n",
    "for asset in asset_list:\n",
    "    df = get_data(asset_name=asset, directory=directory, start_date=start_date, stop_date=stop_date)    \n",
    "    asset_dict[asset] = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset in asset_list:\n",
    "    display(asset_dict[asset].head(5))\n",
    "    print(asset, asset_dict[asset].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the assets in Plotly interactive charts with a Candlestick chart\n",
    "for asset in asset_list:\n",
    "    plotly_candlestick(asset_dict, asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we split the data into train, validation and test sets let's add the Prev Adj Close feature and\n",
    "# remove the Date and Volume columns (which are not used)\n",
    "\n",
    "for asset in asset_list:\n",
    "    asset_dict[asset] = add_features_to_df(asset_dict[asset])       \n",
    "    display(asset, asset_dict[asset].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end dates for each of the sets - start and end dates are inclusive\n",
    "\n",
    "# Training set\n",
    "train_start = '01-01-2005'\n",
    "train_end = '01-01-2008'\n",
    "\n",
    "# Validation set\n",
    "valid_start = '01-02-2008'\n",
    "valid_end = '12-31-2009'\n",
    "\n",
    "# A combined train / valid set\n",
    "train_val_start = '01-01-2005'\n",
    "train_val_end = '12-31-2009'\n",
    "\n",
    "# Pre-test set (120 days prior to test period, to generate allocation policy for testing)\n",
    "pre_test_start = '07-15-2009'\n",
    "pre_test_end = '12-31-2009'\n",
    "\n",
    "# Out of sample test set\n",
    "test_start = '01-01-2010'\n",
    "test_end = '12-20-2019'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_baseline = {'SPY':136.4, 'DIA':136.6, 'ONEQ':228.9, 'IWM':163.5} # Original paper\n",
    "paper_baseline = {'SPY':188.87, 'DIA':172.87, 'ONEQ':293.32, 'IWM':167.34, 'SYN':0} # Latest paper - table 12\n",
    "\n",
    "\n",
    "train_asset_dict = {}\n",
    "valid_asset_dict = {}\n",
    "test_asset_dict = {}\n",
    "train_val_asset_dict = {}\n",
    "pre_test_asset_dict = {}\n",
    "\n",
    "for asset in asset_list:\n",
    "    # Make a dataframe for this asset\n",
    "    df = asset_dict[asset]\n",
    "    \n",
    "    # Mask off the training data and assign result to a train_asset dictionary\n",
    "    mask = (df['Date'] >= train_start) & (df['Date'] <= train_end)\n",
    "    train_asset_dict[asset] = df.loc[mask]\n",
    "    \n",
    "    # Mask off the validation data and assign result to a valid_asset dictionary\n",
    "    mask = (df['Date'] >= valid_start) & (df['Date'] <= valid_end)\n",
    "    valid_asset_dict[asset] = df.loc[mask]\n",
    "    \n",
    "    # Mask off the test data and assign result to a test_asset dictionary\n",
    "    mask = (df['Date'] >= test_start) & (df['Date'] <= test_end)\n",
    "    test_asset_dict[asset] = df.loc[mask]\n",
    "    \n",
    "    # Mask off the combined train / validation data and assign result to a train_val_asset dictionary\n",
    "    mask = (df['Date'] >= train_val_start) & (df['Date'] <= train_val_end)\n",
    "    train_val_asset_dict[asset] = df.loc[mask]\n",
    "\n",
    "    # Mask off the pre_test data and assign result to a pre_test_asset dictionary\n",
    "    mask = (df['Date'] >= pre_test_start) & (df['Date'] <= pre_test_end)\n",
    "    pre_test_asset_dict[asset] = df.loc[mask]\n",
    "    \n",
    "    # Reset the indices to start from 0 again for each of the dataframes\n",
    "    train_asset_dict[asset].index = np.arange(train_asset_dict[asset].shape[0])    \n",
    "    valid_asset_dict[asset].index = np.arange(valid_asset_dict[asset].shape[0])    \n",
    "    test_asset_dict[asset].index = np.arange(test_asset_dict[asset].shape[0])\n",
    "    train_val_asset_dict[asset].index = np.arange(train_val_asset_dict[asset].shape[0])    \n",
    "    pre_test_asset_dict[asset].index = np.arange(pre_test_asset_dict[asset].shape[0])    \n",
    "\n",
    "    \n",
    "#    display(test_asset_dict[asset])\n",
    "\n",
    "print(\"Adjusted Close to Adjusted Close:\")\n",
    "print('Asset\\tStart Date\\t\\tBeg$\\tEnd Date\\t\\tEnd$\\tGain%\\tPaper%')\n",
    "for asset in asset_list:\n",
    "    # Print the buy and hold returns over the entire test period (the papers baseline)\n",
    "    start = test_asset_dict[asset]['Adj Close'].loc[0]\n",
    "    end = test_asset_dict[asset]['Adj Close'].loc[test_asset_dict[asset].shape[0]-1]\n",
    "    gain = 100.0 * (end - start) / start\n",
    "    \n",
    "    print(asset, '\\t', test_asset_dict[asset]['Date'].loc[0], '\\t{:1.2f}'.format(start), '\\t', \n",
    "          test_asset_dict[asset]['Date'].loc[test_asset_dict[asset].shape[0]-1], \n",
    "          '\\t{:1.2f}'.format(end), '\\t{:1.2f}'.format(gain), '\\t{:1.2f}'.format(paper_baseline[asset]))\n",
    "\n",
    "print(\"\\nClose to Close:\")\n",
    "print('Asset\\tStart Date\\t\\tBeg$\\tEnd Date\\t\\tEnd$\\tGain%\\tPaper%')\n",
    "for asset in asset_list:\n",
    "    # Print the buy and hold returns over the entire test period (the papers baseline)\n",
    "    start = test_asset_dict[asset]['Close'].loc[0]\n",
    "    end = test_asset_dict[asset]['Close'].loc[test_asset_dict[asset].shape[0]-1]\n",
    "    gain = 100.0 * (end - start) / start\n",
    "    \n",
    "    print(asset, '\\t', test_asset_dict[asset]['Date'].loc[0], '\\t{:1.2f}'.format(start), '\\t', \n",
    "          test_asset_dict[asset]['Date'].loc[test_asset_dict[asset].shape[0]-1], \n",
    "          '\\t{:1.2f}'.format(end), '\\t{:1.2f}'.format(gain), '\\t{:1.2f}'.format(paper_baseline[asset]))\n",
    "    \n",
    "print(\"\\nOpen to Close:\")\n",
    "print('Asset\\tStart Date\\t\\tBeg$\\tEnd Date\\t\\tEnd$\\tGain%\\tPaper%')\n",
    "for asset in asset_list:\n",
    "    # Print the buy and hold returns over the entire test period (the papers baseline)\n",
    "    start = test_asset_dict[asset]['Open'].loc[0]\n",
    "    end = test_asset_dict[asset]['Close'].loc[test_asset_dict[asset].shape[0]-1]\n",
    "    gain = 100.0 * (end - start) / start\n",
    "    \n",
    "    print(asset, '\\t', test_asset_dict[asset]['Date'].loc[0], '\\t{:1.2f}'.format(start), '\\t', \n",
    "          test_asset_dict[asset]['Date'].loc[test_asset_dict[asset].shape[0]-1], \n",
    "          '\\t{:1.2f}'.format(end), '\\t{:1.2f}'.format(gain), '\\t{:1.2f}'.format(paper_baseline[asset]))    \n",
    "    \n",
    "# It looks like the paper used Close-Close or Open-Close rather than Adjusted Close to compute gains over the test period. \n",
    "# They are a lot closer to the paper quoted returns and better correlated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set length:\", len(train_asset_dict['SPY']))\n",
    "print(\"Valid set length\", len(valid_asset_dict['SPY']))\n",
    "print(\"Train / Valid set length\", len(train_val_asset_dict['SPY']))\n",
    "print(\"Pre-test set\", len(pre_test_asset_dict['SPY']))\n",
    "print(\"Test set\",len(test_asset_dict['SPY']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
